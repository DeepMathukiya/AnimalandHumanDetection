{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c36581fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only a single TORCH_LIBRARY can be used to register the namespace triton; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /dev/null:2623; latest registration was registered at /dev/null:2623",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\__init__.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      9\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# default for reduced CPU utilization during training\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NAS, RTDETR, SAM, YOLO, YOLOE, FastSAM, YOLOWorld\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ASSETS, SETTINGS\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchecks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_yolo \u001b[38;5;28;01mas\u001b[39;00m checks\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\models\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfastsam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAM\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NAS\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrtdetr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\models\\fastsam\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAM\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAMPredictor\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAMValidator\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\models\\fastsam\\model.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAMPredictor\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAMValidator\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\ultralytics\\engine\\model.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Union\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcfg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TASK2DATA, get_cfg, get_save_dir\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\__init__.py:2623\u001b[0m\n\u001b[0;32m   2620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _running_with_deploy():\n\u001b[0;32m   2621\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compiler \u001b[38;5;28;01mas\u001b[39;00m compiler\n\u001b[1;32m-> 2623\u001b[0m     \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_TritonLibrary\u001b[39;00m:\n\u001b[0;32m   2624\u001b[0m         lib \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlibrary\u001b[38;5;241m.\u001b[39mLibrary(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtriton\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2625\u001b[0m         ops_table: _Dict[_Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m], _Callable] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\__init__.py:2624\u001b[0m, in \u001b[0;36m_TritonLibrary\u001b[1;34m()\u001b[0m\n\u001b[0;32m   2623\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_TritonLibrary\u001b[39;00m:\n\u001b[1;32m-> 2624\u001b[0m     lib \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtriton\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDEF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2625\u001b[0m     ops_table: _Dict[_Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m], _Callable] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2627\u001b[0m     \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   2628\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregisterOp\u001b[39m(\u001b[38;5;28mcls\u001b[39m, op_key, full_schema, op_impl, dispatch_key):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\library.py:93\u001b[0m, in \u001b[0;36mLibrary.__init__\u001b[1;34m(self, ns, kind, dispatch_key)\u001b[0m\n\u001b[0;32m     91\u001b[0m frame \u001b[38;5;241m=\u001b[39m traceback\u001b[38;5;241m.\u001b[39mextract_stack(limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     92\u001b[0m filename, lineno \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mfilename, frame\u001b[38;5;241m.\u001b[39mlineno\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm: Optional[Any] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdispatch_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlineno\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mns \u001b[38;5;241m=\u001b[39m ns\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_defs: Set[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Only a single TORCH_LIBRARY can be used to register the namespace triton; please put all of your definitions in a single TORCH_LIBRARY block.  If you were trying to specify implementations, consider using TORCH_LIBRARY_IMPL (which can be duplicated).  If you really intended to define operators for a single namespace in a distributed way, you can use TORCH_LIBRARY_FRAGMENT to explicitly indicate this.  Previous registration of TORCH_LIBRARY was registered at /dev/null:2623; latest registration was registered at /dev/null:2623"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48bfdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:01<00:00, 6.28MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n.pt\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b220ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.146 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.145  Python-3.11.5 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=..\\dataset\\dataset_yolo\\dataset.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train8, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 2487.4482.7 MB/s, size: 306.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Tasks\\Animal and Human Detection\\dataset\\dataset_yolo\\labels\\train.cache... 356 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 356/356 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 16.76.7 MB/s, size: 163.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Tasks\\Animal and Human Detection\\dataset\\dataset_yolo\\labels\\val... 80 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 344.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\Tasks\\Animal and Human Detection\\dataset\\dataset_yolo\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train8\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train8\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      2.09G       1.45      3.249       1.51         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:07<00:00,  3.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178    0.00471      0.639     0.0666     0.0317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      2.39G      1.463      2.503      1.484         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178    0.00515      0.627     0.0585     0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      2.42G      1.448      2.408      1.531         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.308     0.0632     0.0581     0.0178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      2.44G      1.503      2.402      1.564          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.626     0.0701     0.0597     0.0245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      2.46G      1.581       2.32      1.553         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178     0.0579     0.0771     0.0419     0.0187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      2.48G      1.492       2.31      1.566         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.155       0.21      0.108     0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      2.48G      1.518       2.21       1.55         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.176      0.244      0.108     0.0487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      2.51G      1.469      2.229       1.53         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178       0.53     0.0514     0.0286     0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      2.52G      1.419      2.082      1.478         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.293      0.182      0.188     0.0896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      2.54G      1.477       2.06      1.491         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.126      0.234      0.124     0.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      2.55G      1.461      2.012      1.513         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.282      0.283      0.212      0.114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      2.58G      1.469      1.971      1.488          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.285      0.271       0.28      0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50       2.6G      1.448      1.836      1.451         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.315      0.257      0.263      0.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      2.61G      1.413      1.771      1.444         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.297      0.276      0.259      0.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      2.62G      1.336      1.704      1.421         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.728      0.266       0.24      0.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      2.65G      1.354      1.672      1.397         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.383      0.304      0.294      0.153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      2.66G      1.282      1.658      1.392          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178        0.4       0.29      0.288      0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      2.68G      1.299      1.591      1.349         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.392      0.348      0.311      0.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      2.69G      1.261      1.515      1.356         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.337      0.302      0.302      0.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      2.71G      1.267      1.509      1.343          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.392      0.304      0.289       0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      2.73G      1.293      1.573      1.338         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.357       0.34      0.329      0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      2.75G       1.26      1.428      1.326         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178       0.29      0.285       0.28      0.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      2.76G      1.259      1.514       1.32         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.296      0.348       0.29      0.143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      2.78G      1.234      1.421      1.341          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.384      0.388      0.311      0.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50       2.8G      1.208      1.399      1.302          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.337       0.32       0.28      0.132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      2.82G      1.167      1.316      1.271         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.359      0.325      0.298      0.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      2.82G       1.15      1.284      1.274         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.315      0.358      0.308      0.147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      2.85G      1.122      1.274       1.25         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178        0.4      0.346      0.305      0.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      2.87G      1.117      1.237      1.232         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.409       0.32      0.308      0.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      2.89G      1.103      1.155       1.22         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178       0.35      0.353       0.31      0.149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      2.89G       1.12      1.253      1.258          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.348      0.344      0.297      0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      2.92G      1.059      1.147      1.214         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.351       0.32      0.313      0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      2.94G      1.033      1.088      1.184          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.425      0.372      0.317      0.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      2.95G     0.9919      1.077      1.173         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.383      0.337      0.317      0.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      2.96G      1.014      1.065      1.162          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.373      0.367      0.318      0.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      2.98G      1.028      1.009      1.159         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.439      0.332      0.329       0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      3.01G      1.039      1.047      1.182         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.378      0.327      0.296      0.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      2.37G     0.9833      1.001       1.16         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.351      0.353      0.316      0.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      2.67G     0.9577     0.9592      1.142         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.458      0.337      0.341       0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      2.67G     0.9253     0.9467       1.14          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178        0.4      0.375      0.334       0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      2.67G     0.9448      1.037      1.154          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.441      0.344      0.324      0.166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      2.67G     0.9379     0.9855      1.112          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178       0.39      0.409       0.34      0.166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      2.67G     0.8923     0.9014      1.101          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.427       0.41      0.344      0.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      2.67G     0.8988     0.8615      1.098          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178       0.45      0.358      0.345      0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      2.67G     0.8838     0.7787      1.076          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.322      0.374      0.329      0.164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      2.67G      0.856     0.7846       1.08          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.442      0.323      0.336      0.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      2.67G     0.8783     0.7786       1.06          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.477      0.299      0.345      0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      2.67G     0.8279     0.7486      1.045          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.464      0.313      0.346      0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      2.67G     0.8138     0.7343      1.045          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.563       0.29      0.348      0.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      2.67G     0.7927     0.7382      1.039          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:04<00:00,  5.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.583      0.273      0.342      0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.084 hours.\n",
      "Optimizer stripped from runs\\detect\\train8\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\train8\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\train8\\weights\\best.pt...\n",
      "Ultralytics 8.3.145  Python-3.11.5 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.462      0.313      0.346      0.176\n",
      "            Human head         40        107      0.678       0.57      0.627      0.331\n",
      "                Animal         40         71      0.247     0.0563     0.0655     0.0219\n",
      "Speed: 0.3ms preprocess, 4.1ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = model.train(data=\"..\\dataset\\dataset_yolo\\dataset.yaml\", epochs=50, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046bd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.145  Python-3.11.5 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 6144MiB)\n",
      "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1978.2481.8 MB/s, size: 202.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Tasks\\Animal and Human Detection\\dataset\\dataset_yolo\\labels\\val.cache... 80 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         80        178      0.477      0.313      0.347      0.177\n",
      "            Human head         40        107      0.693      0.569      0.628      0.333\n",
      "                Animal         40         71      0.262     0.0563     0.0668     0.0219\n",
      "Speed: 1.3ms preprocess, 8.8ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train82\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save( \"yolo_model_trained.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23c22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 Human head, 119.2ms\n",
      "Speed: 4.7ms preprocess, 119.2ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 512x640 2 Human heads, 82.3ms\n",
      "Speed: 5.2ms preprocess, 82.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 384x640 1 Animal, 6.6ms\n",
      "Speed: 1.8ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x448 1 Human head, 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x480 1 Human head, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 544x640 1 Human head, 9.3ms\n",
      "Speed: 2.4ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 544x640 1 Human head, 8.1ms\n",
      "Speed: 2.2ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x448 1 Human head, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 2 Human heads, 8.5ms\n",
      "Speed: 1.8ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x480 20 Human heads, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 3 Human heads, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 7.1ms\n",
      "Speed: 1.6ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Human head, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 544x640 3 Human heads, 8.6ms\n",
      "Speed: 2.3ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 448x640 6 Human heads, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 Human heads, 7.4ms\n",
      "Speed: 1.9ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 544x640 5 Human heads, 9.1ms\n",
      "Speed: 2.3ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 480x640 5 Human heads, 7.3ms\n",
      "Speed: 1.7ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 18 Human heads, 7.2ms\n",
      "Speed: 1.5ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Animals, 7.2ms\n",
      "Speed: 1.7ms preprocess, 7.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 512x640 1 Human head, 8.1ms\n",
      "Speed: 1.7ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 2 Human heads, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 448x640 (no detections), 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 Human head, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 Human head, 7.1ms\n",
      "Speed: 1.6ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 7.5ms\n",
      "Speed: 1.6ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 (no detections), 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x480 1 Animal, 6.7ms\n",
      "Speed: 1.8ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x448 1 Human head, 13.4ms\n",
      "Speed: 2.5ms preprocess, 13.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 7 Human heads, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 4 Human heads, 7.8ms\n",
      "Speed: 1.8ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 2 Human heads, 8.3ms\n",
      "Speed: 1.7ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 7.4ms\n",
      "Speed: 1.8ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x416 2 Human heads, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "0: 640x384 12 Human heads, 5.9ms\n",
      "Speed: 1.4ms preprocess, 5.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 480x640 1 Animal, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 2 Human heads, 8.3ms\n",
      "Speed: 1.7ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 2 Human heads, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 480x640 5 Human heads, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 12 Human heads, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x480 1 Human head, 11.6ms\n",
      "Speed: 1.9ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x448 1 Human head, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x256 1 Human head, 5.2ms\n",
      "Speed: 1.0ms preprocess, 5.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 256)\n",
      "\n",
      "0: 448x640 2 Human heads, 8.7ms\n",
      "Speed: 1.4ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 3 Human heads, 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 480x640 1 Human head, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 13 Human heads, 8.0ms\n",
      "Speed: 1.4ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 5 Human heads, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x544 1 Human head, 8.7ms\n",
      "Speed: 2.6ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 416x640 1 Human head, 7.7ms\n",
      "Speed: 1.4ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 10.6ms\n",
      "Speed: 1.9ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x448 (no detections), 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x416 4 Human heads, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "0: 640x448 6 Human heads, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x640 2 Human heads, 9.4ms\n",
      "Speed: 2.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x416 1 Human head, 6.8ms\n",
      "Speed: 1.3ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "0: 640x448 3 Human heads, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 416x640 1 Human head, 7.6ms\n",
      "Speed: 1.4ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x448 1 Human head, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x640 1 Human head, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 4 Human heads, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 Human heads, 6.6ms\n",
      "Speed: 1.6ms preprocess, 6.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 17 Human heads, 8.2ms\n",
      "Speed: 1.4ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 3 Human heads, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x512 1 Human head, 7.0ms\n",
      "Speed: 1.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 320x640 1 Human head, 5.8ms\n",
      "Speed: 1.2ms preprocess, 5.8ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 448x640 1 Human head, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 544x640 3 Human heads, 9.3ms\n",
      "Speed: 2.2ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 544x640 1 Human head, 8.5ms\n",
      "Speed: 2.3ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 640x448 1 Human head, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 Human head, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x384 1 Human head, 6.3ms\n",
      "Speed: 1.6ms preprocess, 6.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x448 1 Human head, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 2 Animals, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x480 1 Animal, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 7 Human heads, 10.0ms\n",
      "Speed: 1.8ms preprocess, 10.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 3 Human heads, 8.5ms\n",
      "Speed: 1.6ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 4 Human heads, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 512x640 1 Human head, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 448x640 3 Human heads, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x480 2 Human heads, 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x448 2 Human heads, 7.1ms\n",
      "Speed: 1.6ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x480 2 Human heads, 7.5ms\n",
      "Speed: 1.5ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 448x640 5 Human heads, 9.1ms\n",
      "Speed: 1.5ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 512x640 19 Human heads, 8.4ms\n",
      "Speed: 1.9ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 448x640 2 Human heads, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 Human head, 6.8ms\n",
      "Speed: 1.3ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x512 1 Human head, 8.4ms\n",
      "Speed: 1.8ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x480 3 Human heads, 10.8ms\n",
      "Speed: 1.8ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 448x640 3 Human heads, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 576x640 1 Human head, 9.1ms\n",
      "Speed: 2.5ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x448 1 Human head, 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x640 1 Human head, 10.1ms\n",
      "Speed: 2.8ms preprocess, 10.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Human head, 9.0ms\n",
      "Speed: 3.3ms preprocess, 9.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 3 Human heads, 8.2ms\n",
      "Speed: 1.5ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 Human heads, 8.4ms\n",
      "Speed: 1.8ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 3 Human heads, 7.4ms\n",
      "Speed: 1.9ms preprocess, 7.4ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x480 1 Human head, 11.3ms\n",
      "Speed: 2.0ms preprocess, 11.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 448x640 8 Human heads, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x512 1 Human head, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x448 1 Human head, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 416x640 1 Human head, 7.9ms\n",
      "Speed: 1.4ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 640x448 1 Human head, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x480 1 Human head, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 448x640 3 Human heads, 8.5ms\n",
      "Speed: 1.6ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 Human head, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 4 Human heads, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 608x640 1 Human head, 8.8ms\n",
      "Speed: 2.8ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 640x448 1 Human head, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 3 Human heads, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 4 Human heads, 7.6ms\n",
      "Speed: 1.7ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x480 1 Human head, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 448x640 (no detections), 10.9ms\n",
      "Speed: 1.6ms preprocess, 10.9ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 288x640 1 Human head, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n",
      "0: 640x480 1 Human head, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 Human heads, 6.9ms\n",
      "Speed: 1.8ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 1 Human head, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 7.4ms\n",
      "Speed: 1.8ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Human head, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 416x640 1 Human head, 7.5ms\n",
      "Speed: 1.9ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x640 1 Human head, 9.9ms\n",
      "Speed: 3.5ms preprocess, 9.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 8.1ms\n",
      "Speed: 1.8ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 2 Human heads, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x448 1 Human head, 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 2 Human heads, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 Human heads, 12.5ms\n",
      "Speed: 2.8ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 544x640 1 Human head, 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 448x640 2 Human heads, 8.1ms\n",
      "Speed: 1.7ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x352 1 Human head, 5.9ms\n",
      "Speed: 1.5ms preprocess, 5.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 352)\n",
      "\n",
      "0: 640x512 5 Human heads, 1 Animal, 7.8ms\n",
      "Speed: 1.8ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x544 3 Human heads, 8.9ms\n",
      "Speed: 2.5ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 480x640 2 Human heads, 1 Animal, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x448 1 Human head, 6.6ms\n",
      "Speed: 1.6ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 14 Human heads, 8.4ms\n",
      "Speed: 1.5ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 6 Human heads, 7.5ms\n",
      "Speed: 1.9ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x448 1 Human head, 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 Human head, 8.1ms\n",
      "Speed: 2.0ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x544 4 Human heads, 9.9ms\n",
      "Speed: 2.3ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 448x640 3 Human heads, 8.1ms\n",
      "Speed: 1.9ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x384 1 Human head, 6.5ms\n",
      "Speed: 1.5ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x576 2 Human heads, 9.0ms\n",
      "Speed: 2.9ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 576)\n",
      "\n",
      "0: 480x640 (no detections), 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Human head, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 512x640 1 Human head, 8.3ms\n",
      "Speed: 1.7ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 640x480 1 Human head, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x448 1 Human head, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 480x640 1 Human head, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Human head, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x640 1 Human head, 9.5ms\n",
      "Speed: 3.0ms preprocess, 9.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 24 Human heads, 8.6ms\n",
      "Speed: 1.7ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 6.9ms\n",
      "Speed: 2.7ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x640 1 Human head, 9.5ms\n",
      "Speed: 2.8ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 8.3ms\n",
      "Speed: 1.9ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 512x640 3 Human heads, 8.3ms\n",
      "Speed: 1.8ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 640x640 3 Human heads, 9.8ms\n",
      "Speed: 2.9ms preprocess, 9.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 1 Human head, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 8 Human heads, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 Human head, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 576x640 1 Human head, 9.0ms\n",
      "Speed: 2.8ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 448x640 7 Human heads, 8.4ms\n",
      "Speed: 1.5ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 576x640 2 Human heads, 8.8ms\n",
      "Speed: 2.7ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 10.7ms\n",
      "Speed: 1.7ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 2 Human heads, 8.0ms\n",
      "Speed: 2.4ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 Human head, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 3 Human heads, 7.6ms\n",
      "Speed: 1.8ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 Human head, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x640 9 Human heads, 9.6ms\n",
      "Speed: 2.9ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x448 2 Human heads, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 480x640 1 Human head, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Human head, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 512x640 1 Animal, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 448x640 2 Human heads, 7.6ms\n",
      "Speed: 1.7ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 1 Animal, 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 576x640 1 Human head, 8.7ms\n",
      "Speed: 2.7ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 576x640 1 Human head, 8.5ms\n",
      "Speed: 2.8ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "\n",
      "0: 640x448 3 Human heads, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 480x640 1 Human head, 8.3ms\n",
      "Speed: 1.7ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Human heads, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x544 1 Human head, 8.7ms\n",
      "Speed: 2.3ms preprocess, 8.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 544)\n",
      "\n",
      "0: 448x640 17 Human heads, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 512x640 1 Human head, 8.9ms\n",
      "Speed: 1.8ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 448x640 1 Human head, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 4 Human heads, 7.6ms\n",
      "Speed: 1.6ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 2 Human heads, 9.0ms\n",
      "Speed: 1.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 Human head, 9.6ms\n",
      "Speed: 1.8ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 Human head, 7.2ms\n",
      "Speed: 1.7ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 4 Human heads, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 Animal, 6.4ms\n",
      "Speed: 1.4ms preprocess, 6.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 2 Animals, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 3 Animals, 7.8ms\n",
      "Speed: 1.6ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x640 1 Animal, 10.4ms\n",
      "Speed: 3.2ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.6ms\n",
      "Speed: 1.7ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x512 1 Animal, 7.5ms\n",
      "Speed: 1.7ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x448 1 Animal, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 Animal, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 2 Animals, 8.4ms\n",
      "Speed: 1.9ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 7.6ms\n",
      "Speed: 1.6ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 11 Animals, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x608 1 Animal, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 608)\n",
      "\n",
      "0: 448x640 1 Animal, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 3 Animals, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x384 1 Animal, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 480x640 1 Animal, 8.0ms\n",
      "Speed: 1.8ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 2 Animals, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 7.5ms\n",
      "Speed: 1.6ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 Animals, 7.7ms\n",
      "Speed: 1.6ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 7.1ms\n",
      "Speed: 1.9ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Human head, 1 Animal, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x448 1 Animal, 7.1ms\n",
      "Speed: 1.6ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x320 1 Animal, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 448x640 1 Animal, 8.9ms\n",
      "Speed: 1.6ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 2 Animals, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 640x448 1 Animal, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 Animal, 8.7ms\n",
      "Speed: 1.6ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x480 1 Animal, 7.2ms\n",
      "Speed: 1.5ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 416x640 6 Animals, 7.5ms\n",
      "Speed: 1.4ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.4ms\n",
      "Speed: 1.7ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x256 6 Animals, 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 256)\n",
      "\n",
      "0: 448x640 2 Animals, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 Animal, 6.6ms\n",
      "Speed: 1.6ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 480x640 1 Animal, 8.3ms\n",
      "Speed: 3.2ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 10.4ms\n",
      "Speed: 1.6ms preprocess, 10.4ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 8 Animals, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 480x640 2 Animals, 7.9ms\n",
      "Speed: 1.8ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Animals, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 7.5ms\n",
      "Speed: 1.6ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 2 Animals, 8.2ms\n",
      "Speed: 1.7ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 416x640 1 Animal, 7.3ms\n",
      "Speed: 1.4ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Animals, 6.9ms\n",
      "Speed: 2.0ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x448 1 Animal, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 544x640 1 Animal, 8.8ms\n",
      "Speed: 2.5ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 640x448 1 Animal, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 Animal, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 4 Animals, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Animals, 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Animals, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x448 2 Animals, 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 512x640 1 Animal, 8.3ms\n",
      "Speed: 1.9ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.5ms\n",
      "Speed: 1.5ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 3 Animals, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Human head, 1 Animal, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 2 Animals, 6.6ms\n",
      "Speed: 1.4ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.8ms\n",
      "Speed: 1.5ms preprocess, 8.8ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.6ms\n",
      "Speed: 2.0ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 512x640 1 Animal, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 8.3ms\n",
      "Speed: 1.6ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 9.2ms\n",
      "Speed: 1.5ms preprocess, 9.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 2 Animals, 8.0ms\n",
      "Speed: 1.7ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 2 Animals, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 8.2ms\n",
      "Speed: 1.8ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x448 1 Animal, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 480x640 1 Animal, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.7ms\n",
      "Speed: 1.5ms preprocess, 8.7ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x640 2 Animals, 9.6ms\n",
      "Speed: 3.0ms preprocess, 9.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 448x640 5 Animals, 8.6ms\n",
      "Speed: 1.6ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 8.1ms\n",
      "Speed: 1.7ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.2ms\n",
      "Speed: 1.9ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x640 1 Animal, 9.7ms\n",
      "Speed: 2.9ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 8.4ms\n",
      "Speed: 1.6ms preprocess, 8.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.3ms\n",
      "Speed: 1.8ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 352x640 1 Animal, 6.5ms\n",
      "Speed: 1.4ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 352, 640)\n",
      "\n",
      "0: 640x448 1 Animal, 7.1ms\n",
      "Speed: 1.6ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 384x640 2 Animals, 6.6ms\n",
      "Speed: 1.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 2 Animals, 10.4ms\n",
      "Speed: 1.6ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 8.1ms\n",
      "Speed: 1.9ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x416 1 Animal, 7.3ms\n",
      "Speed: 1.3ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "0: 480x640 1 Animal, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Animals, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 1 Animal, 7.5ms\n",
      "Speed: 1.8ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 Animals, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 1 Animal, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 2 Animals, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 5 Animals, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 Animal, 10.6ms\n",
      "Speed: 1.6ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x512 3 Animals, 7.4ms\n",
      "Speed: 1.8ms preprocess, 7.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 480x640 12 Animals, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x448 1 Animal, 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 480x640 2 Animals, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 9.9ms\n",
      "Speed: 1.8ms preprocess, 9.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 7.7ms\n",
      "Speed: 1.5ms preprocess, 7.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.9ms\n",
      "Speed: 1.5ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 8.1ms\n",
      "Speed: 1.6ms preprocess, 8.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 9.5ms\n",
      "Speed: 1.6ms preprocess, 9.5ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 384x640 1 Animal, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.5ms\n",
      "Speed: 1.7ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x480 2 Animals, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 1 Animal, 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 1 Animal, 7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 544x640 2 Animals, 9.3ms\n",
      "Speed: 2.5ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 Animals, 9.6ms\n",
      "Speed: 1.5ms preprocess, 9.6ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 (no detections), 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.2ms\n",
      "Speed: 1.6ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 3 Animals, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 4 Animals, 8.9ms\n",
      "Speed: 1.9ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 512x640 1 Animal, 10.1ms\n",
      "Speed: 1.9ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.9ms\n",
      "Speed: 1.8ms preprocess, 8.9ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 4 Animals, 7.9ms\n",
      "Speed: 1.8ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 2 Animals, 8.0ms\n",
      "Speed: 1.8ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x448 1 Animal, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x480 1 Animal, 9.2ms\n",
      "Speed: 1.8ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 1 Animal, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 416x640 2 Animals, 8.3ms\n",
      "Speed: 1.5ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n",
      "\n",
      "0: 480x640 2 Animals, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 608x640 2 Animals, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 1.1ms postprocess per image at shape (1, 3, 608, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 384x640 4 Animals, 6.2ms\n",
      "Speed: 1.4ms preprocess, 6.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 480x640 4 Animals, 8.0ms\n",
      "Speed: 1.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 Animals, 7.2ms\n",
      "Speed: 2.1ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 8.1ms\n",
      "Speed: 1.5ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.9ms\n",
      "Speed: 1.6ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.8ms\n",
      "Speed: 1.7ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 512x640 1 Animal, 8.1ms\n",
      "Speed: 1.7ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 9.7ms\n",
      "Speed: 1.6ms preprocess, 9.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.5ms\n",
      "Speed: 1.6ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Animal, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x448 1 Animal, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 480x640 1 Animal, 7.9ms\n",
      "Speed: 1.7ms preprocess, 7.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 448x640 1 Animal, 7.6ms\n",
      "Speed: 1.5ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 Animal, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x640 (no detections), 9.5ms\n",
      "Speed: 3.4ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Animal, 8.9ms\n",
      "Speed: 2.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 480x640 (no detections), 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x640 1 Animal, 9.4ms\n",
      "Speed: 3.0ms preprocess, 9.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 512x640 1 Animal, 10.0ms\n",
      "Speed: 1.6ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def crop_and_save_images(yolo_model, input_dir, output_dir):\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Recursively get all .jpg images\n",
    "    image_files = list(input_dir.rglob(\"*.jpg\"))\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No images found in: {input_dir}\")\n",
    "        return\n",
    "\n",
    "    for img_path in image_files:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            print(f\"Failed to read: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        results = yolo_model(img)\n",
    "        boxes = results[0].boxes\n",
    "\n",
    "        if boxes is None or boxes.xyxy.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        for i, box in enumerate(boxes.xyxy.cpu().numpy()):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            crop = img[y1:y2, x1:x2]\n",
    "            label = int(boxes.cls[i].item())\n",
    "            label_name = \"human\" if label == 0 else \"animal\"\n",
    "\n",
    "            label_dir = output_dir / label_name\n",
    "            label_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            out_path = label_dir / f\"{img_path.stem}_{i}.jpg\"\n",
    "            cv2.imwrite(str(out_path), crop)\n",
    "\n",
    "crop_and_save_images(model, r\"../dataset/dataset_yolo/images/train\", r\"../dataset/cropped_dataset_train\")\n",
    "crop_and_save_images(model, r\"../dataset/dataset_yolo/images/val\", r\"../dataset/cropped_dataset_val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74af95e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "data_dir = \"../dataset/cropped_dataset_train\"\n",
    "target_size = (224, 224)\n",
    "train_X = []\n",
    "train_y = []\n",
    "\n",
    "classes = sorted(os.listdir(data_dir))  \n",
    "for label, class_name in enumerate(classes):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    for fname in os.listdir(class_dir):\n",
    "        fpath = os.path.join(class_dir, fname)\n",
    "        try:\n",
    "            img = load_img(fpath, target_size=target_size)\n",
    "            img_array = img_to_array(img)\n",
    "            train_X.append(img_array)\n",
    "            train_y.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {fpath}: {e}\")\n",
    "\n",
    "X = np.array(train_X) / 255.0\n",
    "y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "569f02ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "augmentor = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "augmented_data_train = augmentor.flow(X, y, batch_size=32, shuffle=True)\n",
    "len(augmented_data_train)  # Number of batches in the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67a080d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 135)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "data_dir = \"../dataset/cropped_dataset_val\"\n",
    "target_size = (224, 224)\n",
    "val_X = []\n",
    "val_y = []\n",
    "\n",
    "classes = sorted(os.listdir(data_dir))  \n",
    "for label, class_name in enumerate(classes):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    for fname in os.listdir(class_dir):\n",
    "        fpath = os.path.join(class_dir, fname)\n",
    "        try:\n",
    "            img = load_img(fpath, target_size=target_size)\n",
    "            img_array = img_to_array(img)\n",
    "            val_X.append(img_array)\n",
    "            val_y.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {fpath}: {e}\")\n",
    "\n",
    "X = np.array(val_X) / 255.0\n",
    "y = np.array(val_y)\n",
    "len(X), len(y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225efa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_data_val = augmentor.flow(X, y, batch_size=32, shuffle=True)\n",
    "len(augmented_data_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0469a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "base_model = VGG19(include_top=False, input_shape=(224, 224, 3), weights=None)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffc8a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cedfea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "file_path = os.path.join(current_dir, 'vgg19_model_o8.keras')\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=file_path, monitor='val_loss', save_best_only=True, save_weights_only=False, verbose=1)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=6, verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', verbose=1, patience=5)\n",
    "\n",
    "callbacks = [checkpoint, reduce_learning_rate]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29112a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6308 - loss: 0.6246\n",
      "Epoch 1: val_loss improved from inf to 0.48826, saving model to d:\\Tasks\\Animal and Human Detection\\models\\vgg19_model_o8.keras\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.6316 - loss: 0.6241 - val_accuracy: 0.7778 - val_loss: 0.4883 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6378 - loss: 0.6057\n",
      "Epoch 2: val_loss improved from 0.48826 to 0.47966, saving model to d:\\Tasks\\Animal and Human Detection\\models\\vgg19_model_o8.keras\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.6384 - loss: 0.6053 - val_accuracy: 0.7704 - val_loss: 0.4797 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6882 - loss: 0.5547\n",
      "Epoch 3: val_loss did not improve from 0.47966\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 2s/step - accuracy: 0.6880 - loss: 0.5554 - val_accuracy: 0.7778 - val_loss: 0.5499 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6838 - loss: 0.5711\n",
      "Epoch 4: val_loss improved from 0.47966 to 0.44872, saving model to d:\\Tasks\\Animal and Human Detection\\models\\vgg19_model_o8.keras\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.6836 - loss: 0.5709 - val_accuracy: 0.7852 - val_loss: 0.4487 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7113 - loss: 0.5343\n",
      "Epoch 5: val_loss improved from 0.44872 to 0.42970, saving model to d:\\Tasks\\Animal and Human Detection\\models\\vgg19_model_o8.keras\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.7111 - loss: 0.5348 - val_accuracy: 0.8074 - val_loss: 0.4297 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7327 - loss: 0.5426\n",
      "Epoch 6: val_loss improved from 0.42970 to 0.42548, saving model to d:\\Tasks\\Animal and Human Detection\\models\\vgg19_model_o8.keras\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7333 - loss: 0.5420 - val_accuracy: 0.7926 - val_loss: 0.4255 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6990 - loss: 0.5450\n",
      "Epoch 7: val_loss did not improve from 0.42548\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.6994 - loss: 0.5443 - val_accuracy: 0.8148 - val_loss: 0.4698 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7117 - loss: 0.5443\n",
      "Epoch 8: val_loss improved from 0.42548 to 0.39491, saving model to d:\\Tasks\\Animal and Human Detection\\models\\vgg19_model_o8.keras\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.7129 - loss: 0.5432 - val_accuracy: 0.8000 - val_loss: 0.3949 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7767 - loss: 0.4742\n",
      "Epoch 9: val_loss did not improve from 0.39491\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7762 - loss: 0.4748 - val_accuracy: 0.8222 - val_loss: 0.4829 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7471 - loss: 0.5185\n",
      "Epoch 10: val_loss did not improve from 0.39491\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7471 - loss: 0.5181 - val_accuracy: 0.8370 - val_loss: 0.4344 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7621 - loss: 0.5001\n",
      "Epoch 11: val_loss improved from 0.39491 to 0.38864, saving model to d:\\Tasks\\Animal and Human Detection\\models\\vgg19_model_o8.keras\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.7615 - loss: 0.5005 - val_accuracy: 0.8000 - val_loss: 0.3886 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7460 - loss: 0.4796\n",
      "Epoch 12: val_loss did not improve from 0.38864\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.7464 - loss: 0.4797 - val_accuracy: 0.8519 - val_loss: 0.3928 - learning_rate: 0.0010\n",
      "Epoch 13/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7680 - loss: 0.4566\n",
      "Epoch 13: val_loss did not improve from 0.38864\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.7671 - loss: 0.4581 - val_accuracy: 0.7556 - val_loss: 0.4737 - learning_rate: 0.0010\n",
      "Epoch 14/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7649 - loss: 0.4764\n",
      "Epoch 14: val_loss did not improve from 0.38864\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7650 - loss: 0.4759 - val_accuracy: 0.8296 - val_loss: 0.3948 - learning_rate: 0.0010\n",
      "Epoch 15/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8296 - loss: 0.4295\n",
      "Epoch 15: val_loss improved from 0.38864 to 0.38857, saving model to d:\\Tasks\\Animal and Human Detection\\models\\vgg19_model_o8.keras\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.8290 - loss: 0.4299 - val_accuracy: 0.8000 - val_loss: 0.3886 - learning_rate: 0.0010\n",
      "Epoch 16/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7942 - loss: 0.4447\n",
      "Epoch 16: val_loss did not improve from 0.38857\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.7935 - loss: 0.4456 - val_accuracy: 0.7852 - val_loss: 0.4790 - learning_rate: 0.0010\n",
      "Epoch 17/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7977 - loss: 0.4546\n",
      "Epoch 17: val_loss improved from 0.38857 to 0.38050, saving model to d:\\Tasks\\Animal and Human Detection\\models\\vgg19_model_o8.keras\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7979 - loss: 0.4541 - val_accuracy: 0.8222 - val_loss: 0.3805 - learning_rate: 0.0010\n",
      "Epoch 18/25\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7981 - loss: 0.4382\n",
      "Epoch 18: val_loss improved from 0.38050 to 0.36742, saving model to d:\\Tasks\\Animal and Human Detection\\models\\vgg19_model_o8.keras\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7976 - loss: 0.4393 - val_accuracy: 0.8444 - val_loss: 0.3674 - learning_rate: 0.0010\n",
      "Epoch 19/25\n",
      "\u001b[1m14/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8177 - loss: 0.4272"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_data_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugmented_data_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(augmented_data_train,validation_data=augmented_data_val, epochs=25, batch_size=32, validation_split=0.2, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ba8e7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"vgg19_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95d5d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dacffc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(len(acc))\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "plt.plot(epochs,acc,'r',label=\"Training Accuracy\")\n",
    "plt.plot(epochs,val_acc,'b',label=\"Validation Accuracy\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ced3767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.650253</td>\n",
       "      <td>0.664956</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.579245</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.655122</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.586572</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.652680</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.582703</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.640569</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.560781</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.635195</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.559972</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.626695</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.538573</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy      loss  val_accuracy  val_loss  learning_rate\n",
       "0  0.650253  0.664956      0.777778  0.579245          0.001\n",
       "1  0.652778  0.655122      0.777778  0.586572          0.001\n",
       "2  0.652778  0.652680      0.777778  0.582703          0.001\n",
       "3  0.652778  0.640569      0.777778  0.560781          0.001\n",
       "4  0.652778  0.635195      0.777778  0.559972          0.001\n",
       "5  0.652778  0.626695      0.777778  0.538573          0.001"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hist_=pd.DataFrame(history.history)\n",
    "hist_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "559cc752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMcAAANMCAYAAABYQ8rCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAADlfUlEQVR4nOzdd1gUV9sG8HuBpfdeRLChKCj23lFi1ESNvbcYe6+JscSoiRpDjBrfGGONPWqMvSv23lHEAlhooqAgbfd8f/DthJW6FFfg/l3XXuLMnDPP7M7unn3mnDMyIYQAERERERERERFRCaSj7QCIiIiIiIiIiIi0hckxIiIiIiIiIiIqsZgcIyIiIiIiIiKiEovJMSIiIiIiIiIiKrGYHCMiIiIiIiIiohKLyTEiIiIiIiIiIiqxmBwjIiIiIiIiIqISi8kxIiIiIiIiIiIqsZgcIyIiIiIiIiKiEovJMdK6J0+eQCaTQSaTYc2aNdoOhyhXmjVrBplMhmbNmmW6XnVOz5o1K8/7OHHihFTPiRMn8lxPQcnpmImISB3bOERFl7u7O2QyGfr3759hXUG9t9esWSPV8+TJkzzXU1CyO2ai4o7JsWIq/Qd2fh70X0KAz0fW7ty5g4EDB8Ld3R0GBgYwMTFB5cqV0b9/f+zYsQMpKSn53kelSpUgk8lgYmKCt2/falT266+/ll7DnTt35jsWKp5mzZr1USUjiShzbOMUrubNm0vPUevWrbUdDn0kzp07h27dusHFxQX6+vowMzODj48Phg0bhkOHDkGpVOar/sTERFhaWkImk8Hd3R1CCI3K9+zZUzpvr127lq9YqGQZMGCAdO5UrFhR2+GQFjE5RkT5smXLFtSsWROrV69GSEgIkpOTkZCQgMDAQKxduxZffPEF9u7dm+/99OnTBwCQkJCAHTt25LqcEAJ//fUXAMDGxgZt27bNdyzFSf/+/aWGKBERlWwhISE4efKk9P+jR4/i+fPnWoyIPgaLFy9Go0aNsHXrVjx//hwpKSl4+/Ytbty4gRUrVsDPzw83b97M1z4MDQ3RpUsXAGnnYUBAQK7LvnnzBrt27QIAeHl5oXr16vmKpbhhz/+sJSQkYPv27dL/g4KCcP78eS1GRNqkp+0AqHC4uLjg1q1bWa739vYGANSqVQurV6/+UGFlKi9Xh+jj8PDhQ/Tt2xfJyckwNDTE6NGj4efnB1NTUwQGBmLXrl3Ys2dPgeyrT58++PbbbyGEwPr169G3b99clTt58iRCQ0MBAN26dYO+vn6BxJOT4nhOszcVEX0M2MYpPOvXr4cQAgYGBlAoFEhNTcWGDRswefJkbYdGWhIQEIAJEyYAACwsLDB58mQ0btwYenp6uHHjBrZv345jx44VyL769u2LP/74A0DaudikSZNclfv777/x7t07qY4Poai9t3PrYxja+SHt2LFDGpFiYmKC+Ph4rFu3DvXq1dNyZKQNTI4VU3K5HF5eXjluZ2JikqvtiDKzcuVKJCcnAwDWrl2Lrl27Suvq1KmDfv364cmTJ1AoFPneV+nSpdG0aVOcOHECx44dw/Pnz+Hs7JxjufXr10t/f6gGExERFR62cQqP6juzXbt2ePfuHfbt24f169czOVaCLVu2DACgo6OD/fv3o379+tK6+vXrY+jQobh16xYcHBzyva9GjRqhTJkyePz4MbZt24alS5fCwMAgx3Kq81ZXVxe9evXKdxxUcqxbtw4AULNmTdStWxfLly/Hli1b4O/v/8EuqNPHg8MqiSjPVFfuzczMpK7w73N3d0e5cuUKZH+q5JZSqcTGjRtz3D4xMVHqKl2xYkXUrVu3QOIgIiIqbs6fP4+goCAAQK9evdC7d28AwO3bt3H16lVthkZapGrreXp6qiXG0vP29oa9vX2+9yWTyaRpNGJjY/Hvv//mWObp06dSz/aWLVvm6sIpEQA8f/4cR48eBaD+mRcTE1NgI1+oaGFyjDJ4f1z6gwcPMHLkSFSoUAHGxsYZ7qby4sULLF++HJ07d0aFChVgYmICAwMDuLi44PPPP8eWLVuynaQzp7u9pJ8kG0hLeCxcuBA1atSAmZkZzMzMUKdOHSxduhSpqakF+VQUmFu3bmHIkCHSc2hmZoYqVapg3LhxOXZfVigUWLNmDfz8/ODo6Ah9fX1YWFigQoUKaNmyJebNm4e7d+9mWjYoKAijRo2Cl5cXzMzMoK+vD2dnZ/j4+GDgwIHYsmULkpKS8nxcenp6UowFMel+Tjp37gxjY2MA6j3CsvLPP/8gLi4OwH9zlgFAcnIy/v33X4wcORK1a9eGlZUV5HI5bGxsULduXcyaNQvR0dH5ijU3d6t89+4d5s2bh2rVqsHExAQ2NjZo2LAhVq5cmauJbZVKJY4dO4aJEyeiYcOGsLW1hVwuh6WlJXx8fDBx4kRpSOn7VO+rtWvXAkib3yOnCatzO2fF6dOn0adPH7i7u8PQ0BCWlpaoXr06pk+fjqioqCzLZXZ3zq1bt6Jly5aws7ODkZERKlasiMmTJyMmJibH50cboqKiMH36dFSvXh2WlpYwNDSEu7s7+vTpg9OnT+dY/tixY+jRowfKlCkDIyMjGBsbw83NDfXq1cPEiROzHLry+vVrzJ07F/Xr15fOZzs7O1SuXBkdO3bEb7/9hoiIiII+XKIih22crKl6UFhZWaFt27bo0KEDzMzM1NblxpkzZzB48GBUrFgR5ubm0NfXR6lSpdCuXTssW7YMr1+/zrLskydPMGXKFNSsWRM2NjaQy+WwtbVF48aNMWvWLDx69CjD9rm9Y2B2d+F7/46BSUlJ8Pf3R7169WBra5vh+7wg2xFJSUn4/fff0bZtW7i4uEg3NqpSpQoGDx6MgwcPSsP3oqOjYWBgAJlMhqFDh+ZY97///isd19atW3MVz/tUbb3ExMQ8lddU+l7+uWnr/fXXX9J7MH3Z+Ph4bNmyBYMHD4aPjw8sLCyk78amTZti0aJFGt/gKb3cnnuvXr3C1KlTUalSJRgZGcHe3h6+vr7Ytm1brvaTn3NNNa+sah7BkydPZmjnvT/nbG7vVvnvv/+ic+fOKFWqFAwMDGBjY4P69evjhx9+yPZ5ff+9plQq8fvvv6NBgwawsrKCiYkJqlatirlz5yIhISFXz1FebdiwAUqlErq6uujRowfq16+P8uXLA9DsM+/27dsYNWoUvL29pdfH0dERvr6+WLBgAV68eJFl2aioKHz33Xdo2LAh7O3tIZfLYWVlhbp162Ly5MmZzuWXm98YQPbt9vfb3EqlEn/++SeaN28OBwcH6OjoqJ0D+fnN8T6lUolNmzbhiy++QOnSpWFkZAQjIyN4eHigV69e2L59u/S7MiUlBY6OjpDJZPjkk09yrPv27dvScS1YsCBX8agRVCIBEABE06ZNM6xr2rSptG7Xrl3CxMRE2l71ePz4sRBCiNTUVKGjo5Nh/fuPVq1aiTdv3mQay+PHj6XtVq9enWH9zJkzpfXh4eHCx8cny/20b99eKBSKAnym/ns+8vp2mTdvXrbPkYGBgVi7dm2mZd+8eSMaN26c4/P7xRdfZCi7detWoa+vn2PZW7du5em4hBBi0aJFUj3+/v55rkcTPXv2lPZ548aNbLdt27atACBkMpkICQmRlvfr1y/H58XGxkacPn06y7rTv08yo6pn5syZma5/8eKF8PT0zHL/fn5+4uDBg9L/jx8/nqGO9O+NrB7GxsZix44deSr7/jmf0zErFAoxYsSIbOuzsLAQhw4dyrT88ePHpe2OHj0qevfunWU95cuXFy9evMi0nrxK/5xk9nzn5ODBg8Lc3Dzb4x8xYkSWn1Fjx47N1Xn5vrt37wpnZ+ccy/76668aHxNRUaQ659nGyb2kpCRhbW0tAIghQ4ZIy1Xfl/b29iIlJSXbOhISEkSPHj1yfL6y+l5cuHChkMvl2ZZ9/zXN6flNz83NTQAQ/fr1y7Bu9erVUj2XLl3K9HVIH3dBtCOEEOLatWuiTJkyOdalOieFEKJLly4CgLC0tBTv3r3Ltv6OHTsKAMLa2lokJiZmu21WRo4cKcWxa9euPNWhqQYNGggAQi6Xi+jo6Gy3rVKligAgzMzMRHx8vLQ8ffs9q0eZMmVEYGBglnVnd87k5tzL6ft5wIABaude+tdZJT/nWm7Kurm55fqYhRDi3bt30nmV1cPZ2Vlcu3Yt0/Lpj/fOnTuiZcuWWdZTp04d8fbt20zrKQheXl4CgGjdurW0TPWZnJtzLzU1VYwbN07IZLJsn4+snssNGzZk+h2U3esjRM6/MVSya7enb3Pv379f+Pr6Zht3fn5zpPf48eNsv+dUj/Tt8EmTJgkAQkdHRzx9+jTb+seNGycACD09vTz9TuCcY5Sl0NBQ9O7dG8bGxvj222/RuHFj6Orq4tKlSzA1NQUA6UpWixYt0KZNG3h7e8POzg5v3rzBo0ePsHLlSpw7dw6HDx/GiBEjpF4qedWpUyfcvXsXo0ePRvv27WFtbY379+9jzpw5CAwMxL///ouVK1fiq6++yvfxF4Tly5fj66+/BgDY2dlhypQpaNiwIRQKBY4cOYKFCxciPj4e/fv3h62tLT799FO18rNmzZLu1tOuXTv06tULpUuXhqGhISIjI3Ht2jXs2bMnQw+fiIgIDBgwAMnJybC3t8fIkSOlq5/v3r1DcHAwTp48Kd3ZJ68GDx6MH3/8EVFRUZgyZQqqV6+e68lT86pv377SkMr169dj4cKFmW4XGRmJgwcPAgCaNm2K0qVLS+tSU1NRtmxZdOzYEXXq1EHp0qWhp6eHkJAQHDlyBH/++SdevnyJjh074vbt2wUyVCC91NRUtGvXDoGBgQCA1q1bY9iwYXB1dUVoaCiWL1+OgwcP5tg7KjU1FU5OTujYsSPq16+PsmXLwtDQEGFhYTh79iyWL1+Ot2/fomfPnrh69So8PT2lssOHD0fnzp0xffp0/PPPP3B2dpaer7yaOnWqNDdJmTJlMGXKFNSoUQPx8fHYvXs3li5ditjYWLRr1w4XL15EtWrVsqzr22+/xdmzZ9GhQwf07dsXbm5uiIiIwLJly7B3714EBwdj3Lhx2LRpU75iLijXr19H+/btkZycDLlcjpEjR+Kzzz6DiYkJrl27hh9++AGPHz/GsmXLYGJigh9//FGt/J49e+Dv7w8AqFq1KoYNGwZPT09YWFjg9evXuHPnDo4cOYKLFy9m2HefPn3w/PlzyOVyfPnll2jTpg0cHR2hVCrx9OlTnD9/Hjt37vwQTwNRkcE2jro9e/ZI3zmqoUWqv9euXYvIyEgcOHAA7dq1y7S8UqnE559/jsOHDwMAKlSogOHDh6NWrVowNjbGixcvcPbs2Sx7L82ZMwczZswAAFhaWmL48OFo3rw5bGxs8Pr1a1y9ehU7duzI0N4pDIMGDcKtW7fQt29fdOvWDY6OjggNDVWb+6og2hGBgYFo3Lix1MumY8eO6N69O8qWLQuFQoGgoCAcOnQow+f34MGDsW3bNrx+/Ro7d+5Ejx49Mj2OqKgoaWhYr169cjV3V2bGjRuHP/74A4mJiRg4cCBOnz6t1p4oDH379sXZs2eRkpKCzZs3Y8SIEZlud+3aNdy5cwcA8MUXX0ijC4C018jb2xufffYZatWqBWdnZwghEBISgp07d2Lr1q14/PgxOnTogOvXr8PQ0LBAjyEuLg5+fn7S3V67deuGfv36wd7eHkFBQVi8eDFWr16N27dvZ1tPfs61uXPnYuLEiRgwYAAuX76c6U1KNJ1Xq1+/ftI5Wa1aNUyYMAGenp6IiYnB5s2bsWbNGjx//hwtW7bEzZs34eLikmVdX375Jc6fP49+/fqha9eu0nttwYIFOHfuHC5evIjvv/8e8+fP1yjG3Lh69ar03L//mTd79mykpKRg06ZNGDlyZJZ1DBkyBH/++ScAwMnJCSNHjkSDBg1gYWGBqKgoXLx4Ue1OmOmlv7mYoaGhWvvt7du3uHnzJnbv3o0HDx4U1CFnacqUKbh58yY+++wz9O/fX2pzq0bfAPn7zaESERGBhg0bSu+JFi1aoF+/fqhUqRJkMhkeP36MY8eOZehVOXjwYCxcuBBKpRLr1q3DtGnTMj2OlJQUbNiwAQCk51JjGqfTqFgAcr6qiv/P/KfvcfM+pVIpHjx4kO2+ZsyYIYC03jtBQUEZ1mtyVVUul2fao+Ply5fCwcFBABBVq1bNNh5N5bXnWGRkpDA2Npaex9DQ0AzbXL16Vbpi4OLiIpKTk9XWu7q6CgCic+fO2e7r5cuXav9ftWqVFHN2PcMSEhJEQkKCBkeV0eDBg6V9WVhYiCtXruSrvpykpqYKJycn6TnL6ir6L7/8IsX1559/qq0LDg4WSqUyy33cvHlTmJqaCgBi+vTpmW6Tn55jS5culdanv0Kf3sCBA7O8gqLy+PHjDOdMemFhYcLFxUUAEL179850G9VVxcyuTL0vu2O+efOm1MPCy8tLvHr1KsM2+/fvl7apU6dOhvXpr2IBEN9//32GbZRKpWjdurV0VSgyMjLHuHMrPz3HateuLQAIXV1dcfDgwQzrY2JiROXKlaUrX7dv31Zb36dPH+l1yKoHihAZ3+sPHz6UYs6uZ5hSqRQxMTEaHRNRUcU2juY+//xzAUC4u7urfT8qFAqp50uXLl2yLJ/+O7djx45Z9lJSKBQZrvxfvXpV+m7w8PAQYWFhWe7n/bZUYfQcAyD++OOPbOsqiHZEjRo1pO+ETZs2ZVlXdHS0WltNoVBIx9KqVassyy1evFg6nqx68eSGQqGQvncBCFdXV/HkyZM815cbr169EgYGBgKAqFevXpbbqXqJABDHjh1TW5fZ+zG9w4cPS+ddVq93fnqOTZw4UVo/b968DOuTk5PVnlcg855jH6LNml52x7xnzx4p1pYtW4qkpKQM2/z+++/SNl27ds2w/v332vr16zNsk5iYKPXqsrGxybHXal6MGTNG6u30frurbt26AoCoXbt2luX/+ecf6Rjq16+fabtX5f3PrefPn0u/Ee3t7bP9rZbZ78fsfmOkl9ueY9mdOyoF8ZsjfY/DH3/8Mcu63rx5k6HNqhpJ5eHhkWW5HTt2SPXv3Lkz2+PJCpNjJVRuG47r1q3L975SU1OFra2tACAWLVqUYb0mDcfx48dnuZ+pU6dKDdTXr1/nO26VvCbHfvzxR6nc5s2bs9zu+++/l7bbunWr2jrV8IJffvlFo33PnTtXABBWVlYaldOEUqmUhtDZ2NgIe3t76e+bN28W2n6FUG9wHD58ONNtatWqJX3pxcXFabwP1RA3Ly+vTNfnJzmmSpI4ODioDQFI782bN8LOzi7PyRoVf39/AUCYm5tn2rgqqOTYsGHDpFjPnz+fZR3pk6kXL15UW5f+i7pmzZpZNgYPHDggbffPP//kGHdu5TU5duHCBanc0KFDs9zu9OnT0nbDhw9XW9eqVSvpR6Umzpw5I9WZ0zBjopKCbRzNREdHS+2Nr7/+OsN61XeuoaFhpj8AFQqFKFWqlAAgSpUqlW2CPzOqoZgymUxcvXpVo7KFkRxr0aKFRjFkJbt2RPppE8aOHatx3bNnz5YSa5n9eBZCCG9vbwFAVK9eXeP6VRITE0WnTp2kdoLqgm7ZsmVzHN6UX507d5aeo8yS1KmpqcLR0VEAEKVLl842gZSVDh06CACiXbt2ma7Pa3IsKSlJWFlZCSAtoZ1VbGFhYWpDiTNLjuVGftus6WV3zG3atBFAWiI/q/NOCCEN0dPT0xPPnz9XW5f+vdapU6cs61ixYkWhtW9SUlKk3y09e/bMsD79Reysht3Wr19f+p3x7NkzjfY/bdo0qf68DFUu6OSYh4eHSE1N1TiO92X3m+PevXvS8NMOHTpoXPfatWuleLMart6+fXsp4ZjXhCon5Kcs6evrZ3kHwqwolUo8f/4c9+/fx+3bt3H79m0EBgaiVKlSAIAbN27kK6bsbs9cs2ZNAIAQAo8fP87XfgrCkSNHAKQND+jUqVOW2w0ePDhDGRUnJycAwJYtWzSalFJV7tWrV/jnn39yXU4Tc+bMkYaIHThwAIcOHYKVlRVevnwJX19f3Lt3L9NykydPhkwmg5GRUa4mnc9Mv379pL8zm6z13r17uHz5MgCoTSiclVevXuHhw4e4c+eOdN5aWloCAO7evVugNxt48eKFdAOFrl27qg0BSM/U1BRdu3bVqO64uDg8fvxY7ThU9avWFRbVuVulSpVs7wr65ZdfZiiTmZ49e2Y5fEb1XgeQYXJmbUh/HIMGDcpyu4YNG0rdzLN6r586dQoPHz7M9b5V5QDkOBk1Ef2HbZz/bNq0SfqeSz+8SEW1LDExMdNJxK9fv46nT58CSPuMVw1LzQ2lUon9+/cDSJs8unr16hrHX9Cyex2yomk7Iv2d8MaOHavx/gYOHAgdHR0olcpMh/NeuXJFusvkwIEDNa5fZdiwYdixYwccHR1x/Phx7Ny5EwYGBnj06BFatGiB8PDwTMt17doVMpkMHh4eed53Tm29w4cPS/vv3bt3jkNuo6Ki8ODBA+n1uX37Nuzs7ADk/737vitXruDVq1cA0o4jq9hKlSqF1q1ba1T3h2yzppeamipN7N+6dWu4urpmua2qrZeamirdYCkzufnMAwq+rXfgwAFERkYCyPwzr1u3bpDL5QAyP/devnyJ8+fPS9tqeodU1fu/bNmy+OyzzzQqWxi6desGXV1djcpo+ptj79690lQF48aN0zjGLl26wMLCAgAyDA0G0oZsqr5L+vTpI91IRFNMjlGWKlSokKvx90IIbNiwAc2bN4epqSlcXFxQqVIleHt7S4/r168DQL7vAFipUqUs11lbW0t/v3nzJl/7KQiqcew1atSQPmAz4+DgIN0p5v15B1QNg7Nnz6JMmTIYOXIkdu7cme0d/wDgs88+k74oO3bsiBYtWuDnn3/GlStXoFAo8nhE/7l27Rpmz54NAJg3bx5q1aqFatWqYd++fTA1NUVkZCRatmyJ4ODgDGVVd2ypUqUKdHTy9hHk5eUlNaB37NiRIXGY/oss/V0q07t16xYGDhwIJycnWFtbo3z58vDy8pLOWdUdYJRKpdTAKQiqxioA1K5dO9tt69Spk2N9ISEhGDVqFNzd3WFhYYGyZcuqHceQIUOkbfP7/stKUlKSNCdCdokxAKhevbr0fshuno2i+F7X19eHj49Pttuqnp8HDx4gOTlZWq6ad+Lly5fw8vJC9+7dsXr16kzfQ+mVKVMGjRs3BgD8/PPPqFKlCmbMmIFjx44V+l2eiIoytnH+o0qu1KhRI9N5YqpVqwYvLy8Amd/B7dq1a9Lfqs+j3Hr8+LF090pNyxaWqlWr5mq7/LQjVM9Z6dKl4ebmpnGMpUqVgp+fH4DML4yofjwaGBjkKdkHpN3xW1XP//73P5QpUwatWrXC5s2boaenh6CgIPj6+mZ63qvaerl9LjPzySefSPNn/fXXXxnW56atd+bMGXTr1g02Njawt7eHh4eH2nt35cqVAAq+fVTQbT1ttVnTe/TokdSuyKmtl379x9jWU33m2dvbo1WrVhnW29raSu+vDRs2SEkdlevXr0vLNP3cSklJkZ6TRo0afZB5FHOS2/dpfn5zqD7z5HI56tWrp3GMRkZG6NmzJ4C0O9ln9ttPdUfn/FwQYHKMsmRlZZXjNomJiWjbti369OmDEydO4N27d9lun9P6nGTVywaAWqKlIBJA+aWa2DY3k7mrJgx8fwL2b7/9FgMHDoRMJkNkZCSWLVuGTp06wd7eHl5eXpg5cyYiIiIy1GdjY4Pdu3fDxcUFQggcP34c48ePR61atWBtbY1OnTqpXbXUlL+/P5RKJaytrdVuJV6vXj38888/MDQ0lCbjDAkJUSt75swZAMhw8wFNqZIJb9++VbuxgBBCakQ5OTll+qW3atUq1KhRA6tXr87yqmd6+T1v00v/Gud0bjg4OGS7fv/+/ahcuTKWLl2a4XnOTEEeR3rpG2I5HZPq9uNAxvM9vaL4Xre2ts7xSpXqvS6EUHveWrZsiaVLl8LIyAiJiYnYsmULBg4ciAoVKqBUqVIYOnRolle2N23ahPr16wNIu2o8Z84ctGzZEpaWlmjSpAlWrFiBxMTEgjhUomKDbZw0gYGBUk/rzHpQqKiSD2fOnMnQIyD9j6D0vVlzIz9lC0tuzo38tiNUx52fY1aNPHj48CFOnTolLU9KSpJuXNShQ4dcHU9mFi9eDCDtgmT63i0dOnTA6tWrIZPJcOfOHfj6+qp9nyUlJUnnVH7aenp6etLNBh4+fIizZ89K69K3/WrXrp1pkmXWrFlo1KgRtm7dmuMNjgq6fVSQbT1ttlnT0+SY0k+E/rG19V6/fo1///0XANC9e/cs222qz7zQ0NAMvd/y87kVExMjJdaK0mdefn9zqJ4za2trjW8CoaL6zHvz5k2GGx2oEvl169ZF5cqV81Q/wOQYZSM33Svnzp0rdWFs2rQptm7diuDgYLx9+xYKhQIibV47Kav+fua9JMjPFQG5XI5Vq1bh9u3bmD59Oho0aCB9oNy5cwffffcdypcvn+nQycaNGyM4OBgbNmxAz549pWEfcXFx2LlzJ9q3b49PPvkkT71LVHfQrF+/foYPuBYtWmDr1q3Q09NDaGgoWrRogWfPngEAzp07h8ePH0Mmk+X5SqZKz549pS+09FcPT506JX1o9+zZM8N5fO/ePQwdOhSpqamwt7fHwoULceXKFbx8+RLJycnSObtq1SqpTGGdt/k5N6Kjo9GzZ08kJCTA1NQUs2bNwrlz5xAZGYmkpCTpOI4ePSqV+RDvv4/hCpi25PfYR4wYgSdPnuDnn3/Gp59+KnUff/bsGf73v/+hevXqmD59eoZyLi4uOHv2LI4cOYLhw4ejSpUqkMlkSElJQUBAAIYNGwYvLy8EBQXlKz6i4oRtnDTpe4KNHz8eMpks08eUKVMApB1jZr3HipOczo2PpR3Rvn17KbGSfpjRrl27pGRVXntQKBQKnDt3DkDauf++3r17S3envnHjBvz8/KQ72+3YsQOJiYkwMTFBx44d87R/FdWFUEC9rff3339L7df026gcPXpUGuFQtmxZLF++HDdv3sTr16+RkpIivUbffvttvuLLjfy0DT6Wc+19Rbmtt2XLFiQlJQEAlixZkuVnXrdu3aQyJf0z72P5zVGjRg1p5FD6z7wLFy5IU9bkp9cYwOQY5YMQAn/88QeAtETMsWPH0KVLF5QrVw4mJiZqGf+crtgUR6ruwJn17Hqf6kpQ+i7E6VWuXBlz5szBmTNnEBsbi8OHD2PAgAHQ1dXF27dv0aNHD6kLe3qGhobo1asX/vrrL4SFheHRo0f49ddfpTkgDh48iG+++UbjY1Mlu7KaV6R9+/ZYt24ddHR01Oal+P777wEAnTt3RsWKFTXeb3r29vZSl+fDhw9Lz3P6xlNmDaY1a9YgNTUVurq6OHnyJCZOnIgaNWrA2tpabfhrYZ2z6a/O5HRuZLd++/bt0lCUnTt3YubMmahXrx7s7OzUEpYf4r2nyTGlpqbi5cuXALI+34sa1XG8fPlS6tKdFdV7XSaTZXqlzt7eHmPHjsXevXsRExODK1euYPr06bC0tIQQAnPnzs1yHsGWLVti2bJluH37NqKiorB582a0aNECQNpV9/QNPSLKXklo4yiVykyHq+Xk/Tl4bG1tpb8za4tkJz9lAfXeJTnNYxofH69x/ZkpiHaE6rjzcswqcrlcauds27YNb9++BfDfj8bSpUvD19c3T3VHRkZKc1dl1dYbNmwYfvjhBwDApUuX0KZNG8TGxkrLhg8fnudeayo1atRAlSpVAKQNpVJNR6A6B+VyudS7LD3VcEkrKyucP38ew4YNg7e3NywsLNR6Cn3sbT1tt1nTS99my+mY0vdw+9jaenlJdKVPxgL5+9yytraWPrfy+v5XJSc/1GdeQfzmUD1nMTExatOKaErVe+zkyZNSL2bVZ56xsTG6d++e57oBJscoH2JiYqQPvy5dumQ5f9Tbt29x//79DxnaR0E1P8fVq1ez/cEcGRkp9XRSlcmOoaEhfH198eeff2LhwoUA0rqu5maYpGreskuXLkk9ybZu3ZpjufephsUFBgZmuU2PHj2wYsUKAEBQUBBq1KiBffv2wcjICPPmzdN4n5lRNQoVCgU2bdqExMREqZtttWrVMh1Df+fOHWl9dnMdqIYEFDRvb2/p70uXLmW7bXbrVcdhbW2dbeM3p+MoiKt/BgYGqFChAoC0qzfZuXbtmtTgzs35XhSojiM5OVmaeygrFy9eBJA231FO3cp1dHRQo0YNzJkzR+1qXG7eszY2NujWrRuOHj0qDYe5fv26NDccEWWvJLRxjh8/jrCwMADAqFGjsGnTpmwfqonjHz58KE2RAKQlMFTSD+/LjTJlykhzpGpaFoDaDXeym2spJiZGujCTXwXRjlA9Z6GhobkaopQV1Q/F+Ph4bNu2DU+fPsXhw4cBpM1bm9e5Xa2traX2QXZtvSlTpuDrr78GkDY/rqenJ27evAkHBwdMnTo1T/t+n6qtFxMTg3379uHZs2c4fvw4gLRhm6o2aXqq16h58+bSpPuZKSptvfy2WQuirVe2bFlpGGRObT1VWwf4uNp66Yfndu/ePcfPvLlz5wJIG8a3c+dOqZ7q1atLz6mmn1tyuVx6TgICAvLUw0r1uZfdZ54QIsd5a3OrIH5zqD7zUlJSpF6pedGrVy8YGRlBCIE1a9bg3bt32Lx5MwDgiy++gLm5eZ7rBpgco3xIn/DJLjP9xx9/5NibojhSfXi8fv0aO3bsyHK7VatWSR+Mml7ha9mypfS3JpOJmpubSxOE5mUS0kaNGgEAbt68me1daL788kssWrQIwH9XR2bMmIHy5ctrvM/MpL/xwPr167F7927ExsYCyLzXGPDfeZvdOfvixQvs3r27QGJ8n7OzszTh8bZt27KcGyI+Pj7bJIjqOBITE7O8cpSQkJDpXXbSU01Irepinleqc/fOnTtqjaL3qXpipC9T1KU/jj///DPL7c6dOyd1+9b02GvUqCFdidb0PZvXzwmikqwktHFUPSh0dXUxffp0dO/ePdvHN998I/W6Sd/7olq1atKd6/744w+pB1Nu6OjooG3btgDSegKkn9w/N6ysrKR2QHY/zDZv3lxgw3wKoh3Rvn176e+ff/45z7F4eHhIw3pXr16NtWvXQqlUQiaTYcCAAXmu18DAALVq1QKQNtdQdhdW5s6di1GjRgH4r63n7+9fYD2GevfuLSX51q9fj7/++ktq9+SnrXft2rUckzx5VbNmTek7e/369Vmee8+ePcOhQ4eyrKeg2qwF0dbT09OThtgePnxYukNtZlRtPT09PTRr1izP+yxo6T+3Jk6cmONn3uTJk6Xka/qy1tbWaNCgAYC0C5bPnz/XKA7V+//x48dZjgbITpkyZQBk/5m3f/9+qbdXfhXEb462bdtKCUV/f/88x2JhYYHOnTsDSLuxwvbt26XffvkdUgkwOUb5YGdnJzVINm3alOkH7qVLlz7IeP6P0YABA6QrLBMmTJCGIqZ348YNqReVi4sLOnToIK2LiYnBv//+m21jLv0XquqDEkgbLpldV93Y2FgpgZG+XG6pGkFAWg+x9HfleZ+Dg4NaD5lt27YV2F1nDA0N0aVLFwBpPfS+++47AGkN/azmNFP1cHrw4IHa5K4qCQkJ6NmzZ6FNaAqkDUUA0rqdT5gwIdNtxo0bJ91mOjOq40hISMg0iaZQKDB48OAcv7BVk4FGRkbm63UZNmyY1HgdMmSINPdIeocOHZLmxahTp06Od3AqKurUqSP9iFi5cqVaLy+V2NhYfPXVVwDSfgyqzgGVLVu2ZHvOXb58WbpCmP49e/369Wx7qwkhcOTIEQBpV45Vd8YlouwV9zZOfHy8dOGucePGubp5kK2trfTjeOvWrdJzoqOjg0mTJgEAnj59ir59+2Y5bEapVGb4Xpo4cSJ0dHQghED37t2z/dGd2bomTZoASLu74sOHDzOsv3//foG+TgXRjvD19UXNmjUBAL/++qvU8yEzL1++zLYuVe+xgIAA/PrrrwCAZs2a5al9l97o0aMBpPX0+PzzzxEaGprpdkqlMsMdN9PfOS6/nJ2dpYs8e/bskYZMWltbo127dpmWUb1Gp0+fzrT3TFRUVJZ3uCwIBgYGUnLy+vXr0kiP9FJTU/Hll19mO8SsoNqsqrbeo0eP8pUkHjFiBIC0nvKDBg2SRgKk9+eff0q/Tzp16vTRTDqvuvMwALi7u0vvv+zo6elJv82OHj2q9ttKNQ9jQkICunTpIiVoMvP+59bIkSNhYmICAPjqq6+yvaNnZp95qs/hCxcuqPXiVQkPD1f7rZZfBfGbw8PDQ5qDcNeuXZm+J1Ti4+Oz7RWn+swLCQnB5MmTAQDlypXLdH5EjQkqkQAIAKJp06YZ1jVt2jTLde8bMWKEVFetWrXExo0bxaVLl8SRI0fE+PHjhaGhobC1tRUeHh5Z1vn48WOpjtWrV2dYP3PmTGl9do4fPy5td/z48Rxjzy3V86GKL6fHP//8I5VdtmyZVNbBwUH8/PPP4sKFC+LMmTNi9uzZwtTUVAAQMplM7N27V22/qufF3d1djB8/XmzZskWcP39eXL58Wfz7779iyJAhQkdHRwAQLi4u4s2bN1LZfv36CblcLj799FPh7+8vjhw5Iq5evSpOnjwpli1bJjw9PaW4fv755zw9LxMmTJDqMDQ0FEOHDhV79uwRV69eFadOnRJLliwRtWvXlrYpX7689Levr69ISkrK037fFxAQINWrerRp0ybL7S9evChtZ2lpKebOnStOnjwpLly4IJYvXy4qVKggAIiGDRtK2z1+/DhDPTm9T1RlZ86cmWFdSkqKqF69urTNJ598Inbt2iWuXLkidu3aJVq3bi29p7I6p8PCwoSBgYH0/E+ZMkUcOXJEXLp0SaxZs0bUrFkzw3Fk9r44fPiwtL5nz57i3Llz4sGDB9JDk2OeNGmSVFe5cuXE77//Li5duiROnDghJkyYIORyuQAg9PX1xbVr1zKU1+Q9nN3zm1fpP2umTJmSq/e76jy+du2a0NfXl45vwoQJ4sSJE+LSpUvi999/F2XLlpXqnjx5coZ9u7m5CUtLS9GvXz+xatUqERAQIK5evSoOHz4sZs6cKaytrQUAoaurKy5duiSVW716tQAgateuLb777juxZ88ecfnyZXHu3DmxceNG0apVK2m/n3/+eYE9V0QfM7ZxcrZu3Tqpvl9//TXX5ZYvXy6V27p1q7RcoVCofd54eHgIf39/cfr0aXH16lWxb98+MWPGDFGhQoVMP7fnzJmj9t38zTffiCNHjohr166J48ePi59//lk0btxYNGvWLEPZAwcOSGVLlSol/vjjD3HlyhVx8uRJMWPGDGFhYSHKly8v7OzsBADRr1+/DHWoPkuz+s5Pr6DaEXfv3pXagQBEp06dxNatW8Xly5fFhQsXxF9//SX69esnTExMso0pISFBWFhYqLWD1q9fn+0x5IZSqRSdO3eW6rSwsBCTJk0Shw4dkl6XH3/8UVSqVCnTtl5mz3NerV+/PkNbb9iwYVluv23bNmk7Z2dnsWTJEnHmzBlx5swZsXDhQuHk5CRkMpmoX79+tu8/Nze3LI8lp/f269evRalSpaRtevToIfbv3y+uXLkiNm3aJLWR07f13n+dC+pcW7lypbR+7Nix4vLly1I778mTJ7k+ZiGE6NKli1RXjRo1xIYNG8Tly5fF4cOHxaBBg4RMJhMAhLW1tXj69GmG8rl9r+X0/Grq1KlTUn0TJkzIdbl9+/ZJ5RYsWKC2btCgQWrn2bx588TJkyfFtWvXxOHDh8X8+fOFj49Pps9l+s9gIyMjMXr0aLF//35x7do1ERAQIH777TfRpk0bUbZs2Qxlb9++LfT09AQAYWVlJX7++Wdx6dIlcebMGbFgwQLh6OgobGxspPMjs+8mTb5TCuo3R3h4uHB2dpa2adGihVi3bp24ePGiuHTpkti2bZsYPny4sLa2zjEm1feu6jFnzpxst88tJsdKqIJqOL5+/Vr4+Phk+MJSPaytrcXJkyezrfNjbTiqpE+O5eZRrVo1tfJz586VkliZPQwMDMTatWsz7Df985Ldw8nJSVy+fFmtbL9+/XJVdujQoUKhUOTpeVEqlWLOnDnSh3NWDxMTEzF37lyRmpoq+vbtq9ZIUCqVedr3+9InHgCITZs2Zbv97Nmzs415woQJOX555yc5JoQQz549ExUrVswyhtatW4uDBw9me07/+eef2Z5b3bp1E0eOHMm2DoVCIerVq5dlHZocs0KhEMOHD8/2ubWwsBAHDx7MtPzHlBzL7ePVq1dS+YMHDwpzc/Nstx8xYkSm7zlVYzS7h4GBQYbPyPTnaXaPBg0aiOjo6AJ7rog+Zqrznm2crPn6+gog7eLcs2fPcl0uPDxc+t5p166d2rr4+Hi1ZEpWj6w+t+fOnZtjmyKr12306NFZlildurS4e/dutj/6NUmOCVEw7QghhLh8+bJwdXXN8TnLKaZhw4apfc8mJCTkeAy5kZSUpJYkzu69sHLlSpGSkiJatGghLZ8yZUqBxBEfH6+WSAQgzp07l22ZAQMGZBmvrq6u8Pf3z/H9l5/kmBBpSQxHR8cs4+jfv3+O50lBnGtv3rzJ0FZWPdzc3HJ9zEII8e7dO9GxY8dsY3J2ds70IqgQ2kuODR48ONfnTnrJycnC0tJSABDe3t5q61JTU8XIkSOlhGBWj6yeyzVr1ggjI6Nsy77/+qgsXrw42/fjqVOnsv1u0vQ7pSB+cwghxMOHD4WXl1eOnyk5xfTjjz9K2+ro6IiwsLAcjyE3mBwroVQnU34bjkKkfWHNmTNHeHt7C0NDQ2Fqaio8PT3FxIkTpRO1KDYcVfKbHBNCiBs3bogvv/xSlCtXThgZGQkTExPh6ekpxowZk+UXg1KpFBcvXhSzZs0SrVu3FhUrVhSWlpZCT09P2NraiiZNmoiFCxeK2NjYDGVjYmLEhg0bxMCBA0WtWrWEi4uL0NfXF0ZGRsLDw0P069dPBAQEFMjz8/DhQzFp0iRRo0YNKT57e3vRtGlTMW/ePBEVFSVtm5iYKOrWrSs9V2PHji2QGGbNmiXVaW5unqtG4d69e0Xr1q2FlZWV0NfXF6VKlRKdOnUShw4dEkLk/OWd3+SYEGlXe7///nvh5eUljIyMhKWlpahXr55Yvny5UCgUuTqnz5w5Izp06CDs7OyEXC4XTk5O4pNPPhFbtmwRQuTufREXFyemT58uqlWrJkxNTdW+5DU5ZpVTp06JXr16idKlSwsDAwNhbm4ufHx8xNdffy0iIyOzLFfUk2NCCBEZGSm+/vpr4ePjI8zNzYWBgYEoXbq06NWrV7bvuUePHolffvlFfPHFF8Lb21vY2dkJPT09YW5uLqpXry4mTpwoHj58mKFcYmKi2Ldvnxg3bpxo1KiRKFOmjDA2NpbO6c8++0z89ddfeU6CExVFbONk7+nTp9KPnAYNGmhcvnHjxgKA0NPTy/Qz/dixY6JPnz6iTJkywsjISOjr6wtXV1fRvn178b///U/ExcVlWXdQUJAYO3as8PLyEubm5kJPT0/Y2dmJpk2biu+//16EhoZmWXbjxo2iSZMmwtzcXBgZGYmKFSuKqVOnShcGCjI5JkT+2xEqCQkJYsmSJaJFixbC3t5e6OnpCVNTU+Ht7S2GDBkijh49mmMsZ8+elfb11Vdf5Sp+Tdy8eVOMGDFCeHl5CTMzM6Gvry+cnZ2Fn5+f+OWXX9RGL0RHR6slYvz9/Qskhv79+0t1VqhQIVdl1q9fLxo3bizMzMyEgYGBcHNzE3369BEXLlwQQuT8/stvckwIIV6+fCkmT54sKlSoIAwMDIStra1o3ry52LhxoxAid+dJQZxr4eHhYsyYMcLT01MYGxtnmXzJKTmmsnv3btGpUyfh7Ows9PX1hZWVlahbt66YP3++2vnwPm0kx969eyf1rnRxcdH44nyfPn2kWK5evZph/ZUrV8SQIUOEh4eHMDExEXK5XDg6OorWrVuLxYsXq/0Wet/z58/FN998I2rWrCksLS2Frq6usLKyEvXq1RNff/21CAwMzLLsgQMHhJ+fn7CyshIGBgaiTJkyYsSIESIkJEQIkf13U16+UwriN4cQaUnFNWvWiLZt2wonJychl8ul36h9+/YV//zzj0hNTc02lufPn0v78vPzy1X8uSETooBmpyQiIiIiIqIPauXKlRgyZAiAtHmI6tSpo+WIiIgKz+HDh9G6dWsAafP2du3atUDq5YT8RERERERERZTqTsleXl5MjBFRsaf6zLOxscHnn39eYPUyOUZERERERFQEnTp1CufPnwcADB06VMvREBEVrocPH2L79u0AgAEDBsDAwKDA6uawSiIiIiIioiIiJCQESUlJuHPnDsaNG4eQkBA4Ojri0aNHMDIy0nZ4REQF6tmzZ0hISMCjR48wZcoU3LhxA4aGhnj48CGcnZ0LbD96BVYT0Ufo2bNnePXqlcblTExMUKZMmUKIiIgKw+vXr/H06dM8lfXy8irgaIiICh/bOCVX06ZNERISorbs119/ZWKMirXIyEhERkZqXE5fXx8eHh6FEBF9KL169cLJkyfVls2ZM6dAE2MAk2NUzH3zzTdYu3atxuWaNm2KEydOFHxARFQodu3ahQEDBuSpLDtQE1FRxDYOmZmZwcvLC9988w3atm2r7XCICtXy5csxe/Zsjcu5ubnhyZMnBR8QfXDGxsbw8PDA2LFj0a9fvwKvn8kxIiIiIiKiIoI/9ImoJPlQF3SKzZxjSqUSz58/h5mZGWQymbbDISIioiJACIE3b97A2dkZOjq8T9HHiu08IiIi0pQm7bxi03Ps+fPncHV11XYYREREVASFhYWhVKlS2g6DssB2HhEREeVVbtp5xSY5ZmZmBiDtoM3NzbUcDRERERUFcXFxcHV1ldoR9HFiO4+IiIg0pUk7r9gkx1Rd7M3NzdloIiIiIo1wqN7Hje08IiIiyqvctPM4uQYREREREREREZVYTI4REREREREREVGJxeQYERERERERERGVWMVmzjEiIiqaFAoFUlJStB0GFVNyuRy6urraDoOIiIiIPmJMjhERkVYIIRAeHo7Xr19rOxQq5iwtLeHo6MhJ94mIiIgoU0yOERGRVqgSY/b29jA2NmbiggqcEAIJCQmIjIwEADg5OWk5IiIiIiL6GDE5RkREH5xCoZASYzY2NtoOh4oxIyMjAEBkZCTs7e05xJKIiIiIMuCE/ERE9MGp5hgzNjbWciRUEqjOM85tR0RERESZYXKMiIi0hkMp6UPgeUZERERE2WFyjIiIiIiIiIiISiwmx4iIiLTI3d0d/v7+2g6DiIiIiKjEYnKMiIgoF2QyWbaPWbNm5aneS5cuYciQIQUS45MnTyCTyXD9+vUCqY+IiIiIqCTg3SqJiIhy4cWLF9LfW7ZswYwZM3D//n1pmampqfS3EAIKhQJ6ejl/zdrZ2RVsoEREREREpBH2HCMiIsoFR0dH6WFhYQGZTCb9/969ezAzM8P+/ftRs2ZNGBgY4PTp03j48CE+//xzODg4wNTUFLVr18aRI0fU6n1/WKVMJsMff/yBjh07wtjYGBUqVMDu3bsL5BiSkpIwevRo2Nvbw9DQEI0aNcKlS5ek9a9evUKvXr1gZ2cHIyMjVKhQAatXrwYAJCcnY+TIkXBycoKhoSHc3Nwwf/78AomLiIiIiEib2HOMiIi0TgiBdykKrezbSK5bYHcznDp1KhYtWoSyZcvCysoKYWFh+PTTTzF37lwYGBhg3bp1aN++Pe7fv4/SpUtnWc/s2bOxYMECLFy4EL/++it69eqFkJAQWFtb5yu+yZMn4++//8batWvh5uaGBQsWwM/PD8HBwbC2tsa3336Lu3fvYv/+/bC1tUVwcDDevXsHAFiyZAl2796NrVu3onTp0ggLC0NYWFi+4iEiIiIi+hgwOUZERFr3LkWByjMOamXfd7/zg7F+wXwdfvfdd2jVqpX0f2tra1SrVk36/5w5c7Bz507s3r0bI0eOzLKe/v37o0ePHgCAefPmYcmSJbh48SI++eSTPMcWHx+P3377DWvWrEGbNm0AACtXrsThw4exatUqTJo0CaGhoahevTpq1aoFIK1Xm0poaCgqVKiARo0aQSaTwc3NLc+xEBERERF9TDiskoiIqICokkoqb9++xcSJE+Hp6QlLS0uYmpoiMDAQoaGh2dZTtWpV6W8TExOYm5sjMjIyX7E9fPgQKSkpaNiwobRMLpejTp06CAwMBAAMGzYMmzdvho+PDyZPnoyzZ89K2/bv3x/Xr19HxYoVMXr0aBw6dChf8dDHa9myZXB3d4ehoSHq1q2LixcvZrlts2bNMr1BRdu2baVt3r59i5EjR6JUqVIwMjJC5cqVsWLFig9xKERERES5wp5jRESkdUZyXdz9zk9r+y4oJiYmav+fOHEiDh8+jEWLFqF8+fIwMjJC586dkZycnG09crlc7f8ymQxKpbLA4sxKmzZtEBISgn379uHw4cNo2bIlRowYgUWLFqFGjRp4/Pgx9u/fjyNHjqBr167w9fXF9u3bCz0u+nC2bNmC8ePHY8WKFahbty78/f3h5+eH+/fvw97ePsP2O3bsUDufX758iWrVqqFLly7SsvHjx+PYsWPYsGED3N3dcejQIQwfPhzOzs747LPPPshxEREREWWHPceIiEjrZDIZjPX1tPIoqPnGMnPmzBn0798fHTt2hLe3NxwdHfHkyZNC2192ypUrB319fZw5c0ZalpKSgkuXLqFy5crSMjs7O/Tr1w8bNmyAv78/fv/9d2mdubk5unXrhpUrV2LLli34+++/ERMT80GPgwrX4sWL8eWXX2LAgAFSDy9jY2P8+eefmW5vbW2tdrOKw4cPw9jYWC05dvbsWfTr1w/NmjWDu7s7hgwZgmrVqmXbI42IiIjoQ2LPMSIiokJSoUIF7NixA+3bt4dMJsO33377QXqA3b9/P8OyKlWqYNiwYZg0aRKsra1RunRpLFiwAAkJCRg0aBAAYMaMGahZsyaqVKmCpKQk7NmzB56engDSkiZOTk6oXr06dHR0sG3bNjg6OsLS0rLQj4c+jOTkZFy5cgXTpk2Tluno6MDX1xfnzp3LVR2rVq1C9+7d1XpRNmjQALt378bAgQPh7OyMEydOICgoCD///HOW9SQlJSEpKUn6f1xcXB6OiIiIiCh3mBwjIiIqJIsXL8bAgQPRoEED2NraYsqUKR/kR3737t0zLAsLC8MPP/wApVKJPn364M2bN6hVqxYOHjwIKysrAIC+vj6mTZuGJ0+ewMjICI0bN8bmzZsBAGZmZliwYAEePHgAXV1d1K5dG/v27YOODjuhFxfR0dFQKBRwcHBQW+7g4IB79+7lWP7ixYu4ffs2Vq1apbb8119/xZAhQ1CqVCno6elBR0cHK1euRJMmTbKsa/78+Zg9e3beDoSIiIhIQzIhhNB2EAUhLi4OFhYWiI2Nhbm5ubbDISKibCQmJuLx48coU6YMDA0NtR0OFXPZnW9sP/zn+fPncHFxwdmzZ1G/fn1p+eTJk3Hy5ElcuHAh2/JfffUVzp07h5s3b6otX7RoEVauXIlFixbBzc0Np06dwrRp07Bz5074+vpmWldmPcdcXV35OhEREVGuadLOY88xIiIiIoKtrS10dXURERGhtjwiIgKOjo7Zlo2Pj8fmzZvx3XffqS1/9+4dvv76a+zcuVO6g2XVqlVx/fp1LFq0KMvkmIGBAQwMDPJxNERERES5x7EQRERERcTQoUNhamqa6WPo0KHaDo+KOH19fdSsWRNHjx6VlimVShw9elStJ1lmtm3bhqSkJPTu3VtteUpKClJSUjIMv9XV1f0g8+8RERER5QZ7jhERERUR3333HSZOnJjpOg41o4Iwfvx49OvXD7Vq1UKdOnXg7++P+Ph4DBgwAADQt29fuLi4YP78+WrlVq1ahQ4dOsDGxkZtubm5OZo2bYpJkybByMgIbm5uOHnyJNatW4fFixd/sOMiIiIiyg6TY0REREWEvb097O3ttR0GFWPdunVDVFQUZsyYgfDwcPj4+ODAgQPSJP2hoaEZeoHdv38fp0+fxqFDhzKtc/PmzZg2bRp69eqFmJgYuLm5Ye7cueztSERERB8NTshPREQfHCfkpw+JE/IXfXydiIiISFOatB845xgREREREREREZVYTI4REREREREREVGJxeQYERERERERERGVWJyQP5eSU5XQ12MukYiIiKhYEQJISdB2FERERCWX3BiQybQaApNjufAg4g16rLyA0S3Lo2ed0tDTZZKMiIg016xZM/j4+MDf3x8A4O7ujrFjx2Ls2LFZlpHJZNi5cyc6dOiQr30XVD1ExU5KAjDPWdtREBERlVxfPwf0TbQaArM8ubD23BNEv03CjH/u4JNfAnD8fqS2QyIiog+sffv2+OSTTzJdFxAQAJlMhps3b2pU56VLlzBkyJCCCE8ya9Ys+Pj4ZFj+4sULtGnTpkD3lZ1mzZplm/QjIiIiIvpYsOdYLsxqXwUVHc2x+NB9BEe+xYDVl9DEww7T23rCw8FM2+EREdEHMGjQIHzxxRd4+vQpSpUqpbZu9erVqFWrFqpWrapRnXZ2dgUZYrYcHR0/2L6IihS5cdoVayIiItIOubG2I2ByLDf0dHXQp54bPqvmjKXHHmDN2Sc4FRSFNsHR6FHHFeN8PWBjaqDtMImIqBC1a9cOdnZ2WLNmDaZPny4tf/v2LbZt24apU6eiR48eOHXqFF69eoVy5crh66+/Ro8ePbKs8/1hlQ8ePMCgQYNw8eJFlC1bFr/88kuGMlOmTMHOnTvx9OlTODo6olevXpgxYwbkcjnWrFmD2bNnA0gbRgmkJe769++fYVjlrVu3MGbMGJw7dw7Gxsb44osvsHjxYpiamgIA+vfvj9evX6NRo0b46aefkJycjO7du8Pf3x9yuTzfz+fff/+NGTNmIDg4GE5OThg1ahQmTJggrV++fDl+/vlnhIWFwcLCAo0bN8b27dsBANu3b8fs2bMRHBwMY2NjVK9eHf/88w9MTLTbHZ+KKJlM60M5iIiISLuYHNOAhZEc37StjF513TB/fyAO3onAhvOh+Of6c4xuUQF9G7jBQE9X22ESERU92pwQO5cTgOrp6aFv375Ys2YNvvnmGyn5tG3bNigUCvTu3Rvbtm3DlClTYG5ujr1796JPnz4oV64c6tSpk2P9SqUSnTp1goODAy5cuIDY2NhMhyWamZlhzZo1cHZ2xq1bt/Dll1/CzMwMkydPRrdu3XD79m0cOHAAR44cAQBYWFhkqCM+Ph5+fn6oX78+Ll26hMjISAwePBgjR47EmjVrpO2OHz8OJycnHD9+HMHBwejWrRt8fHzw5Zdf5ng82bly5Qq6du2KWbNmoVu3bjh79iyGDx8OGxsb9O/fH5cvX8bo0aOxfv16NGjQADExMQgICACQNjy0R48eWLBgATp27Ig3b94gICAAQoh8xUREREREJReTY3ngbmuC//WphXMPX+L7vXdx53kc5u4LxIYLIZjWxhN+VRykH01ERJQL2pwQW4MJQAcOHIiFCxfi5MmTaNasGYC0nllffPEF3NzcMHHiRGnbUaNG4eDBg9i6dWuukmNHjhzBvXv3cPDgQTg7pz0X8+bNyzBPWPpea+7u7pg4cSI2b96MyZMnw8jICKamptDT08t2GOXGjRuRmJiIdevWSb2tli5divbt2+PHH3+Eg4MDAMDKygpLly6Frq4uKlWqhLZt2+Lo0aP5To4tXrwYLVu2xLfffgsA8PDwwN27d7Fw4UL0798foaGhMDExQbt27WBmZgY3NzdUr14dQFpyLDU1FZ06dYKbmxsAwNvbO1/xEBEREVHJxgn586F+ORvsHtkICzpXhZ2ZAUJeJmDohivosfI8bj+L1XZ4RERUwCpVqoQGDRrgzz//BAAEBwcjICAAgwYNgkKhwJw5c+Dt7Q1ra2uYmpri4MGDCA0NzVXdgYGBcHV1lRJjAFC/fv0M223ZsgUNGzaEo6MjTE1NMX369FzvI/2+qlWrpjYMsWHDhlAqlbh//760rEqVKtDV/a9HtJOTEyIj839TmsDAQDRs2FBtWcOGDfHgwQMoFAq0atUKbm5uKFu2LPr06YO//voLCQlpPQurVauGli1bwtvbG126dMHKlSvx6tWrfMdERERERCUXe47lk66ODF1rueJTbyesOPEQKwMe4fyjGLRfehqda5TCJL+KsDc31HaYREQfN21OiK3hBKCDBg3CqFGjsGzZMqxevRrlypVD06ZN8eOPP+KXX36Bv78/vL29YWJigrFjxyI5ObnAQj137hx69eqF2bNnw8/PDxYWFti8eTN++umnAttHeu/PLSaTyaBUKgtlX+mZmZnh6tWrOHHiBA4dOoQZM2Zg1qxZuHTpEiwtLXH48GGcPXsWhw4dwq+//opvvvkGFy5cQJkyZQo9NiIiIiIqfthzrICYGuhhol9FHJvYDJ9Vc4YQwLYrT9Fs0QksPfYAiSkKbYdIRPTxUk2IrY2HhsPgu3btCh0dHWzcuBHr1q3DwIEDIZPJcObMGXz++efo3bs3qlWrhrJlyyIoKCjX9Xp6eiIsLAwvXryQlp0/f15tm7Nnz8LNzQ3ffPMNatWqhQoVKiAkJERtG319fSgU2X/neHp64saNG4iPj5eWnTlzBjo6OqhYsWKuY84rT09PnDlzRm3ZmTNn4OHhIfVU09PTg6+vLxYsWICbN2/iyZMnOHbsGIC0JF3Dhg0xe/ZsXLt2Dfr6+ti5c2ehx01ERERExROTYwXMxdIIS3pUx47hDeDjaomEZAUWHQpCy59O4p/rzzhhMBFREWdqaopu3bph2rRpePHiBfr37w8AqFChgtSjKTAwEF999RUiIiJyXa+vry88PDzQr18/3LhxAwEBAfjmm2/UtqlQoQJCQ0OxefNmPHz4EEuWLMmQFHJ3d8fjx49x/fp1REdHIykpKcO+evXqBUNDQ/Tr1w+3b9/G8ePHMWrUKPTp00eab6wgREVF4fr162qPiIgITJgwAUePHsWcOXMQFBSEtWvXYunSpdKcbXv27MGSJUtw/fp1hISEYN26dVAqlahYsSIuXLiAefPm4fLlywgNDcWOHTsQFRUFT0/PAoubiIiIiEoWJscKSY3SVtg5vAF+6e4DZwtDPHv9DmM2X0en387iaijnRiEiKsoGDRqEV69ewc/PT5ojbPr06ahRowb8/PzQrFkzODo6okOHDrmuU0dHBzt37sS7d+9Qp04dDB48GHPnzlXb5rPPPsO4ceMwcuRI+Pj44OzZs9Kk9ipffPEFPvnkEzRv3hx2dnbYtGlThn0ZGxvj4MGDiImJQe3atdG5c2e0bNkSS5cu1fzJyMbGjRtRvXp1tcfKlStRo0YNbN26FZs3b4aXlxdmzJiB7777Tko0WlpaYseOHWjRogU8PT2xYsUKbNq0CVWqVIG5uTlOnTqFTz/9FB4eHpg+fTp++umnDDcuICIiIiLKLZkoJl2Z4uLiYGFhgdjYWJibm2s7HDWJKQqsPPUIv518iITktKEun1VzxpQ2leBiaaTl6IiIPrzExEQ8fvwYZcqUgaEh52WkwpXd+fYxtx/oP3ydiIiISFOatB/Yc+wDMJTrYlTLCjg+sRm61CwFmQzYfeM5Wiw6gZ8O3Ud8Uqq2QyQiIiIiIiIiKpGYHPuAHMwNsbBLNfw7shHqlrFGUqoSvx4LRvNFJ7D1chiUymLRiY+IiIq5gIAAmJqaZvkgIiIiIipK9LQdQEnk5WKBzUPq4eCdcMzbdw+hMQmYvP0m1p59gm/bVUa9sjbaDpGIiChLtWrVwvXr17UdBhERERFRgWByTEtkMhk+8XJC80r2WHv2CX49Gow7z+PQ/ffz8KvigK8/9YSbjYm2wyQiIsrAyMgI5cuX13YYREREREQFgsMqtcxATxdDmpTDiUnN0LteaejIgIN3IuC7+CTm7r2L2Hcp2g6RiIiIiIiIiKjYYnLsI2FjaoDvO3jjwNgmaOJhhxSFwMqAx2i+6ATWnw9BqkKp7RCJiApcMblhMn3keJ4RERERUXaYHPvIeDiYYd3AOlg9oDbK25siJj4Z3+66jU+XBOBkUJS2wyMiKhByuRwAkJCQoOVIqCRQnWeq846IiIiIKD3OOfaRal7RHo3K22LjhVD8fCQIQRFv0e/Pi2hW0Q7T23qivL2ZtkMkIsozXV1dWFpaIjIyEgBgbGwMmUym5aiouBFCICEhAZGRkbC0tISurq62QyIiIiKijxCTYx8xua4O+jVwRwcfFyw59gBrzz7BiftRCHgQjV51S2OsrwesTfS1HSYRUZ44OjoCgJQgIyoslpaW0vlGRERERPQ+mSgmE3HExcXBwsICsbGxMDc313Y4heJxdDzm7QvE4bsRAABzQz2MblkBfeu7Q1+PI2SJqGhSKBRISeHNR6hwyOXybHuMlYT2Q3HA14mIiIg0pUn7gT3HipAytiZY2bcWzgZHY87eQAS+iMP3ewPx14VQTGtTCa0qO3BYEhEVObq6uhzuRkREREREWsPuRkVQg/K22DOqEX7o5A1bUwM8jo7HkPVX0HPlBdx9Hqft8IiIiIiIiIiIiow8JceWLVsGd3d3GBoaom7durh48WK2279+/RojRoyAk5MTDAwM4OHhgX379qlt8+zZM/Tu3Rs2NjYwMjKCt7c3Ll++nJfwSgRdHRm61ymNE5OaYXizctDX08G5Ry/R9tcATNl+E5FvErUdIhERERERERHRR0/j5NiWLVswfvx4zJw5E1evXkW1atXg5+eX5YTKycnJaNWqFZ48eYLt27fj/v37WLlyJVxcXKRtXr16hYYNG0Iul2P//v24e/cufvrpJ1hZWeX9yEoIUwM9TP6kEo6Ob4p2VZ0gBLDlchiaLzyBZceDkZii0HaIREREREREREQfLY0n5K9bty5q166NpUuXAgCUSiVcXV0xatQoTJ06NcP2K1aswMKFC3Hv3j3I5fJM65w6dSrOnDmDgICAPBxCGk7UmuZKSAy+2xOIG2GvAQAulkaY2qYS2lV14nxkRERE72H7oWjg60RERESa0qT9oFHPseTkZFy5cgW+vr7/VaCjA19fX5w7dy7TMrt370b9+vUxYsQIODg4wMvLC/PmzYNCoVDbplatWujSpQvs7e1RvXp1rFy5UpPQ6P/VdLPGzmEN4N/NB04Whnj2+h1GbbqGzivO4fr/J8yIiIiIiIiIiCiNRsmx6OhoKBQKODg4qC13cHBAeHh4pmUePXqE7du3Q6FQYN++ffj222/x008/4fvvv1fb5rfffkOFChVw8OBBDBs2DKNHj8batWuzjCUpKQlxcXFqD0qjoyNDh+ouODahGcb5esBIrosrIa/QYdkZjN18Dc9fv9N2iEREREREREREH4VCv1ulUqmEvb09fv/9d9SsWRPdunXDN998gxUrVqhtU6NGDcybNw/Vq1fHkCFD8OWXX6pt87758+fDwsJCeri6uhb2oRQ5Rvq6GONbAccnNsMXNUoBAHZdf44WP53A4kP3EZ+UquUIiYiIiIiIiIi0S6PkmK2tLXR1dREREaG2PCIiAo6OjpmWcXJygoeHB3R1daVlnp6eCA8PR3JysrRN5cqV1cp5enoiNDQ0y1imTZuG2NhY6REWFqbJoZQojhaG+KlrNfw7shHquFsjMUWJJceC0eKnE9h+5SmUSo2mnSMiIiIiIiIiKjY0So7p6+ujZs2aOHr0qLRMqVTi6NGjqF+/fqZlGjZsiODgYCiVSmlZUFAQnJycoK+vL21z//59tXJBQUFwc3PLMhYDAwOYm5urPSh73qUssOWrevitVw24WhshIi4JE7fdwOfLzuDi4xhth0dERERERERE9MFpPKxy/PjxWLlyJdauXYvAwEAMGzYM8fHxGDBgAACgb9++mDZtmrT9sGHDEBMTgzFjxiAoKAh79+7FvHnzMGLECGmbcePG4fz585g3bx6Cg4OxceNG/P7772rbUMGQyWRo4+2Ew+OaYmqbSjA10MOtZ7Ho+r9zGLbhCkJfJmg7RCIiIiIiIiKiD0ZP0wLdunVDVFQUZsyYgfDwcPj4+ODAgQPSJP2hoaHQ0fkv5+bq6oqDBw9i3LhxqFq1KlxcXDBmzBhMmTJF2qZ27drYuXMnpk2bhu+++w5lypSBv78/evXqVQCHSJkxlOtiaNNy6FyzFBYfDsLmi6HYfzscRwMjMaChO0a0KA9zQ7m2wyQiIiIiIiIiKlQyIUSxmHAqLi4OFhYWiI2N5RDLPLgXHoe5ewMR8CAaAGBjoo9xrTzQvbYr9HQL/b4NREREWsH2Q9HA14mIiIg0pUn7gVkPAgBUcjTHuoF18Gf/WihrZ4KX8cmYvus22i45jYAHUdoOj4iIiIiIiIioUDA5RhKZTIYWlRxwcGwTzGpfGRZGctyPeIM+qy5i4JpLCI58q+0QiYiIiIiIiIgKFJNjlIFcVwf9G5bByUnNMKChO/R0ZDh2LxKf+J/CrN138Co+WdshEhEREREREREVCCbHKEuWxvqY2b4KDo5rAl9Pe6QqBdacfYJmi07gz9OPkaJQajtEIiIiIiIiIqJ8YXKMclTOzhR/9KuNDYPqopKjGWLfpeC7PXfh9/MpHLkbgWJyTwciIiIiIiIiKoGYHKNca1TBFntHN8b8Tt6wNdXHo+h4DF53Gb1XXUDgizhth0dEREREREREpDEmx0gjujoy9KhTGscnNsPQpuWgr6uDM8Ev0XZJAKbtuImoN0naDpGIiIiIiIiIKNeYHKM8MTOUY2qbSjg6oSnaejtBKYBNF8PQfNEJ/HbiIRJTFNoOkYiIiIiIiIgoR0yOUb64WhtjWa8a2Da0PqqWssDbpFT8eOAefBefxN6bLzgfGRERERERERF91JgcowJR290au4Y3xOKu1eBoboinr95hxMar6Pq/c7j59LW2wyMiIiIiIiIiyhSTY1RgdHRk6FSjFI5NbIoxLSvAUK6DS09e4bOlZzB+y3W8iH2n7RCJiIiIiIiIiNQwOUYFzlhfD+NaeeD4xGboVN0FALDj2jM0X3QC/keCkJCcquUIiYiIiIiIiIjSMDlGhcbJwgiLu/ngnxENUcvNCokpSvgfeYAWi05ix9WnUCo5HxkRERERERERaReTY1ToqrlaYtvQ+ljaszpKWRkhPC4R47feQIflZ3DpSYy2wyMiIiIiIiKiEozJMfogZDIZ2lV1xpHxTTH5k4owNdDDzaex6LLiHEb8dRVhMQnaDpGIiIiIiIiISiAmx+iDMpTrYniz8jg+sRl61HGFjgzYe+sFWi4+iR/238ObxBRth0hEREREREREJQiTY6QVdmYGmN+pKvaOboyG5W2QnKrEipMP0XzRCWy6GAoF5yMjIiIiIiIiog+AyTHSKk8nc2wYVBd/9K2FsrYmiH6bjGk7bqHtkgCcCY7WdnhEREREREREVMwxOUZaJ5PJ4FvZAQfGNsG37SrD3FAP98LfoNcfFzB47SU8inqr7RCJiIiIiIiIqJhicow+Gvp6OhjUqAxOTmqO/g3coasjw5HASLT++RRm/3sHt5/Fck4yIiIiIiIiIipQMiFEsZjcKS4uDhYWFoiNjYW5ubm2w6ECEBz5FvP2BeLYvUi15bam+nCzMYGbjTHc0/3rbmMCC2O5lqIlIqKiiO2HooGvExEREWlKk/aD3geKiUhj5e1N8Wf/2gh4EIXfTjxEUMQbRL9Nlh5XQl5lKGNpLIebjQncbYwz/Gttog+ZTKaFIyEiIiIiIiKijxWTY/TRa1zBDo0r2AEA3iSmIORlAkJeJuDJy3iEvIzHk5cJCHkZj4i4JLxOSMHrhNe4EfY6Qz1mBnpws30/aZb2t52ZARNnRERERERERCUQk2NUpJgZyuHlYgEvF4sM6xKSUxEak4An0QlqSbOQlwl4HvsOb5JScftZHG4/i8tQ1lhfF6Wt/3+Ypq36cE1Hc0Po6DBxRkRERERERFQcMTlGxYaxvh4qOZqjkmPGscSJKQo8fZWWOHvyMv7/e52l/f3s1TskJCtwL/wN7oW/yVDWQE8HbhmGaaYlz5wtjaDLxBkRERERERFRkcXkGJUIhnJdlLc3Q3l7swzrklOVePoq/VDN//4Ni0lAUqoSQRFvERTxNkNZua4MrtbqPc1U/7pYGUGuyxvCEhEREREREX3MmByjEk9fTwdl7UxR1s40w7pUhRLPXydmmN/sycsEhL5MQLJCiUdR8XgUFZ+hrK6ODKWsjDK9QYCrtREM9HQ/xOERERERERERUTaYHCPKhp6uDkrbGKO0jTEAO7V1CqVAeFwiQqLTJ83+63mWmKKUbh5w6r16ZTLA2cII7pncIKC0tTGM9Jk4IyIiIiIiIvoQmBwjyiNdHRlcLI3gYmmEBuXV1wkhEPkmCU+i4/9/jrP/T579/80C4pMVePb6HZ69foczwS8z1O1obgh36cYA/yXP3GyMYWLAty0RERERERFRQeGvbKJCIJPJ4GBuCAdzQ9Qta6O2TgiB6LfJGYZphryMx+PoeLxJTEV4XCLC4xJx/lFMhrrtzAwyDNNU3WXT3FD+oQ6RiIiIiIiIqFhgcozoA5PJZLAzM4CdmQFquVurrRNC4HVCSoYbA6j+jYlPRtSbJES9ScKlJ68y1G1top/hxgCqfy2N5ZDJeGdNIiIiIiIiovSYHCP6iMhkMliZ6MPKRB/VS1tlWB/7LgWhUrJMvedZ1JskxMQnIyY+GddCX2coa26oB3dbkww3CHC3NYGNiT4TZ0RERERERFQiMTlGVIRYGMnhXcoC3qUsMqx7m5SKkPQ9zaL/63EWHpeIuMRU3Hwai5tPYzOUNTXQy7zHma0J7M0MmDgjIiIiIiKiYovJMaJiwtRAD1WcLVDFOWPi7F2yAqExmfQ4i07A89h3eJuUijvP43DneVyGsoZyHbjbmOAzH2cMaVwWero6H+JwiIiIiIiIiD4IJseISgAjfV1UdDRDRUezDOuSUhUIi3mX6Q0Cnr56h8QUJe6Fv8G9A/dx+G4Efu7qA3dbEy0cBREREREREVHBY3KMqIQz0NNFeXtTlLc3zbAuRaHEs1fvcO7RS8zbF4hroa/x6ZIAfNuuMrrXduVwSyIiIiIiIiryOD6KiLIk19WBu60JetQpjQNjm6BeWWskJCswbcctfLnuMqLfJmk7RCIiIiIiIqJ8YXKMiHLFxdIIGwfXw9efVoK+rg6OBEbC7+dTOHI3QtuhEREREREREeUZk2NElGs6OjIMaVIO/4xsiEqOZngZn4zB6y5j2o6biE9K1XZ4RERERERERBpjcoyINObpZI5dIxriy8ZlIJMBmy6Goe2SAFwNfaXt0IiIiIiIiIg0wuQYEeWJoVwX37StjL8G14WzhSGevExA59/OYvGh+0hRKLUdHhEREREREVGuMDlGRPnSoJwt9o9tgg4+zlAKYMmxYHT+7SweRr3VdmhEREREREREOWJyjIjyzcJIDv/u1fFrj+owN9TDjaexaLskAOvPh0AIoe3wiIiIiIiIiLLE5BgRFZj21ZxxcFwTNCxvg8QUJb7ddRsD1lxCZFyitkMjIiIiIiIiyhSTY0RUoJwsjLB+YF3MaFcZ+no6OHE/Cn7+p3Dgdri2QyMiIiIiIiLKgMkxIipwOjoyDGxUBntGNUJlJ3O8SkjB0A1XMGnbDbxJTNF2eEREREREREQSJseIqNB4OJhh14iGGNasHGQyYNuVp2jzSwAuPYnRdmhEREREREREAJgcI6JCpq+ngymfVMKWIfXhYmmEp6/eodv/zmHBgXtITlVqOzwiIiIiIiIq4ZgcI6IPok4ZaxwY2xhf1CgFpQCWn3iIjsvP4EHEG22HRkRERERERCUYk2NE9MGYGcrxU9dq+K1XDVgZy3HneRza/Xoaq888hlIptB0eERERERERlUBMjhHRB9fG2wkHxzZBUw87JKUqMfvfu+i3+iLCYxO1HRoRERERERGVMEyOEZFW2JsbYs2A2vju8yowlOsg4EE0/PxPYc/N59oOjYiIiIiIiEoQJseISGtkMhn61nfHnlGNUbWUBWLfpWDkxmsYt+U64hJTtB0eERERERERlQBMjhGR1pW3N8XfwxpgVIvy0JEBO689Qxv/AJx/9FLboREREREREVExx+QYEX0U5Lo6mNC6IrYNbQA3G2M8e/0OPVaex7x9gUhKVWg7PCIiIiIiIiqmmBwjoo9KTTcr7BvdGN1ru0II4PdTj/D50jO4Fx6n7dCIiIiIiIioGGJyjIg+OiYGevjhi6r4vU9N2Jjo4174G3z26xn8EfAISqXQdnhERERERERUjDA5RkQfrdZVHHFgbBO0rGSPZIUS3+8NRK8/LuD563faDo2IiIiIiIiKCSbHiOijZmdmgD/61cK8jt4wkuvi3KOX8PM/hX+uP9N2aERERERERFQMMDlGRB89mUyGnnVLY9+YxvBxtcSbxFSM2XwdozZdQ2xCirbDIyIqVpYtWwZ3d3cYGhqibt26uHjxYpbbNmvWDDKZLMOjbdu2atsFBgbis88+g4WFBUxMTFC7dm2EhoYW9qEQERER5QqTY0RUZJSxNcH2ofUxztcDujoy/HvjOfz8T+FMcLS2QyMiKha2bNmC8ePHY+bMmbh69SqqVasGPz8/REZGZrr9jh078OLFC+lx+/Zt6OrqokuXLtI2Dx8+RKNGjVCpUiWcOHECN2/exLfffgtDQ8MPdVhERERE2ZIJIYrF7NZxcXGwsLBAbGwszM3NtR0OERWy62GvMW7LdTyOjgcADGxYBpM/qQhDua6WIyOiooTtB3V169ZF7dq1sXTpUgCAUqmEq6srRo0ahalTp+ZY3t/fHzNmzMCLFy9gYmICAOjevTvkcjnWr1+f57j4OhEREZGmNGk/sOcYERVJPq6W2Du6EXrXKw0A+PPMY7T/9TTuPI/VcmREREVTcnIyrly5Al9fX2mZjo4OfH19ce7cuVzVsWrVKnTv3l1KjCmVSuzduxceHh7w8/ODvb096tati127dhXGIRARERHlCZNjRFRkGevr4fsO3ljdvzZsTQ3wIPItOiw7g99OPIRCWSw6xRIRfTDR0dFQKBRwcHBQW+7g4IDw8PAcy1+8eBG3b9/G4MGDpWWRkZF4+/YtfvjhB3zyySc4dOgQOnbsiE6dOuHkyZNZ1pWUlIS4uDi1BxEREVFhYXKMiIq85pXscXBsY7Su7IAUhcCPB+6hx+/nERaToO3QiIhKjFWrVsHb2xt16tSRlimVSgDA559/jnHjxsHHxwdTp05Fu3btsGLFiizrmj9/PiwsLKSHq6trocdPREREJReTY0RULNiYGuB/fWpiQeeqMNHXxcUnMWjzSwC2X3mKYjK1IhFRobK1tYWuri4iIiLUlkdERMDR0THbsvHx8di8eTMGDRqUoU49PT1UrlxZbbmnp2e2d6ucNm0aYmNjpUdYWJiGR0NERESUe0yOEVGxIZPJ0LWWK/aPaYJablZ4m5SKidtuYPhfV/EqPlnb4RERfdT09fVRs2ZNHD16VFqmVCpx9OhR1K9fP9uy27ZtQ1JSEnr37p2hztq1a+P+/ftqy4OCguDm5pZlfQYGBjA3N1d7EBERERUWJseIqNgpbWOMLV/VxyS/itDTkWH/7XD4+Z/CifuR2g6NiOijNn78eKxcuRJr165FYGAghg0bhvj4eAwYMAAA0LdvX0ybNi1DuVWrVqFDhw6wsbHJsG7SpEnYsmULVq5cieDgYCxduhT//vsvhg8fXujHQ0RERJQbetoOgIioMOjqyDCieXk09bDD2C3XERz5Fv1XX0Lf+m6Y1sYTRvq62g6RiOij061bN0RFRWHGjBkIDw+Hj48PDhw4IE3SHxoaCh0d9Wur9+/fx+nTp3Ho0KFM6+zYsSNWrFiB+fPnY/To0ahYsSL+/vtvNGrUqNCPh4iIiCg3ZKKYTMYTFxcHCwsLxMbGsus9EalJTFHgh/33sObsEwBAOTsT+HerDu9SFtoNjIi0ju2HooGvExEREWlKk/YDh1USUbFnKNfFrM+qYO3AOrA3M8DDqHh0XH4GS489QKpCqe3wiIiIiIiISIuYHCOiEqOphx0Ojm2Ctt5OSFUKLDoUhG6/n0fIy3hth0ZERERERERawuQYEZUoVib6WNqzOhZ3rQYzAz1cCXmFT38JwJZLoSgmo8yJiIiIiIhIA0yOEVGJI5PJ0KlGKewf2xh1ylgjPlmBKX/fwpD1V/DybZK2wyMiIiIiIqIPiMkxIiqxSlkZY9OX9TCtTSXIdWU4fDcCfv6ncOxehLZDIyIiIiIiog+EyTEiKtF0dWT4qmk5/DOiETwcTBH9NhkD11zG1ztvISE5VdvhERERERERUSFjcoyICEBlZ3PsHtkIgxuVAQBsvBCKT38JwLXQV1qOjIiIiIiIiAoTk2NERP/PUK6L6e0qY+PgunCyMMSTlwnovOIcfj4chBSFUtvhERERERERUSFgcoyI6D0NytviwJgm+KyaMxRKgV+OPkDnFefwODpe26ERERERERFRAWNyjIgoExbGcizpUR2/dPeBuaEeboS9xqe/BOCvCyEQQmg7PCIiIiIiIiogTI4REWXjcx8XHBjbBA3K2eBdigLf7LyNQWsvI/JNorZDIyIiIiIiogLA5BgRUQ6cLY2wYVBdTG/rCX09HRy7F4lP/ANw6E64tkMjIiIiIiKifGJyjIgoF3R0ZBjcuCz+HdkInk7miIlPxpD1VzBl+028TUrVdnhERERERESUR0yOERFpoKKjGXaNaICvmpaFTAZsuRyGT38JwJWQGG2HRkRERERERHnA5BgRkYYM9HQxrY0nNn1ZDy6WRgiNSUCXFeew6OB9pCiU2g6PiIiIiIiINMDkGBFRHtUra4P9YxujU3UXKAWw9HgwOi0/i+DIN9oOjYiIiIiIiHKJyTEionwwN5RjcTcfLOtZA5bGctx6Fou2S05j7dknEEJoOzwiIiIiIiLKAZNjREQFoG1VJxwc2wSNK9giKVWJmbvvoN/qS4iIS9R2aERERERERJQNJseIiAqIg7kh1g2sg9mfVYGBng5OBUXBz/8U9t16oe3QiIiIiIiIKAtMjhERFSCZTIZ+Ddyxd3QjeLmY43VCCob/dRXjt15HXGKKtsMjIiIiIiKi9zA5RkRUCMrbm2HHsIYY2bw8dGTAjqvP0MY/ABcevdR2aERERERERJQOk2NERIVEX08HE/0qYutX9eFqbYRnr9+h+8rzmL8/EEmpCm2HR0RERERERGByjIio0NVyt8b+MU3QtVYpCAH87+QjdFh2FkERb7QdGhERERERUYnH5BgR0QdgaqCHBZ2r4X99asLaRB+BL+LQ7tfTWHX6MZRKoe3wiIiIiIiISiwmx4iIPiC/Ko44MLYxmle0Q3KqEnP23EWfPy/gRew7bYdGRERERERUIjE5RkT0gdmbGeLP/rXxfQcvGMl1cSb4Jfx+PoXdN55rOzQiIiIiIqISh8kxIiItkMlk6F3PDXtHN0K1UhaIS0zF6E3XMGbzNcQmpGg7PCIiIiIiohKDyTEiIi0qa2eK7cMaYEzLCtDVkeGf68/xyS+ncDY4WtuhERERERERlQhMjhERaZlcVwfjWnlg+9D6cLcxxovYRPT84wK+33MXiSkKbYdHRERERERUrDE5RkT0kahe2gr7xjRGz7qlAQB/nH6Mz5eewd3ncVqOjIiIiIiIqPjKU3Js2bJlcHd3h6GhIerWrYuLFy9mu/3r168xYsQIODk5wcDAAB4eHti3b1+m2/7www+QyWQYO3ZsXkIjIirSjPX1MK+jN1b1qwVbU33cj3iDDsvO4Ps9d3ElJAZKpdB2iERERERERMWKnqYFtmzZgvHjx2PFihWoW7cu/P394efnh/v378Pe3j7D9snJyWjVqhXs7e2xfft2uLi4ICQkBJaWlhm2vXTpEv73v/+hatWqeToYIqLioqWnAw6MbYKpf9/CkcAI/HH6Mf44/Ri2pgbw9bRHq8oOaFjeFoZyXW2HSkREREREVKTJhBAadUOoW7cuateujaVLlwIAlEolXF1dMWrUKEydOjXD9itWrMDChQtx7949yOXyLOt9+/YtatSogeXLl+P777+Hj48P/P39cx1XXFwcLCwsEBsbC3Nzc00OiYjooyWEwOG7Edhz8wWO34/Em8RUaZ2xvi6aVLBDq8oOaFHJHlYm+lqMlKhoYvuhaODrRERERJrSpP2g0bDK5ORkXLlyBb6+vv9VoKMDX19fnDt3LtMyu3fvRv369TFixAg4ODjAy8sL8+bNg0KhPsn0iBEj0LZtW7W6iYhKOplMhtZVHLGkR3Vcmd4KGwbVRd/6bnCyMERCsgIH7oRjwrYbqDX3CLr/fg6rTj9GWEyCtsMmIiIiIiIqMjQaVhkdHQ2FQgEHBwe15Q4ODrh3716mZR49eoRjx46hV69e2LdvH4KDgzF8+HCkpKRg5syZAIDNmzfj6tWruHTpUq5jSUpKQlJSkvT/uDhOWE1ExZu+ng4aVbBFowq2mP1ZFdx5HodDd8Jx6G4E7oW/wflHMTj/KAZz9txFJUcztK7sgFaVHeHlYg6ZTKbt8ImIiIiIiD5KGs85pimlUgl7e3v8/vvv0NXVRc2aNfHs2TMsXLgQM2fORFhYGMaMGYPDhw/D0NAw1/XOnz8fs2fPLsTIiYg+XjKZDF4uFvByscD41hURFpOAQ3cjcPhuOC49eYV74W9wL/wNlhwLhrOFIXwrO6BVZQfULWMDfT3eqJiIiIiIiEhFo+SYra0tdHV1ERERobY8IiICjo6OmZZxcnKCXC6Hru5/k0Z7enoiPDxcGqYZGRmJGjVqSOsVCgVOnTqFpUuXIikpSa2syrRp0zB+/Hjp/3FxcXB1ddXkcIiIig1Xa2MMalQGgxqVwav4ZBy/H4lDdyJw6kEUnscmYt25EKw7FwIzQz00r5g2oX+zinYwM8x6LkgiIiIiIqKSQKPkmL6+PmrWrImjR4+iQ4cOANJ6hh09ehQjR47MtEzDhg2xceNGKJVK6Oik9VYICgqCk5MT9PX10bJlS9y6dUutzIABA1CpUiVMmTIl08QYABgYGMDAwECT8ImISgQrE310qlEKnWqUQmKKAmcfRuPQnQgcCYxA9Ntk7L7xHLtvPIdcV4b65WzRqrIDWnk6wNEi9713iYiIiIiIiguNh1WOHz8e/fr1Q61atVCnTh34+/sjPj4eAwYMAAD07dsXLi4umD9/PgBg2LBhWLp0KcaMGYNRo0bhwYMHmDdvHkaPHg0AMDMzg5eXl9o+TExMYGNjk2E5ERFpxlCuixaVHNCikgOUSoFrYa9x6G44Dt+NwKOoeJwKisKpoCh8u+s2qpaykOYp83Aw5TxlRERERERUImicHOvWrRuioqIwY8YMhIeHw8fHBwcOHJAm6Q8NDZV6iAGAq6srDh48iHHjxqFq1apwcXHBmDFjMGXKlII7CiIiypGOjgw13axQ080K09p4IjjyLQ7//zxl18Je4+bTWNx8GotFh4JQ2tr4/xNlDqjpZgU9Xc5TRkRERERExZNMCCG0HURBiIuLg4WFBWJjY2Fubq7tcIiIipTIN4k4FhiJQ3cjcDo4GsmpSmmdlbEcLSo5oHUVBzSpYAcj/cyHuxMVRWw/FA18nYiIiEhTmrQfmBwjIiI18UmpCHgQhUN3InD0XiRi36VI6wz0dNC4gi1aV3ZEC0972Jpy7kcq2th+KBr4OhEREZGmNGk/aDyskoiIijcTAz184uWET7yckKpQ4tKTV9I8ZU9fvcORwEgcCYyETAbULG2F1lXS5ikrY2ui7dCJiIiIiIg0xp5jRESUK0II3At/g0N3InA4MBy3n8WprS9vb4pWlR3QurIDqpWyhI4OJ/Snjx/bD0UDXyciIiLSFIdVstFERFTonr9+hyOBETh0JwLnH71EqvK/rxN7MwO09Eybp6xBORsY6HGeMvo4sf1QNPB1IiIiIk0xOcZGExHRBxX7LgUn7qdN6H/yfhTeJqVK60z0ddG0oh1aVXZAi4oOsDCWazFSInVsPxQNfJ2IiIhIU5xzjIiIPigLIzk+93HB5z4uSEpV4PyjGBy6E44jgRGIiEvCvlvh2HcrHLo6MtQtY41WlR3QqrIDSlkZazt0IiIiIiIq4dhzjIiICo1SKXDrWSwO343AobvhCIp4q7a+spO5lCir4mwOmYzzlNGHxfZD0cDXiYiIiDTFYZVsNBERfZRCXsanJcruROBySAzSTVMGF0sjKVFWp4w15Lo62guUSgy2H4oGvk5ERESkKSbH2GgiIvrovXybhGP30uYpC3gQhcQUpbTO3FAPLSrZo1VlRzStaAdTA84CQIWD7Yeiga8TERERaYpzjhER0UfPxtQAXWq5okstV7xLVuB0cDQO3QnH0XuRiIlPxq7rz7Hr+nPo6+qgQXmbtF5lng6wNzfUduhERERERFSMsOcYERF9VBRKgauhr/5/+GU4nrxMUFvv42qJVpUd0LqyA8rbm3KeMsoXth+KBr5OREREpCkOq2SjiYioWBBCIDjyLQ7djcChuxG4EfZabX0ZWxNpnrIapa2gq8NEGWmG7Yeiga8TERERaYrJMTaaiIiKpYi4RBwJTJvQ/9zDl0hW/DdPmY2JPlp6ps1T1riCLQzlulqMlIoKth+KBr5OREREpCkmx9hoIiIq9t4kpuBUUDQO3Q3HsXuReJOYKq0zlOugSQU7tKrsgJaeDrA20ddipPQxY/uhaODrRERERJrihPxERFTsmRnK0baqE9pWdUKKQomLj2OkecqexyZKQzF1ZEAtd2u0/v/hl242JtoOnYiIiIiIPiLsOUZERMWKEAJ3nselJcruRiDwRZzaeg8HU7Su7IhWlR3g7WIBHc5TVqKx/VA08HUiIiIiTXFYJRtNRET0/8JiEqR5yi4+iYFC+d/XnoO5wf9P6O+I+mVtoK+no8VISRvYfiga+DoRERGRppgcY6OJiIgy8TohGcfvR+LQnQicDIpCQrJCWmdqoIdmFdPmKWtW0R4WRnItRkofCtsPRQNfJyIiItIU5xwjIiLKhKWxPjpWL4WO1UshMUWBcw9f4tDdCBy+G4Hot0nYc/MF9tx8AT0dGeqVtUHrKg7w9XSAs6WRtkMnIiIiIqJCwp5jRERU4imVAtefvpYm9H8YFa+2vk4Za4xqUR6NyttCJuMcZcUJ2w9FA18nIiIi0hSHVbLRRERE+fAo6q00of/V0FdQfVNWL22J0S0qoFlFOybJigm2H4oGvk5ERESkKSbH2GgiIqIC8iL2HX4/9QgbL4QiKVUJAPB2scCoFuXRqrIDk2RFHNsPRQNfJyIiItKUJu0H3paLiIgoG04WRpjZvgoCpjTHkCZlYSTXxa1nsRiy/gra/BKAfbdeQKksFteZiIiIiIhKJCbHiIiIcsHezBBff+qJ01OaY3izcjA10MO98DcY/tdV+Pmfwj/Xn0HBJBkRERERUZHD5BgREZEGbEwNMPmTSjg9pTlGt6wAM0M9PIh8izGbr6PV4pP4+8pTpCqU2g6TiIiIiIhyickxIiKiPLA01sf4Vh44M7UFJrTygKWxHI+i4zFh2w20+OkkNl8MRXIqk2RERERERB87JseIiIjywdxQjlEtK+D0lBaY2qYSbEz0ERqTgKk7bqH5ohNYfz4ESakKbYdJRERERERZYHKMiIioAJga6GFo03IImNIc09t6ws7MAM9ev8O3u26j6YITWH3mMRJTmCQjIiIiIvrYMDlGRERUgIz19TC4cVkETG6OWe0rw9HcEOFxiZj97100+vE4Vp56hITkVG2HSURERERE/4/JMSIiokJgKNdF/4ZlcHJyM8zt6AUXSyNEv03C3H2BaPTjcSw/EYy3SUySERERERFpG5NjREREhchATxe96rrhxKRmWPBFVZS2NkZMfDIWHLiPRj8ew5KjDxD7LkXbYRIRERERlVhMjhEREX0Acl0ddK3timMTmmJx12ooa2eC1wkpWHw4CI1+OIbFh+7jdUKytsMkIiIiIipxmBwjIiL6gPR0ddCpRikcHtcUS3pURwV7U7xJSsWSY8Fo+MMx/HjgHl6+TdJ2mEREREREJQaTY0RERFqgqyPDZ9WccXBsE/zWqwY8ncwRn6zAbyceotGPxzF3711EvknUdphERERERMUek2NERERapKMjQxtvJ+wb3Qgr+9ZC1VIWeJeiwMqAx2j843HM2n0H4bFMkhERERERFRYmx4iIiD4CMpkMrSo74J8RDbF6QG3UKG2JpFQl1px9giYLjuObnbfw9FWCtsMkIiIiIip29LQdABEREf1HJpOheUV7NPOww9mHL/HL0Qe4+DgGf10IxZZLYfiiRikMb14ObjYm2g6ViIiIiKhYYHKMiIjoIySTydCwvC0alrfF+Ucv8euxBzgT/BJbLodh+9Wn+NzHGSObl0dZO1Nth0pEREREVKQxOUZERPSRq1fWBvXK2uBKSAyWHA3GyaAo7Lj6DLuuPUO7qs4Y2aI8PBzMtB0mEREREVGRxDnHiIiIioiabtZYO7AO/hnREL6e9lAKYPeN5/DzP4Xhf13B3edx2g6RiIiIiKjIYXKMiIioiKnmaok/+tXGnlGN8EkVRwgB7LsVjk+XBODLdZdx62mstkMkIiIiIioymBwjIiIqorxcLLCiT00cHNsE7as5QyYDDt+NQPulpzFg9UVcDX2l7RCJiIiIiD56TI4REREVcRUdzfBrj+o4PK4pOlZ3gY4MOH4/Cp2Wn0WfVRdw8XGMtkMkIiIiIvpoMTlGRERUTJS3N8XP3XxwbEIzdK1VCno6MgQ8iEbX/51D99/P4WxwNIQQ2g6TiIiIiOijwuQYERFRMeNua4IFnavh+MRm6Fm3NOS6Mpx/FIOef1xAlxXncDIoikkyIiIiIqL/x+QYERFRMeVqbYx5Hb1xclJz9KvvBn09HVwOeYV+f15Eh+VncTQwgkkyIiIiIirxmBwjIiIq5pwtjTD7cy+cntwcgxqVgaFcBzfCXmPQ2sto9+tpHLgdDqWSSTIiIiIiKpmYHCMiIioh7M0N8W27yjg9pQW+aloWxvq6uPM8DkM3XEGbXwLw743nUDBJRkREREQlDJNjREREJYytqQGmtfHE6SktMLJ5eZgZ6OF+xBuM2nQNrX8+iV3XniFVodR2mEREREREHwSTY0RERCWUtYk+JvpVxOkpLTDWtwLMDfXwMCoeY7dch+/ik9h2OQwpTJIRERERUTHH5BgREVEJZ2Esx1hfD5yZ2gKT/CrCyliOJy8TMGn7TTRfdAIbL4QiOZVJMiIiIiIqnpgcIyIiIgCAmaEcI5qXx+kpLfD1p5Vga6qPp6/e4eudt9Bs4XGsO/cEiSkKbYdJRERERFSgmBwjIiIiNSYGehjSpBwCJrfAt+0qw97MAM9jEzHjnztosuA4Vp1+jHfJTJIRERERUfHA5BgRERFlykhfF4MalcGpyc3x3edV4GxhiMg3SZiz5y4aLziG/518iPikVG2HSURERESUL0yOERERUbYM5broW98dJyY1x/xO3ihlZYTot8mYv/8eGv14DMuOB+NNYoq2wyQiIiIiyhMmx4iIiChX9PV00KNOaRyf2AwLO1eFu40xXiWkYOHB+2j4wzH4HwlCbAKTZERERERUtDA5RkRERBqR6+qgSy1XHBnfFP7dfFDOzgRxianwP/IAjX48hkUH7+NVfLK2wyQiIiIiyhUmx4iIiChP9HR10KG6Cw6Na4qlPaujooMZ3iSlYunxYDT88Rjm7w9E9NskbYdJRERERJQtJseIiIgoX3R1ZGhX1Rn7xzTGit41UcXZHAnJCvzv5CM0+vEY5uy5i8i4RG2HSbm0bNkyuLu7w9DQEHXr1sXFixez3LZZs2aQyWQZHm3bts10+6FDh0Imk8Hf37+QoiciIiLSHJNjREREVCB0dGT4xMsRe0Y1wqp+tVDN1RKJKUqsOv0YjRYcx4x/buP563faDpOysWXLFowfPx4zZ87E1atXUa1aNfj5+SEyMjLT7Xfs2IEXL15Ij9u3b0NXVxddunTJsO3OnTtx/vx5ODs7F/ZhEBEREWmEyTEiIiIqUDKZDC09HbBreAOsHVgHtdyskJyqxLpzIWi68Dim7biFsJgEbYdJmVi8eDG+/PJLDBgwAJUrV8aKFStgbGyMP//8M9Ptra2t4ejoKD0OHz4MY2PjDMmxZ8+eYdSoUfjrr78gl8s/xKEQERER5RqTY0RERFQoZDIZmnrYYdvQ+tj4ZV3UK2uNFIXApouhaL7oBCZtu4En0fHaDpP+X3JyMq5cuQJfX19pmY6ODnx9fXHu3Llc1bFq1Sp0794dJiYm0jKlUok+ffpg0qRJqFKlSoHHTURERJRfetoOgIiIiIo3mUyGBuVs0aCcLS4+jsGvxx4g4EE0tl15ir+vPsXnPi4Y0bw8ytubajvUEi06OhoKhQIODg5qyx0cHHDv3r0cy1+8eBG3b9/GqlWr1Jb/+OOP0NPTw+jRo3MdS1JSEpKS/ruZQ1xcXK7LEhEREWmKPceIiIjog6lTxhrrB9XFjuEN0LyiHZQC2HntGVr9fBIjN17F/fA32g6R8mjVqlXw9vZGnTp1pGVXrlzBL7/8gjVr1kAmk+W6rvnz58PCwkJ6uLq6FkbIRERERACYHCMiIiItqFHaCqsH1MG/IxuhVWUHCAHsufkCfv6nMHT9Fdx+FqvtEEscW1tb6OrqIiIiQm15REQEHB0dsy0bHx+PzZs3Y9CgQWrLAwICEBkZidKlS0NPTw96enoICQnBhAkT4O7unmV906ZNQ2xsrPQICwvL83ERERER5YTJMSIiItIa71IWWNm3FvaNboxPvR0hkwEH7oSj3a+nMXjtJdwIe63tEEsMfX191KxZE0ePHpWWKZVKHD16FPXr18+27LZt25CUlITevXurLe/Tpw9u3ryJ69evSw9nZ2dMmjQJBw8ezLI+AwMDmJubqz2IiIiICgvnHCMiIiKtq+xsjuW9auJBxBssPR6Mf288x5HASBwJjERTDzt838ELrtbG2g6z2Bs/fjz69euHWrVqoU6dOvD390d8fDwGDBgAAOjbty9cXFwwf/58tXKrVq1Chw4dYGNjo7bcxsYmwzK5XA5HR0dUrFixcA+GiIiIKJeYHCMiIqKPRgUHM/zSvTpGt6yAZceD8c/157ga8grmRnJth1YidOvWDVFRUZgxYwbCw8Ph4+ODAwcOSJP0h4aGQkdHfeDB/fv3cfr0aRw6dEgbIRMRERHlm0wIIbQdREGIi4uDhYUFYmNj2fWeiIiomAh5GY/74W/Qukr2c17lFdsPRQNfJyIiItKUJu0H9hwjIiKij5abjQncbEy0HQYRERERFWOckJ+IiIiIiIiIiEosJseIiIiIiIiIiKjEYnKMiIiIiIiIiIhKLCbHiIiIiIiIiIioxGJyjIiIiIiIiIiISiwmx4iIiIiIiIiIqMRicoyIiIiIiIiIiEosJseIiIiIiIiIiKjEYnKMiIiIiIiIiIhKLCbHiIiIiIiIiIioxGJyjIiIiIiIiIiISiwmx4iIiIiIiIiIqMRicoyIiIiIiIiIiEosJseIiIiIiIiIiKjEYnKMiIiIiIiIiIhKLCbHiIiIiIiIiIioxGJyjIiIiIiIiIiISiwmx4iIiIiIiIiIqMRicoyIiIiIiIiIiEosJseIiIiIiIiIiKjEYnKMiIiIiIiIiIhKLCbHiIiIiIiIiIioxGJyjIiIiIiIiIiISiwmx4iIiIiIiIiIqMRicoyIiIiIiIiIiEosJseIiIiIiIiIiKjEYnKMiIiIiIiIiIhKLCbHiIiIiIiIiIioxGJyjIiIiIiIiIiISiwmx4iIiIiIiIiIqMTKU3Js2bJlcHd3h6GhIerWrYuLFy9mu/3r168xYsQIODk5wcDAAB4eHti3b5+0fv78+ahduzbMzMxgb2+PDh064P79+3kJjYiIiIiIiIiIKNc0To5t2bIF48ePx8yZM3H16lVUq1YNfn5+iIyMzHT75ORktGrVCk+ePMH27dtx//59rFy5Ei4uLtI2J0+exIgRI3D+/HkcPnwYKSkpaN26NeLj4/N+ZERERERERERERDmQCSGEJgXq1q2L2rVrY+nSpQAApVIJV1dXjBo1ClOnTs2w/YoVK7Bw4ULcu3cPcrk8V/uIioqCvb09Tp48iSZNmuSqTFxcHCwsLBAbGwtzc/PcHxARERGVWGw/FA18nYiIiEhTmrQfNOo5lpycjCtXrsDX1/e/CnR04Ovri3PnzmVaZvfu3ahfvz5GjBgBBwcHeHl5Yd68eVAoFFnuJzY2FgBgbW2d5TZJSUmIi4tTexAREREREREREWlCo+RYdHQ0FAoFHBwc1JY7ODggPDw80zKPHj3C9u3boVAosG/fPnz77bf46aef8P3332e6vVKpxNixY9GwYUN4eXllGcv8+fNhYWEhPVxdXTU5FCIiIiIiIiIiosK/W6VSqYS9vT1+//131KxZE926dcM333yDFStWZLr9iBEjcPv2bWzevDnbeqdNm4bY2FjpERYWVhjhExERERERERFRMaanyca2trbQ1dVFRESE2vKIiAg4OjpmWsbJyQlyuRy6urrSMk9PT4SHhyM5ORn6+vrS8pEjR2LPnj04deoUSpUqlW0sBgYGMDAw0CR8IiIiIiIiIiIiNRr1HNPX10fNmjVx9OhRaZlSqcTRo0dRv379TMs0bNgQwcHBUCqV0rKgoCA4OTlJiTEhBEaOHImdO3fi2LFjKFOmTF6OhYiIiIiIiIiISCMaD6scP348Vq5cibVr1yIwMBDDhg1DfHw8BgwYAADo27cvpk2bJm0/bNgwxMTEYMyYMQgKCsLevXsxb948jBgxQtpmxIgR2LBhAzZu3AgzMzOEh4cjPDwc7969K4BDJCIiIiIiIiIiypxGwyoBoFu3boiKisKMGTMQHh4OHx8fHDhwQJqkPzQ0FDo6/+XcXF1dcfDgQYwbNw5Vq1aFi4sLxowZgylTpkjb/PbbbwCAZs2aqe1r9erV6N+/fx4Oi4iIiIiIiIiIKGcyIYTQdhAFIS4uDhYWFoiNjYW5ubm2wyEiIqIigO2HooGvE/1fe/cdHkWd+HH8vQlplIQeelEEASlSD+yKFxuKFT0URIp66KlY+d2JXfQshwVFOYodbHjYQI3lVFAQDkWliAVQCFUSCZKEZH9/rK5GacHAJNn363nmudnJzOxnNngOH7/zXUmSSqok9w97/NsqJUmSJEmSpLLKckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSVFjxoyhWbNmJCcn0717d2bPnr3dfQ8//HBCodDvluOPPx6AgoICrr76atq1a0eVKlVo0KAB/fv3Z+XKlXvrciRJknbKckySJEkATJkyheHDh3Pdddcxb948OnToQEZGBmvWrNnm/s8//zyrVq2KLp9++inx8fGcfvrpAGzevJl58+Zx7bXXMm/ePJ5//nkWL17MiSeeuDcvS5IkaYdC4XA4HHSI0pCTk0NaWhrZ2dmkpqYGHUeSJJUD3j8U1717d7p27cr9998PQFFREY0bN+biiy/mmmuu2enxo0ePZuTIkaxatYoqVapsc585c+bQrVs3li1bRpMmTXYpl78nSZJUUiW5f3DkmCRJksjPz2fu3Ln06tUrui0uLo5evXoxa9asXTrH+PHjOfPMM7dbjAFkZ2cTCoWoXr36dvfJy8sjJyen2CJJkrSnWI5JkiSJdevWUVhYSHp6erHt6enpZGVl7fT42bNn8+mnnzJ48ODt7rNlyxauvvpqzjrrrB3+F9xRo0aRlpYWXRo3brzrFyJJklRClmOSJEn6w8aPH0+7du3o1q3bNn9eUFDAGWecQTgc5sEHH9zhuUaMGEF2dnZ0WbFixZ6ILEmSBECloANIkiQpeLVr1yY+Pp7Vq1cX27569Wrq1au3w2Nzc3OZPHkyN9544zZ//nMxtmzZMt58882dzvuRlJREUlJSyS5AkiRpNzlyTJIkSSQmJtK5c2cyMzOj24qKisjMzKRHjx47PPaZZ54hLy+Ps88++3c/+7kY++KLL3jjjTeoVatWqWeXJEn6Ixw5JkmSJACGDx/OgAED6NKlC926dWP06NHk5uYycOBAAPr370/Dhg0ZNWpUsePGjx9Pnz59fld8FRQUcNpppzFv3jxeeuklCgsLo/OX1axZk8TExL1zYZIkSTtgOSZJkiQA+vbty9q1axk5ciRZWVl07NiR6dOnRyfpX758OXFxxR88WLx4Me+99x6vvfba78733XffMW3aNAA6duxY7GdvvfUWhx9++B65DkmSpJIIhcPhcNAhSkNOTg5paWlkZ2fvdB4LSZIk8P6hvPD3JEmSSqok9w/OOSZJkiRJkqSYZTkmSZIkSZKkmOWcY5IkSZIkVTCFhYUUFBQEHUPaYxISEoiPjy+Vc1mOSZIkSZJUQYTDYbKysti4cWPQUaQ9rnr16tSrV49QKPSHzmM5JkmSJElSBfFzMVa3bl0qV678h0sDqSwKh8Ns3ryZNWvWAFC/fv0/dD7LMUmSJEmSKoDCwsJoMVarVq2g40h7VEpKCgBr1qyhbt26f+gRSyfklyRJkiSpAvh5jrHKlSsHnETaO37+s/5H59ezHJMkSZIkqQLxUUrFitL6s245JkmSJEmSpJhlOSZJkiRJkiqUZs2aMXr06KBjqJywHJMkSZIkSYEIhUI7XK6//vrdOu+cOXMYOnRo6YYFMjIyiI+PZ86cOaV+bgXHb6uUJEmSJEmBWLVqVXR9ypQpjBw5ksWLF0e3Va1aNboeDocpLCykUqWdVxl16tQp3aDA8uXLmTlzJhdddBETJkyga9eupf4eJVFQUEBCQkKgGSoKR45JkiRJkqRA1KtXL7qkpaURCoWirxctWkS1atV49dVX6dy5M0lJSbz33nt8+eWXnHTSSaSnp1O1alW6du3KG2+8Uey8v32sMhQK8e9//5uTTz6ZypUrs99++zFt2rQSZZ04cSInnHACF154IU899RQ//vhjsZ9v3LiR888/n/T0dJKTkznggAN46aWXoj9///33Ofzww6lcuTI1atQgIyOD77//fpt5ATp27Fhs5FwoFOLBBx/kxBNPpEqVKtxyyy0UFhYyaNAgmjdvTkpKCq1ateKee+75XfYJEybQtm1bkpKSqF+/PhdddBEA5513HieccEKxfQsKCqhbty7jx48v0edTnlmOSZIkSZJUAYXDYTbnbw1kCYfDpXYd11xzDbfddhsLFy6kffv2bNq0ieOOO47MzEz+97//ccwxx9C7d2+WL1++w/PccMMNnHHGGXzyySccd9xx9OvXjw0bNuxShnA4zMSJEzn77LPZf//9adGiBc8++2z050VFRRx77LG8//77PP7443z++efcdtttxMfHAzB//nyOOuoo2rRpw6xZs3jvvffo3bs3hYWFJfosrr/+ek4++WQWLFjAeeedR1FREY0aNeKZZ57h888/Z+TIkfzf//0fTz/9dPSYBx98kGHDhjF06FAWLFjAtGnTaNGiBQCDBw9m+vTpxUbwvfTSS2zevJm+ffuWKFt55mOVkiRJkiRVQD8WFNJm5IxA3vvzGzOonFg6lcONN97I0UcfHX1ds2ZNOnToEH190003MXXqVKZNmxYdEbUt5557LmeddRYAt956K/feey+zZ8/mmGOO2WmGN954g82bN5ORkQHA2Wefzfjx4znnnHOiP589ezYLFy6kZcuWAOyzzz7R4//5z3/SpUsXHnjggei2tm3b7srlF/OXv/yFgQMHFtt2ww03RNebN2/OrFmzePrppznjjDMAuPnmm7n88su55JJLovv9/Ehoz549adWqFY899hhXXXUVEBkhd/rppxd7pLWic+SYJEmSJEkqs7p06VLs9aZNm7jiiito3bo11atXp2rVqixcuHCnI8fat28fXa9SpQqpqamsWbNmlzJMmDCBvn37Ruc7O+uss3j//ff58ssvgcjIsEaNGkWLsd/6eeTYH/XbzwJgzJgxdO7cmTp16lC1alUefvjh6GexZs0aVq5cucP3Hjx4MBMnTgRg9erVvPrqq5x33nl/OGt54sgxSZIkSZIqoJSEeD6/MSOw9y4tVapUKfb6iiuu4PXXX+fOO++kRYsWpKSkcNppp5Gfn7/D8/x28vpQKERRUdFO33/Dhg1MnTqVgoICHnzwwej2wsJCJkyYwC233EJKSsoOz7Gzn8fFxf3uUdSCgoLf7ffbz2Ly5MlcccUV3HXXXfTo0YNq1apxxx138OGHH+7S+wL079+fa665hlmzZjFz5kyaN2/OIYccstPjKhLLMUmSJEmSKqBQKFRqjzaWJe+//z7nnnsuJ598MhAZSfbNN9/ssfd74oknaNSoES+88EKx7a+99hp33XUXN954I+3bt+fbb79lyZIl2xw91r59ezIzM4s9AvlrderUKTbvV05ODl9//fVOs73//vv07NmTv/71r9FtP49mA6hWrRrNmjUjMzOTI444YpvnqFWrFn369GHixInMmjXrd49txoKK90+JJEmSJEmqsPbbbz+ef/55evfuTSgU4tprr92lEWC7a/z48Zx22mkccMABxbY3btyYESNGMH36dI4//ngOPfRQTj31VO6++25atGjBokWLCIVCHHPMMYwYMYJ27drx17/+lQsuuIDExETeeustTj/9dGrXrs2RRx7JpEmT6N27N9WrV2fkyJHRyfx3ZL/99uPRRx9lxowZNG/enMcee4w5c+bQvHnz6D7XX389F1xwAXXr1uXYY4/lhx9+4P333+fiiy+O7jN48GBOOOEECgsLGTBgQOl9eOWEc45JkiRJkqRy4+6776ZGjRr07NmT3r17k5GRQadOnfbIe82dO5ePP/6YU0899Xc/S0tL46ijjmL8+PEAPPfcc3Tt2pWzzjqLNm3acNVVV0W/jbJly5a89tprfPzxx3Tr1o0ePXrwn//8JzqH2YgRIzjssMM44YQTOP744+nTpw/77rvvTvOdf/75nHLKKfTt25fu3buzfv36YqPIAAYMGMDo0aN54IEHaNu2LSeccAJffPFFsX169epF/fr1ycjIoEGDBrv1WZVnoXBpfr9qgHJyckhLSyM7O5vU1NSg40iSpHLA+4fywd+TJO2aLVu28PXXX9O8eXOSk5ODjqNyZNOmTTRs2JCJEydyyimnBB1nl+3oz3xJ7h98rFKSJEmSJCkGFRUVsW7dOu666y6qV6/OiSeeGHSkQPhYpSRJkiRJilkXXHABVatW3eZywQUXBB1vj1q+fDnp6ek8+eSTTJgwIfqYZ6yJzauWJEmSJEkCbrzxRq644opt/qyiP87frFkzKshsW3+I5ZgkSZIkSYpZdevWpW7dukHHUIB8rFKSJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIkSTHLckySJEmSJEkxy3JMkiRJkiRJMctyTJIkSZIklVuHH344l156afR1s2bNGD169A6PCYVCvPDCC3/4vUvrPAqW5ZgkSZIkSQpE7969OeaYY7b5s3fffZdQKMQnn3xSonPOmTOHoUOHlka8qOuvv56OHTv+bvuqVas49thjS/W9dsVTTz1FfHw8w4YN2+vvXRHtVjk2ZswYmjVrRnJyMt27d2f27Nk73H/jxo0MGzaM+vXrk5SURMuWLXnllVf+0DklSZIkSVL5NmjQIF5//XW+/fbb3/1s4sSJdOnShfbt25fonHXq1KFy5cqlFXGH6tWrR1JS0l55r18bP348V111FU899RRbtmzZ6+//a/n5+YG+f2kocTk2ZcoUhg8fznXXXce8efPo0KEDGRkZrFmzZpv75+fnc/TRR/PNN9/w7LPPsnjxYsaNG0fDhg13+5ySJEmSJKn8O+GEE6hTpw6TJk0qtn3Tpk0888wz9OnTh7POOouGDRtSuXJl2rVrx1NPPbXDc/72scovvviCQw89lOTkZNq0acPrr7/+u2OuvvpqWrZsSeXKldlnn3249tprKSgoAGDSpEnccMMNfPzxx4RCIUKhUDTvbx+rXLBgAUceeSQpKSnUqlWLoUOHsmnTpujPzz33XPr06cOdd95J/fr1qVWrFsOGDYu+1674+uuvmTlzJtdccw0tW7bk+eef/90+EyZMoG3btiQlJVG/fn0uuuii6M82btzI+eefT3p6OsnJyRxwwAG89NJLwLZHyI0ePZpmzZr97hpuueUWGjRoQKtWrQB47LHH6NKlC9WqVaNevXr85S9/+V2v89lnn3HCCSeQmppKtWrVOOSQQ/jyyy/573//S0JCAllZWcX2v/TSSznkkEN2+bPZXSUux+6++26GDBnCwIEDadOmDWPHjqVy5cpMmDBhm/tPmDCBDRs28MILL3DQQQfRrFkzDjvsMDp06LDb55QkSZIkSTsRDkN+bjBLOLxLEStVqkT//v2ZNGkS4V8d88wzz1BYWMjZZ59N586defnll/n0008ZOnQo55xzzi4/bVZUVMQpp5xCYmIiH374IWPHjuXqq6/+3X7VqlVj0qRJfP7559xzzz2MGzeOf/3rXwD07duXyy+/nLZt27Jq1SpWrVpF3759f3eO3NxcMjIyqFGjBnPmzOGZZ57hjTfeKFZMAbz11lt8+eWXvPXWWzzyyCNMmjTpd+XgjkycOJHjjz+etLQ0zj77bMaPH1/s5w8++CDDhg1j6NChLFiwgGnTptGiRYvo53Hsscfy/vvv8/jjj/P5559z2223ER8fv8vvD5CZmcnixYt5/fXXo8VaQUEBN910Ex9//DEvvPAC33zzDeeee270mO+++45DDz2UpKQk3nzzTebOnct5553H1q1bOfTQQ9lnn3147LHHovsXFBTwxBNPcN5555Uo2+6oVJKd8/PzmTt3LiNGjIhui4uLo1evXsyaNWubx0ybNo0ePXowbNgw/vOf/1CnTh3+8pe/cPXVVxMfH79b5wTIy8sjLy8v+jonJ6cklyJJkiRJUsVWsBlubRDMe//fSkissku7nnfeedxxxx288847HH744UCkADr11FNp2rQpV1xxRXTfiy++mBkzZvD000/TrVu3nZ77jTfeYNGiRcyYMYMGDSKfxa233vq7ecL+8Y9/RNebNWvGFVdcweTJk7nqqqtISUmhatWqVKpUiXr16m33vZ588km2bNnCo48+SpUqkWu///776d27N7fffjvp6ekA1KhRg/vvv5/4+Hj2339/jj/+eDIzMxkyZMhOr6eoqIhJkyZx3333AXDmmWdy+eWX8/XXX9O8eXMAbr75Zi6//HIuueSS6HFdu3aNfh6zZ89m4cKFtGzZEoB99tlnp+/7W1WqVOHf//43iYmJ0W2/LrH22Wcf7r33Xrp27cqmTZuoWrUqY8aMIS0tjcmTJ5OQkAAQzQCRR2wnTpzIlVdeCcCLL77Ili1bOOOMM0qcr6RKNHJs3bp1FBYWRn+hP0tPT//d0LefffXVVzz77LMUFhbyyiuvcO2113LXXXdx88037/Y5AUaNGkVaWlp0ady4cUkuRZIkSZIklQH7778/PXv2jD49tnTpUt59910GDRpEYWEhN910E+3ataNmzZpUrVqVGTNmsHz58l0698KFC2ncuHG0GAPo0aPH7/abMmUKBx10EPXq1aNq1ar84x//2OX3+PV7dejQIVqMARx00EEUFRWxePHi6La2bdsWG6lVv379XZ5W6vXXXyc3N5fjjjsOgNq1a3P00UdHP7s1a9awcuVKjjrqqG0eP3/+fBo1alSslNod7dq1K1aMAcydO5fevXvTpEkTqlWrxmGHHQYQ/Rznz5/PIYccEi3Gfuvcc89l6dKlfPDBB0DkcdYzzjij2Oe5p5Ro5NjuKCoqom7dujz88MPEx8fTuXNnvvvuO+644w6uu+663T7viBEjGD58ePR1Tk6OBZkkSZIkST9LqBwZwRXUe5fAoEGDuPjiixkzZgwTJ05k33335bDDDuP222/nnnvuYfTo0bRr144qVapw6aWXluok8LNmzaJfv37ccMMNZGRkREc33XXXXaX2Hr/223IoFApRVFS0S8eOHz+eDRs2kJKSEt1WVFTEJ598wg033FBs+7bs7OdxcXHFHm8Ftjkf2m8Lq58fKc3IyOCJJ56gTp06LF++nIyMjOjvamfvXbduXXr37s3EiRNp3rw5r776Km+//fYOjyktJSrHateuTXx8PKtXry62ffXq1dsdWli/fn0SEhKKtaKtW7cmKyuL/Pz83TonQFJSUiDfCCFJkiRJUrkQCu3yo41BO+OMM7jkkkt48sknefTRR7nwwgsJhUK8//77nHTSSZx99tlApAhasmQJbdq02aXztm7dmhUrVrBq1Srq168PEB2Z9LOZM2fStGlT/v73v0e3LVu2rNg+iYmJFBYW7vS9Jk2aRG5ubrQ8ev/994mLi4tOWv9HrF+/nv/85z9MnjyZtm3bRrcXFhZy8MEH89prr3HMMcfQrFkzMjMzOeKII353jvbt2/Ptt9+yZMmSbY4eq1OnDllZWYTDYUKhEBAZ8bUzixYtYv369dx2223RgUsfffTR7977kUceoaCgYLujxwYPHsxZZ51Fo0aN2HfffTnooIN2+t6loUSPVSYmJtK5c2cyMzOj24qKisjMzNzmsESIDCFcunRpsRZ0yZIl1K9fn8TExN06pyRJkiRJqjiqVq1K3759GTFiBKtWrYpO5L7ffvvx+uuvM3PmTBYuXMj555//u8E1O9KrVy9atmzJgAED+Pjjj3n33XeLlWA/v8fy5cuZPHkyX375Jffeey9Tp04ttk+zZs34+uuvmT9/PuvWrSs2B/rP+vXrR3JyMgMGDODTTz/lrbfe4uKLL+acc8753VRSu+Oxxx6jVq1anHHGGRxwwAHRpUOHDhx33HHRifmvv/567rrrLu69916++OIL5s2bF52j7LDDDuPQQw/l1FNP5fXXX+frr7/m1VdfZfr06QAcfvjhrF27ln/+8598+eWXjBkzhldffXWn2Zo0aUJiYiL33XcfX331FdOmTeOmm24qts9FF11ETk4OZ555Jh999BFffPEFjz32WLFHTjMyMkhNTeXmm29m4MCBf/gz21Ul/rbK4cOHM27cOB555BEWLlzIhRdeSG5ubjR0//79i02uf+GFF7JhwwYuueQSlixZwssvv8ytt97KsGHDdvmckiRJkiSpYhs0aBDff/89GRkZ0TnC/vGPf9CpUycyMjI4/PDDqVevHn369Nnlc8bFxTF16lR+/PFHunXrxuDBg7nllluK7XPiiSdy2WWXcdFFF9GxY0dmzpzJtddeW2yfU089lWOOOYYjjjiCOnXq8NRTT/3uvSpXrsyMGTPYsGEDXbt25bTTTuOoo47i/vvvL/mHsQ0TJkzg5JNPjo7o+m2+adOmsW7dOgYMGMDo0aN54IEHaNu2LSeccAJffPFFdN/nnnuOrl27ctZZZ9GmTRuuuuqq6Ki41q1b88ADDzBmzBg6dOjA7Nmzi30hwvbUqVOHSZMm8cwzz9CmTRtuu+027rzzzmL71KpVizfffJNNmzZx2GGH0blzZ8aNG1dsFFlcXBznnnsuhYWF9O/ff3c/qhILhX/7MOkuuP/++7njjjvIysqiY8eO3HvvvXTv3h2ItIzNmjUr9jWks2bN4rLLLmP+/Pk0bNiQQYMGRb+tclfOuStycnJIS0sjOzub1NTUkl6SJEmKQd4/lA/+niRp12zZsiX6rYXJyclBx5F2y6BBg1i7di3Tpk3b6b47+jNfkvuH3SrHyiJvmiRJUkl5/1A++HuSpF1jOabyLDs7mwULFnD00Uczbdo0jj766J0eU1rl2B7/tkpJkiRJkiTt2Lvvvsuxxx673Z9v2rRpL6bZ+0466SRmz57NBRdcsEvFWGmyHJMkSZIkSQpYly5ddumbISuqt99+O7D3thyTJEmSJEkKWEpKCi1atAg6Rkwq8bdVSpIkSZIkSRWF5ZgkSZIkSRVIUVFR0BGkvaK0/qz7WKUkSZIkSRVAYmIicXFxrFy5kjp16pCYmEgoFAo6llTqwuEw+fn5rF27lri4OBITE//Q+SzHJEmSJEmqAOLi4mjevDmrVq1i5cqVQceR9rjKlSvTpEkT4uL+2IORlmOSJEmSJFUQiYmJNGnShK1bt1JYWBh0HGmPiY+Pp1KlSqUyOtJyTJIkSZKkCiQUCpGQkEBCQkLQUaRywQn5JUmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMckSZIUNWbMGJo1a0ZycjLdu3dn9uzZ29338MMPJxQK/W45/vjjo/uEw2FGjhxJ/fr1SUlJoVevXnzxxRd741IkSZJ2ieWYJEmSAJgyZQrDhw/nuuuuY968eXTo0IGMjAzWrFmzzf2ff/55Vq1aFV0+/fRT4uPjOf3006P7/POf/+Tee+9l7NixfPjhh1SpUoWMjAy2bNmyty5LkiRphyzHJEmSBMDdd9/NkCFDGDhwIG3atGHs2LFUrlyZCRMmbHP/mjVrUq9evejy+uuvU7ly5Wg5Fg6HGT16NP/4xz846aSTaN++PY8++igrV67khRde2ItXJkmStH2WY5IkSSI/P5+5c+fSq1ev6La4uDh69erFrFmzdukc48eP58wzz6RKlSoAfP3112RlZRU7Z1paGt27d9/hOfPy8sjJySm2SJIk7SmWY5IkSWLdunUUFhaSnp5ebHt6ejpZWVk7PX727Nl8+umnDB48OLrt5+NKes5Ro0aRlpYWXRo3blySS5EkSSoRyzFJkiT9YePHj6ddu3Z069btD59rxIgRZGdnR5cVK1aUQkJJkqRtsxyTJEkStWvXJj4+ntWrVxfbvnr1aurVq7fDY3Nzc5k8eTKDBg0qtv3n40p6zqSkJFJTU4stkiRJe4rlmCRJkkhMTKRz585kZmZGtxUVFZGZmUmPHj12eOwzzzxDXl4eZ599drHtzZs3p169esXOmZOTw4cffrjTc0qSJO0tlYIOIEmSpLJh+PDhDBgwgC5dutCtWzdGjx5Nbm4uAwcOBKB///40bNiQUaNGFTtu/Pjx9OnTh1q1ahXbHgqFuPTSS7n55pvZb7/9aN68Oddeey0NGjSgT58+e+uyJEmSdshyTJIkSQD07duXtWvXMnLkSLKysujYsSPTp0+PTqi/fPly4uKKP3iwePFi3nvvPV577bVtnvOqq64iNzeXoUOHsnHjRg4++GCmT59OcnLyHr8eSZKkXREKh8PhoEOUhpycHNLS0sjOznZeiormu7nw2VRIqQmNu0GDTpBYOehUkqQKwPuH8sHfkyRJKqmS3D84ckxl09a8SCE2++FIOfZrcZUg/YBIUdaoGzTuCtWbQigUTFZJkiRJklRuWY6pbMn+Fj6aCHMnweZ1kW3xidD6RCjMh2/nwA+rYNX8yDL74cg+Ver+VJZ1hcbdoUFHSEgJ5hokSZIkSVK5YTmm4IXD8M17kaJr0csQLoxsT20IXc6DTgOgap1f9s3+Fr6dDSvmRP531SeQuwYWvRRZIDK6rF77XxVm3SCtsaPLJEmSJElSMZZjCk7eJvhkCsweB2sX/rK92SHQbSi0Og7if/NHNBSC6o0jywGnRrYV/AirPoYVH8KK2ZHRZZtWw8p5keXDsZH9qtaLPILZqFtkdFn9DpDgZMCSJEmSJMUyyzHtfeu/hDn/hv89AXnZkW0JlaHDmdB1CKS3Kdn5ElKgyZ8iC0RGl21cHinJVsyOjC7LWgCbsmDhi5EFIC4hUpAVG13WqPSuU5IkSZIklXmWY9o7iopg6euRRyeXvvHL9pr7Qrch0OEsSKleOu8VCkGNppGl3WmRbfmbYeX/ij+OmbsWvvsosvysWoPfjC5rD5WSSieXJEmSJEkqcyzHtGf9+D387/HISLHvv/lpYwj2+zN0Hwr7HAlxcXs+R2JlaHZQZIHI6LLvv/nN6LJP4YeV8Pl/IgtEvgygfsfio8tSG+z5vJIkSZIkaa+wHNOekbUgMpfYJ0/D1h8j25LT4MBzoOsgqLlPsPlCIajZPLK0PyOyLT8XvptXfHTZ5vWR//129i/HpjYqPrqsXjuolBjMdUiSJEmSpD/Eckylp7AgMp/X7HGwfOYv29MPiEyw3+70yAiusiqxCjQ/JLJAZHTZhq+Kjy5b/RnkfAuffQufTY3sVyn5p9FlPxdm3aBavcAuQ5IkSZIk7TrLMf1xP6yGuZNg7kT4YVVkW1wlaN0bup0fmSg/FAo04m4JhaDWvpGlw5mRbXmb4Lu5xUeX/fg9rPggsvwsrUnxsqxeO4hPCOY6JEmSJEnSdlmOafeEw5ERVbMfhs9egKKCyPYqdaHLQOh8bsWcmyupKuxzWGSByOew/sufyrLZkc9kzeeQvTyyfPpcZL9KKdDgwOKFWdW6wV2HJEmSJEkCLMdUUgU/Rgqf2Q/Dqo9/2d64e+TRydYnxtb8W6EQ1G4RWTr+JbJtS85Po8vm/FKYbdkYedT014+bVm/600T/P5Vl6QdAvP9ISpIkSZK0N/k3ce2a75fBR+Nh3qORxwgB4pMi84h1GwINOgYar0xJToV9j4gsAEVFsH7pb0aXLYSNyyLLgmci+yVUhgadio8uq1I7uOuQJEmSJCkGWI5p+8Jh+OrtyAT7S16FcFFke1qTyDdOduoPlWsGGrFciIuDOi0jy4FnR7ZtyYZvP/rV6LKPIC8blr0XWX5Wo/lPo8u6Rkbn1W3j6DJJkiRJkkqRf8vW723JgY8nw5xxsG7JL9v3OSLy6GTLDIiLDy5fRZCcBi2OiiwQGV22bknx0WVrF8H3X0eWT6ZE9kuoAg07/fI4ZqOuUKVWcNchSZIkSVI5ZzmmX6xdEplL7OOnIH9TZFti1chcWl2HREY+ac+Ii4O6+0eWTv0j2378Hr6d+0th9t1cyMuBb96NLD+rue9vRpe1tryUJEmSJGkXWY7FuqJCWDI9Uop99fYv22u3jIwSa983MoeW9r6UGrBfr8gCkd/V2sU/lWVzYMWHsP4L2PBlZPn4qch+idV+M7qsi4+/SpIkSZK0HZZjsSp3PfzvUZgzAbKXR7aF4qDVcZEJ9psfFvkmRpUdcfGQ3iaydD43sm3zhp/mLvvV6LL8H+DrdyLLz2rtV3x0WZ39I6PVJEmSJEmKcZZjsWbl/MgosQXPQmFeZFtKzcijfF0HQfUmgcZTCVWuCS3/HFkgMrpszcLio8s2fBkZYbb+C5j/RGS/pFRo2Ln46LKU6oFdhiRJkiRJQbEciwVb8+Hz/0RKsW9n/7K9fgfodj4ccAokpASXT6UnLh7qHRBZupwX2Za7PjLBf3R02bzI3GVfvRVZfla7FTTuGinLGnePPFrr6DJJkiRJUgVnOVaR5ayEjybC3EmQuyayLS4B2p4cmU+sURcfnYwFVWpBq2MiC0DhVljzefHRZd9/DesWR5b/PR7ZLzkNGnb55XHM5odCfEJw1yFJkiRJ0h5gOVbRhMOwfBZ8+BAsfBHChZHt1epHRhJ1Pheq1g00ogIWXwnqt48sXQdHtm1a+6vRZXNg5TzYkg1fZkYWiIwmG/AiVEoKLrskSZIkSaXMcqyiyM+FBc/A7HGw+tNftjc9KDLB/v4nOOpH21e1Dux/XGSByOiy1Z9GCrMVs2Hxq5ERZq9cCSfeG2xWSZIkSZJKkeVYebfhK5gzHv73WGSkD0ClFOjQF7oOicw9JZVUfCVo0DGydBsCX7wBT5wG8x6Bhp1++bZMSZIkSZLKOcux8qioCL58E2Y/BF+8DoQj22s0ixRiB/aDlBpBJlRFs18vOPIf8OZNkdFj6QdE5qyTJEmSJKmcsxwrT37cCPOfhDnjIiPGftbi6MgE+y16+e2C2nMOuRxW/g8WvQRTzoHz33H+OkmSJElSuWc5Vh6s/iwyl9gnU6Bgc2RbUhoceDZ0HQS19g02n2JDKAR9HoR/L4F1S+CZgdD/BeeykyRJkiSVa5ZjZVXhVlj8Mnz4MCx775ftddtE5oBqdwYkVQ0un2JTcir0fQLGHRn5c/n6SDhmVNCpJEmSJEnabZZjZc2mtTBvEnw0EXK+i2wLxUPrEyKPTjY9KDKCRwpKnZZw8oMw5Wz44AFo0Ananx50KkmSJEmSdovlWFnx7Ucw+2H4bCoU5ke2VakT+VbAzgMhrWGg8aRiWveOzEH27l0w7WKouz/Uaxd0KkmSJEmSSsxyLEgFWyJl2OyHYeW8X7Y37BIZJda2D1RKCiyetENH/B1WzocvM2FyPxj6NlSuGXQqSZIkSZJKxHIsCBtXwEcTYN4jsHl9ZFt8EhxwKnQbDA07B5tP2hVx8XDqv+Hhw2HjMnh+CPzl6ch2SZIkSZLKibjdOWjMmDE0a9aM5ORkunfvzuzZs7e776RJkwiFQsWW5OTkYvts2rSJiy66iEaNGpGSkkKbNm0YO3bs7kQru8Jh+OqdyAibe9rDe3dHirHURnDUdTD888g8ThZjKk8q14Qzn4BKKbD0DXjr1qATSZIkSZJUIiUeOTZlyhSGDx/O2LFj6d69O6NHjyYjI4PFixdTt27dbR6TmprK4sWLo69Dv5lQfvjw4bz55ps8/vjjNGvWjNdee42//vWvNGjQgBNPPLGkEcuWvE3wyWSYPQ7WLvple/NDI49OtjwW4h3Ap3KsXjs48d7IyLF374QGB0a+QEKSJEmSpHKgxCPH7r77boYMGcLAgQOjI7wqV67MhAkTtntMKBSiXr160SU9Pb3Yz2fOnMmAAQM4/PDDadasGUOHDqVDhw47HJFW5q37Al69Gu5uDS9fHinGEqpAl0Hw1w9gwIuRSc0txlQRtD8Dul8YWZ96AaxdEmweSZIkSZJ2UYnKsfz8fObOnUuvXr1+OUFcHL169WLWrFnbPW7Tpk00bdqUxo0bc9JJJ/HZZ58V+3nPnj2ZNm0a3333HeFwmLfeeoslS5bw5z//uYSXE7CiQlj8Kjx2MtzfBT4cC3k5UHNfOOZ2uHwhnHA31G0ddFKp9P35Jmh6EOT/AFP6Qd4PQSeSJEmSJGmnSjRsad26dRQWFv5u5Fd6ejqLFi3a5jGtWrViwoQJtG/fnuzsbO6880569uzJZ599RqNGjQC47777GDp0KI0aNaJSpUrExcUxbtw4Dj300O1mycvLIy8vL/o6JyenJJdSujZvgP89DnP+HZmYHIAQtDwGug2BfY6AuN2a3k0qP+IT4PRJ8NChsG4JvHAhnPEY/OYxakmSJEmSypI9/kxfjx496NGjR/R1z549ad26NQ899BA33XQTECnHPvjgA6ZNm0bTpk3573//y7Bhw2jQoEGxUWq/NmrUKG644YY9HX/HVn0Csx+GBc/A1i2RbcnVodM50HUw1GgWZDpp76taN1KITTwWFr4I7/0LDhkedCpJkiRJkrarROVY7dq1iY+PZ/Xq1cW2r169mnr16u3SORISEjjwwANZunQpAD/++CP/93//x9SpUzn++OMBaN++PfPnz+fOO+/cbjk2YsQIhg//5S/dOTk5NG7cuCSXs3u25sPCaZEJ9ld88Mv29HbQfSgccBokVt7zOaSyqnFXOO4OeOlSePMmqN8BWhwVdCpJkiRJkrapRM/6JSYm0rlzZzIzM6PbioqKyMzMLDY6bEcKCwtZsGAB9evXB6CgoICCggLifvPYYXx8PEVFRds9T1JSEqmpqcWWPeqHLHj7NhjdDp4bFCnG4irBAafCeTPggnehU3+LMQmgy8DIPw/hInj2PPj+m6ATSZIkSZK0TSV+rHL48OEMGDCALl260K1bN0aPHk1ubi4DBw4EoH///jRs2JBRo0YBcOONN/KnP/2JFi1asHHjRu644w6WLVvG4MGDAUhNTeWwww7jyiuvJCUlhaZNm/LOO+/w6KOPcvfdd5fipf4B794Nb90CRVsjr6umQ+eBkQKg2q6NmJNizrF3QNansHIeTDkbznvN8liSJEmSVOaUuBzr27cva9euZeTIkWRlZdGxY0emT58enaR/+fLlxUaBff/99wwZMoSsrCxq1KhB586dmTlzJm3atInuM3nyZEaMGEG/fv3YsGEDTZs25ZZbbuGCCy4ohUssBbVbRoqxxn+KTLDf+kSolBh0KqlsS0iGvo/BQ4dB1oLIY5YnP+QE/ZIkSZKkMiUUDofDQYcoDTk5OaSlpZGdnV36j1gWFcLqz6B++9I9rxQLvn4XHj0JwoVw7D+h+/lBJ5KkqD16/6BS4+9JkiSVVEnuH0o051jMiou3GJN2V/ND4M+Rb6Zlxv/BspnB5pEkSZIk6VcsxyTteX/6a+TLK4q2wtMDIGdl0IkkSZIkSQIsxyTtDaEQnHgfpB8AuWvg6f6wNS/oVJIkSZIkWY5J2ksSq0Qm6E9Og2/nwPRrgk4kSZIkSZLlmKS9qOY+cOp4IAQfTYB5jwWdSJIkSZIU4yzHJO1d+x0NR/w9sv7ycPhubrB5JEmSJEkxzXJM0t53yOXQ6jgozIcp58CmtUEnkiRJkiTFKMsxSXtfXBycPBZqtYCc7+DZgVC4NehUkiRJkqQYZDkmKRjJadD3CUisCt+8C29cF3QiSZIkSVIMshyTFJy6+0OfByLrs+6HBc8Gm0eSJEmSFHMsxyQFq81JcPBlkfVpF8Pqz4LNI0mSJEmKKZZjkoJ35LWwzxFQsBkm94Mfvw86kSRJkiQpRliOSQpeXDycNgHSmsD3X8PzQ6GoKOhUkiRJkqQYYDkmqWyoXBPOfBwqJcMXr8E7twWdSJIkSZIUAyzHJJUd9TtA73si6+/cDoteCTaPJEmSJKnCsxyTVLZ0OBO6DY2sTz0f1i0NNo8kSZIkqUKzHJNU9mTcCk16QF4OTOkHeT8EnUiSJEmSVEFZjkkqe+IT4PRHoGo9WLsI/jMMwuGgU0mSJEmSKiDLMUllU7V06PsYxCXA5/+B9+8JOpEkSZIkqQKyHJNUdjXuBsfeHlnPvAG+fDPYPJIkSZKkCsdyTFLZ1uU86Hg2hIvg2UHw/bKgE0mSJEmSKhDLMUllWygEx98FDQ6EHzfAlLOh4MegU0mSJEmSKgjLMUllX0IynPEYVK4FWZ/AS5c5Qb8kSZIkqVRYjkkqH6o3htMmQigOPn4K5vw76ESSJEmSpArAckxS+bHPYdDrhsj69Gtg+QfB5pEkSZIklXuWY5LKl54XQ9tToGgrPN0fclYFnUiSJEmSVI5ZjkkqX0IhOOl+qNsGNq2GZwbA1vygU0mSJEmSyinLMUnlT2IV6Ps4JKXBig9hxoigE0mSJEmSyinLMUnlU6194dRxkfU5/4b/PRFsHkmSJElSuWQ5Jqn8apkBh/80auyly2Dl/4LNI0mSJEkqdyzHJJVvh14FLY+BwjyYcg7krgs6kSRJkiSpHLEck1S+xcXByQ9BzX0hewU8ex4Ubg06lSRJkiSpnLAck1T+pVSHM5+AhCrw9TuQeUPQiSRJkiRJ5YTlmKSKoW5r6DMmsj7zXvhsarB5JEmSJEnlguWYpIqj7cnQ82+R9ReGwerPg80jSZIkSSrzLMckVSxHXQfND4OCXJjSD37cGHQiSZIkSVIZZjkmqWKJrwSnTYS0xrDhK5h6PhQVBZ1KkiRJklRGWY5Jqniq1IK+j0F8EiyZDv/9Z9CJJEmSJElllOWYpIqpwYFwwr8i62+PgsXTg80jSZIkSSqTLMckVVwH9oOugyPrzw+F9V8Gm0eSJEmSVOZYjkmq2DJGQePukJcNU86GvE1BJ5IkSZIklSGWY5IqtkqJcPojUDUd1nwO0y6CcDjoVJIkSZKkMsJyTFLFl1ofzngU4irBZ1Nh5n1BJ5IkSZIklRGWY5JiQ5M/wTG3RdbfuA6+eifYPJIkSZKkMsFyTFLs6DoYOvwFwkXw7EDYuCLoRJIkSZKkgFmOSYodoRCccDfU7wCb10cm6C/YEnQqSZIkSVKALMckxZaEFOj7OKTUhFXz4eXLnaBfkiRJkmKY5Zik2FO9CZw2AUJxMP9x+GhC0IkkSZIkSQGxHJMUm/Y9Ao66LrL+6tWwYnaweSRJkiRJgbAckxS7DroE2pwERQUw5Rz4ISvoRJIkSZKkvcxyTFLsCoXgpDFQZ3/YlAVPD4Ct+UGnkiRJkiTtRZZjkmJbUjXo+wQkpcKKD+C1vwedSJIkSZK0F1mOSVLtFnDyQ5H12Q/D/KeCzSNJkiRJ2mssxyQJYP/j4LCrI+svXQor5weZRpIkSZK0l1iOSdLPDrsG9vszbN0SmaB/84agE0mSJEmS9jDLMUn6WVwcnPIw1GgO2cvh2fOgqDDoVJIkSZKkPchyTJJ+LaUGnPkEJFSGr96CN28KOpEk7VVjxoyhWbNmJCcn0717d2bPnr3D/Tdu3MiwYcOoX78+SUlJtGzZkldeeSX688LCQq699lqaN29OSkoK++67LzfddBPhcHhPX4okSdIuqRR0AEkqc9Lbwon3wXOD4L1/QYMDoc1JQaeSpD1uypQpDB8+nLFjx9K9e3dGjx5NRkYGixcvpm7dur/bPz8/n6OPPpq6devy7LPP0rBhQ5YtW0b16tWj+9x+++08+OCDPPLII7Rt25aPPvqIgQMHkpaWxt/+9re9eHWSJEnbZjkmSdvS7jRY+T+YdT+88Feo3Qrq7h90Kknao+6++26GDBnCwIEDARg7diwvv/wyEyZM4Jprrvnd/hMmTGDDhg3MnDmThIQEAJo1a1Zsn5kzZ3LSSSdx/PHHR3/+1FNP7XREmiRJ0t7iY5WStD29boBmh0D+JpjSD7ZkB51IkvaY/Px85s6dS69evaLb4uLi6NWrF7NmzdrmMdOmTaNHjx4MGzaM9PR0DjjgAG699VYKC3+Zr7Fnz55kZmayZMkSAD7++GPee+89jj322O1mycvLIycnp9giSZK0p1iOSdL2xFeC0ydBaiNYvxSmXgBFRUGnkqQ9Yt26dRQWFpKenl5se3p6OllZWds85quvvuLZZ5+lsLCQV155hWuvvZa77rqLm2++ObrPNddcw5lnnsn+++9PQkICBx54IJdeein9+vXbbpZRo0aRlpYWXRo3blw6FylJkrQNlmOStCNVakPfxyA+CRa/Au/eFXQiSSozioqKqFu3Lg8//DCdO3emb9++/P3vf2fs2LHRfZ5++mmeeOIJnnzySebNm8cjjzzCnXfeySOPPLLd844YMYLs7OzosmLFir1xOZIkKUY555gk7UzDTnD8XTDtInjrFmjQEfY7OuhUklSqateuTXx8PKtXry62ffXq1dSrV2+bx9SvX5+EhATi4+Oj21q3bk1WVhb5+fkkJiZy5ZVXRkePAbRr145ly5YxatQoBgwYsM3zJiUlkZSUVEpXJkmStGOOHJOkXdHpHOhyHhCOfIvlhq+CTiRJpSoxMZHOnTuTmZkZ3VZUVERmZiY9evTY5jEHHXQQS5cupehXj5wvWbKE+vXrk5iYCMDmzZuJiyt+yxkfH1/sGEmSpCBZjknSrjrmNmjUNTIx/+SzIT836ESSVKqGDx/OuHHjeOSRR1i4cCEXXnghubm50W+v7N+/PyNGjIjuf+GFF7JhwwYuueQSlixZwssvv8ytt97KsGHDovv07t2bW265hZdffplvvvmGqVOncvfdd3PyySfv9euTJEnaFh+rlKRdVSkJzngUHjoM1nwG0y6GU8dDKBR0MkkqFX379mXt2rWMHDmSrKwsOnbsyPTp06OT9C9fvrzYKLDGjRszY8YMLrvsMtq3b0/Dhg255JJLuPrqq6P73HfffVx77bX89a9/Zc2aNTRo0IDzzz+fkSNH7vXrkyRJ2pZQOBwOBx2iNOTk5JCWlkZ2djapqalBx5FUkS2bCY/0hqKtkHEr9Bi282MklUneP5QP/p4kSVJJleT+wccqJamkmvaMlGIAr10LX/832DySJEmSpN1mOSZJu6PbUGh/JoQL4ZmBkP1t0IkkSZIkSbvBckySdkcoBCf8C+q1g83rYMo5ULAl6FSSJEmSpBKyHJOk3ZVYGfo+Dik1YOU8ePXKoBNJkiRJkkrIckyS/ogazX76xso4mPcofDQx6ESSJEmSpBKwHJOkP6rFUXDktZH1V66EFXOCzSNJkiRJ2mWWY5JUGg6+DFr3hqICePoc2LQm6ESSJEmSpF1gOSZJpSEUgj4PQu1W8MMqeHoAFBYEnUqSJEmStBOWY5JUWpKqwZlPQGI1WD4TXrs26ESSJEmSpJ2wHJOk0lR7Pzjlocj6hw/Cx1OCzSNJkiRJ2iHLMUkqbfsfD4deGVl/8RJY9UmweSRJkiRJ22U5Jkl7wuEjoEUv2PojTDkbNm8IOpEkSZIkaRssxyRpT4iLh1PGQY1msHEZPDcIigqDTiVJkiRJ+g3LMUnaUyrXhL6PQ6UU+PJNeOuWoBNJkiRJkn7DckyS9qR67eCk+yPr794FC18MNo8kSZIkqRjLMUna09qdBn8aFlmfegGsXRJsHkmSJElSlOWYJO0NR98ATQ+G/E0w+S+wJSfoRJIkSZIkLMckae+IT4DTJ0G1BrD+C3jhQigqCjqVJEmSJMU8yzFJ2luq1olM0B+fCItegvfuDjqRJEmSJMU8yzFJ2psadYbj7oysv3kzLH0j2DySJEmSFOMsxyRpb+s8ADoNAMLw7CDY8HXQiSRJkiQpZlmOSVIQjrsDGnaGLRthyjmQvznoRJIkSZIUkyzHJCkIlZLgjMegSh1YvQBe/BuEw0GnkiRJkqSYYzkmSUFJaxj5BstQPCx4Bj4cG3QiSZIkSYo5lmOSFKRmB0PGLZH1GX+Hb94LNo8kSZIkxRjLMUkKWvcLoN3pEC6EZ86F7O+CTiRJkiRJMcNyTJKCFgpB73shvR3kroWn+8PWvKBTSZIkSVJMsByTpLIgsTL0fQySq8N3H8GrVwWdSJIkSZJiguWYJJUVNZvDqeOBEMydBHMfCTqRJEmSJFV4lmOSVJbs1wuO/Htk/ZUr4Nu5weaRJEmSpArOckySypqDL4f9T4DCfHj6HNi0NuhEkiRJklRhWY5JUlkTFwd9HoRa+0HOd5FvsCzcGnQqSZIkSaqQKgUdQJK0DcmpcOYTMO5IWPYe/PtISG0IiVV+Wqr+av23r6tCQuXi2xNSIt+KKUmSJEkqZrfKsTFjxnDHHXeQlZVFhw4duO++++jWrds29500aRIDBw4sti0pKYktW7YU27Zw4UKuvvpq3nnnHbZu3UqbNm147rnnaNKkye5ElKTyr04rOHksTDkHVn0cWXZbaOeF2nZ/tp3tCVUg3v/GIkmSJKl8K/HfaqZMmcLw4cMZO3Ys3bt3Z/To0WRkZLB48WLq1q27zWNSU1NZvHhx9HXoN6MXvvzySw4++GAGDRrEDTfcQGpqKp999hnJyckljSdJFUvr3vDXWbD6M8jfBPm5Py3bW99c/HVB7k8nCkP+D5GlNFVK3vWy7bej2ba3XinJUW6SJEmS9ppQOBwOl+SA7t2707VrV+6//34AioqKaNy4MRdffDHXXHPN7/afNGkSl156KRs3btzuOc8880wSEhJ47LHHSpb+V3JyckhLSyM7O5vU1NTdPo8kVShFRVCweRsl2o4Ktk2/OmYbP8vbBOHCPZc5FF+CkWy7ULb9PMotzmk29XveP5QP/p4kSVJJleT+oUQjx/Lz85k7dy4jRoyIbouLi6NXr17MmjVru8dt2rSJpk2bUlRURKdOnbj11ltp27YtECnXXn75Za666ioyMjL43//+R/PmzRkxYgR9+vQpSTxJ0m/FxUFS1chCeumcMxyOfJPmzgq2bY1k21FBt/XHn85fCHnZkaU0RUeu/Xoutl0czdbkT1C5ZunmkSRJklQmlKgcW7duHYWFhaSnF/8LVnp6OosWLdrmMa1atWLChAm0b9+e7Oxs7rzzTnr27Mlnn31Go0aNWLNmDZs2beK2227j5ptv5vbbb2f69OmccsopvPXWWxx22GHbPG9eXh55eXnR1zk5OSW5FEnS7gqFIo8+Vkoq3cKoqHD7xVnBrox4287rcFHk/AWbI0vu2pJnq1wLhrwJNZqV3vVKkiRJKhP2+EzKPXr0oEePHtHXPXv2pHXr1jz00EPcdNNNFBVF/tJy0kkncdlllwHQsWNHZs6cydixY7dbjo0aNYobbrhhT8eXJO0tcfGRb+lMLsVHpsJh2LrlV8XZth4x3UnZtu4L+GElTO4Hg16LjCSTJEmSVGGUqByrXbs28fHxrF69utj21atXU69evV06R0JCAgceeCBLly6NnrNSpUq0adOm2H6tW7fmvffe2+55RowYwfDhw6Ovc3JyaNy48a5eiiQpFoRCkJASWarU3r1zZH8LDx8Oqz+FF/4Kp0/yCwMkSZKkCqREsxMnJibSuXNnMjMzo9uKiorIzMwsNjpsRwoLC1mwYAH169ePnrNr167Fvs0SYMmSJTRt2nS750lKSiI1NbXYIklSqUtrBGc8BnEJ8PkL8O5dQSeSJEmSVIpK/Fjl8OHDGTBgAF26dKFbt26MHj2a3NxcBg4cCED//v1p2LAho0aNAuDGG2/kT3/6Ey1atGDjxo3ccccdLFu2jMGDB0fPeeWVV9K3b18OPfRQjjjiCKZPn86LL77I22+/XTpXKUnSH9G0Bxx3B7x0Kbx5M6QfAK2OCTqVJEmSpFJQ4nKsb9++rF27lpEjR5KVlUXHjh2ZPn16dJL+5cuXExf3y4C077//niFDhpCVlUWNGjXo3LkzM2fOLPYY5cknn8zYsWMZNWoUf/vb32jVqhXPPfccBx98cClcoiRJpaDLQMhaAB+Nh+cGw5BMqNMq6FSSJEmS/qBQOBwOBx2iNOTk5JCWlkZ2draPWEqS9oyt+fDoSbB8JtTcN/INlinVg06lP8D7h/LB35MkSSqpktw/lGjOMUmSYlqlRDjjUUhtBBu+jIwgKyoMOpUkSZKkP8ByTJKkkqhaB858AiqlwNLXIfPGoBNJkiRJ+gMsxyRJKqkGHeGk+yPr74+GBc8GmUaSJEnSH2A5JknS7mh3Ghx0SWT9PxfBqo+DzSNJkiRpt1iOSZK0u466Dlr0gq0/wuR+sGlt0IkkSZIklZDlmCRJuysuHk4dH/nmyuwV8MwAKCwIOpUkSZKkErAckyTpj0ipDmc9BYnVYNn7MP2aoBNJkiRJKgHLMUmS/qg6reDUcUAI5vwb5k4KOpEkSZKkXWQ5JklSaWh1LBz598j6y1fA8g+CzSNJkiRpl1iOSZJUWg65Atr0gaICmHIOZH8XdCJJkiRJO2E5JklSaQmFoM8DkH4A5K6BKf2g4MegU0mSJEnaAcsxSZJKU2IVOPMJSKkJK/8HL14C4XDQqSRJkiRth+WYJEmlrUYzOOMRCMXDJ1Ng1pigE0mSJEnaDssxSZL2hOaHwjGjIuuvXwtLM4PNI0mSJGmbLMckSdpTug2FjmdDuAiePQ/Wfxl0IkmSJEm/YTkmSdKeEgrBCXdDo66wZSNM/gvk/RB0KkmSJEm/YjkmSdKeVCkJzngMqtaDtYtg6gVQVBR0KkmSJEk/sRyTJGlPS60f+QbL+ERY9BK8c3vQiSRJkiT9xHJMkqS9oVEXOGF0ZP2d22Dhi4HGkSRJkhRhOSZJ0t5yYD/ofmFk/fnzYfXnweaRJEmSZDkmSdJe9eebofmhUJALk8+CzRuCTiRJkiTFNMsxSZL2pvhKcPojUL0pfP8NPDsQCrcGnUqSJEmKWZZjkiTtbZVrwplPQkJl+OpteH1k0IkkSZKkmGU5JklSEOodACePjax/MAbmPxVsHkmSJClGWY5JkhSUNifBoVdG1l+8BL6dG2weSZIkKQZZjkmSFKTD/w9aHguFeTClH/yQFXQiSZIkKaZYjkmSFKS4ODjlYajdCn5YBVPOga15QaeSJEmSYoblmCRJQUtOhbOeguQ0+HY2vHw5hMNBp5IkSZJiguWYJEllQa194bQJEIqD/z0Gc/4ddCJJkiQpJliOSZJUVrToBb2uj6xPvwa+fjfQOJIkSVIssByTJKks6fk3aHc6FG2FZwbAxuVBJ5IkSZIqNMsxSZLKklAITrwP6neAzeth8l8gPzfoVJIkSVKFZTkmSVJZk5ACfZ+AKnUgawH85yIn6JckSZL2EMsxSZLKouqN4YxHIa4SfPY8vPevoBNJkiRJFZLlmCRJZVXTnnDcHZH1zBthyYxg80iSJEkVkOWYJEllWZfzoPNAIAzPDYZ1XwSdSJIkSapQLMckSSrrjv0nNOkBeTnw1FmwJTvoRJIkSVKFYTkmSVJZVykxMv9YakNY/wU8NwSKCoNOJUmSJFUIlmOSJJUHVevCmU9ApWT4Yga8eXPQiSRJkqQKwXJMkqTyosGBcOL9kfX37oZPnws2jyRJklQBWI5JklSetD8dev4tsv7CMFj1SbB5JEmSpHLOckySpPKm1/Ww71Gw9UeY3A9y1wWdSJIkSSq3LMckSSpv4uLhtPFQcx/IXg5PD4DCgqBTSZIkSeWS5ZgkSeVRSg048ylIrArL3oMZ/xd0IkmSJKlcshyTJKm8qrs/nDIusj77YZj3aLB5JEmSpHLIckySpPJs/+PgiL9H1l8aDss/DDaPJEmSVM5YjkmSVN4dcgW0PhGKCmDK2ZD9XdCJJEmSpHLDckySpPIuLg76PAh120LumkhBVrAl6FSSJElSuWA5JklSRZBUFc58IjJR/8p58OIlEA4HnUqSJEkq8yzHJEmqKGo2h9MnQSgePpkMHzwQdCJJkiSpzLMckySpItnncMi4JbL+2j/gy7cCjSNJkiSVdZZjkiRVNN0vgI79IFwEz5wLG74KOpEkSZJUZlmOSZJU0YRCcPzd0LAzbNkIT/0F8n4IOpUkSZJUJlmOSZJUESUkQ98noGo9WLsQpl4ARUVBp5IkSZLKHMsxSZIqqtT60PdxiE+ERS/Bf+8IOpHKgTFjxtCsWTOSk5Pp3r07s2fP3uH+GzduZNiwYdSvX5+kpCRatmzJK6+8Umyf7777jrPPPptatWqRkpJCu3bt+Oijj/bkZUiSJO0yyzFJkiqyxl3hhH9F1t++FRa+FGwelWlTpkxh+PDhXHfddcybN48OHTqQkZHBmjVrtrl/fn4+Rx99NN988w3PPvssixcvZty4cTRs2DC6z/fff89BBx1EQkICr776Kp9//jl33XUXNWrU2FuXJUmStEOhcDgcDjpEacjJySEtLY3s7GxSU1ODjiNJUtnyylUw+yFIrAqD34C6rYNOVCZ4/1Bc9+7d6dq1K/fffz8ARUVFNG7cmIsvvphrrrnmd/uPHTuWO+64g0WLFpGQkLDNc15zzTW8//77vPvuu7udy9+TJEkqqZLcPzhyTJKkWJBxCzQ7BPI3wVNnweYNQSdSGZOfn8/cuXPp1atXdFtcXBy9evVi1qxZ2zxm2rRp9OjRg2HDhpGens4BBxzArbfeSmFhYbF9unTpwumnn07dunU58MADGTdu3B6/HkmSpF1lOSZJUiyIT4DTH4HqTeD7r+HZ86Bwa9CpVIasW7eOwsJC0tPTi21PT08nKytrm8d89dVXPPvssxQWFvLKK69w7bXXctddd3HzzTcX2+fBBx9kv/32Y8aMGVx44YX87W9/45FHHtlulry8PHJycootkiRJe4rlmCRJsaJKLTjzSUioDF+9BW9cF3QilXNFRUXUrVuXhx9+mM6dO9O3b1/+/ve/M3bs2GL7dOrUiVtvvZUDDzyQoUOHMmTIkGL7/NaoUaNIS0uLLo0bN94blyNJkmKU5ZgkSbGkXjvo80Bkfdb98PGUYPOozKhduzbx8fGsXr262PbVq1dTr169bR5Tv359WrZsSXx8fHRb69atycrKIj8/P7pPmzZtih3XunVrli9fvt0sI0aMIDs7O7qsWLFidy9LkiRppyzHJEmKNW1PhkOuiKxPuxi+mxdsHpUJiYmJdO7cmczMzOi2oqIiMjMz6dGjxzaPOeigg1i6dClFRUXRbUuWLKF+/fokJiZG91m8eHGx45YsWULTpk23myUpKYnU1NRiiyRJ0p5iOSZJUiw64u/Q8hgozIMpZ8MPq3d+jCq84cOHM27cOB555BEWLlzIhRdeSG5uLgMHDgSgf//+jBgxIrr/hRdeyIYNG7jkkktYsmQJL7/8MrfeeivDhg2L7nPZZZfxwQcfcOutt7J06VKefPJJHn744WL7SJIkBalS0AEkSVIA4uLglIfh371g3RJ4uj8MeBEqJQadTAHq27cva9euZeTIkWRlZdGxY0emT58enaR/+fLlxMX98t9WGzduzIwZM7jsssto3749DRs25JJLLuHqq6+O7tO1a1emTp3KiBEjuPHGG2nevDmjR4+mX79+e/36JEmStiUUDofDQYcoDTk5OaSlpZGdne3Qe0mSdtW6pTDuSMjLhk4DoPc9EAoFnWqv8f6hfPD3JEmSSqok9w8+VilJUiyr3QJOGw+EYN4j8NH4oBNJkiRJe5XlmCRJsW6/o6HXdZH1V6+Gb94PNo8kSZK0F1mOSZIkOOhSOOBUKNoamX9s44qgE0mSJEl7heWYJEmKzDN24v1Qrz1sXgeT/wL5m4NOJUmSJO1xlmOSJCkisTKc+SRUrg1Zn8C0i6BifG+PJEmStF2WY5Ik6RfVG8MZj0JcJfj0OXj/nqATSZIkSXuU5ZgkSSqu2UFw7O2R9TeuhyWvBRpHkiRJ2pMsxyRJ0u91GQSdzwXC8NxgWLc06ESSJEnSHmE5JkmSfi8UgmPvgMZ/grxsmHwWbMkOOpUkSZJU6izHJEnStlVKhL6PQWpDWLcEnh8KRUVBp5IkSZJKleWYJEnavqp1oe/jUCkZlkyHt24JOpEkSZJUqizHJEnSjjXsBL3vjay/eyd8NjXYPJIkSVIpshyTJEk716Ev9Lgosv7CXyFrQbB5JEmSpFJiOSZJknZNrxtg3yOhYDM89RfIXR90IkmSJOkPsxyTJEm7Jr4SnDYBajSH7OXwzAAoLAg6lSRJkvSHWI5JkqRdl1IDznoKEqvCN+/CjL8HnUiSJEn6QyzHJElSydRtDac8HFmf/RDMeyzYPJIkSdIfYDkmSZJKbv/j4fD/i6y/PBxWzAk2jyRJkrSbLMckSdLuOfRK2P8EKMyHKWdDzqqgE0mSJEklZjkmSZJ2T1wcnDwW6raBTVkwpR8UbAk6lSRJklQilmOSJGn3JVWDM5+A5Orw3Vx46TIIh4NOJUmSJO0yyzFJkvTH1NwHTp8EoTj4+En4cGzQiSRJkqRdZjkmSZL+uH2PgD/fHFmf8Xf46u1A40iSJEm7ynJMkiSVjj/9FTqcBeFCeOZc2PB10IkkSZKknbIckyRJpSMUghNGQ4NO8OP3MLkf5G0KOpUkSZK0Q5ZjkiSp9CQkRybor5oOaz6DFy50gn5JkiSVaZZjkiSpdKU2gDMeg7gEWDgN/ntn0IkkSZKk7bIckyRJpa9Jdzjh7sj6WzfDoleCzSNJkiRth+WYJEnaMzr1h25DI+vPD4U1i4LNI0mSJG2D5ZgkSdpzMm6FZodA/g8w+azIRP2SJElSGWI5JkmS9pz4BDh9EqQ1gQ1fwbODoKgw6FSSJElSlOWYJEnas6rUjnyDZaUU+DIT3rg+6ESSJElSVKWgA0iSpBhQvz30eQCeHQgz74V67aD9GUGnkhSALQWFrNiwma/X5fLN+lyWrd/MloKioGNJkgLy9+NbU7NKYqAZLMckSdLeccApkLUA3rsbpl0MtfeDBgcGnUrSHpC/tYjlGzbzzU8F2M9F2DfrNrMy+0fC4aATSpLKisuO3s9yTJIkxZAj/wGrP4MvZsDkfjD0bahaN+hUknZDQWER337/I9+s+6X8+vl/v/v+R4p2UIBVS6pEs9pVIkutylRN8q8lkhSrUlMSgo6we+XYmDFjuOOOO8jKyqJDhw7cd999dOvWbZv7Tpo0iYEDBxbblpSUxJYtW7a5/wUXXMBDDz3Ev/71Ly699NLdiSdJksqquHg4dRyMOwrWfwFP94f+06BSsP+1UNK2bS0s4ruNP0ZKr3W5fLM+8jjksvW5rPj+Rwp30IBVSYz/qfyqQrPalWlWqwrNfyrEalVJJBQK7cUrkSRp+0pcjk2ZMoXhw4czduxYunfvzujRo8nIyGDx4sXUrbvt//KbmprK4sWLo6+39y/CqVOn8sEHH9CgQYOSxpIkSeVFchqc9RSMOxKWz4JXr4Leo4NOJcWswqIwKzf++NNjj7l8vW5zdH3F95spKNx+AZaSEE/TWpWjpVfzWj+NBqtdmTpVkyzAJEnlQonLsbvvvpshQ4ZER4ONHTuWl19+mQkTJnDNNdds85hQKES9evV2eN7vvvuOiy++mBkzZnD88ceXNJYkSSpPau8Hp46HJ8+AuRMjE/R3HRR0KqnCKioKsypnyy+PQP40Cuyb9bksX7+Z/MLtT4ifVCmOprWKj/z6eT091QJMklT+lagcy8/PZ+7cuYwYMSK6LS4ujl69ejFr1qztHrdp0yaaNm1KUVERnTp14tZbb6Vt27bRnxcVFXHOOedw5ZVXFtu+I3l5eeTl5UVf5+TklORSJElS0Fr+GY4aCZk3REaP1W0NTXsGnUoqt8LhMKtz8n41+X1usW+EzNu6/QIsMT6OJtECrHKxUWD1UpOJi7MAkyRVXCUqx9atW0dhYSHp6enFtqenp7No0aJtHtOqVSsmTJhA+/btyc7O5s4776Rnz5589tlnNGrUCIDbb7+dSpUq8be//W2Xs4waNYobbrihJPElSVJZc/BlkW+w/Ox5mHJOZIL+6o2DTiWVWeFwmLU/5P1qAvxfvhFy2frN/FhQuN1jK8WFaFKz8q9Gfv2y3qB6CvEWYJKkGLXHvxamR48e9OjRI/q6Z8+etG7dmoceeoibbrqJuXPncs899zBv3rwSDckeMWIEw4cPj77OycmhcWNvpiVJKldCITjp/sjk/FkLYEo/GDgdEisHnUwKTDgcZn1ufrGRX9+s+2Ui/Nz87Rdg8XEhGtdIKfbo48/fCNmwegqV4uP24pVIklQ+lKgcq127NvHx8axevbrY9tWrV+90TrGfJSQkcOCBB7J06VIA3n33XdasWUOTJk2i+xQWFnL55ZczevRovvnmm22eJykpiaSkpJLElyRJZVFiFTjzSXj4cFj1Mbz4NzhlXKQ4kyqocDjM95sLfjX/V+5P5VdkJNgPeVu3e2xcCBrWSPml/PpVCdaoRgoJFmCSJJVIicqxxMREOnfuTGZmJn369AEi84VlZmZy0UUX7dI5CgsLWbBgAccddxwA55xzDr169Sq2T0ZGBuecc0500n9JklTBVW8CZzwKj54EC56JTNB/0CVBp5L+sOzNBXz9m/m/fl7P2bL9AiwUggZpKT+VXpG5wJr9NAdY45opJFWK34tXIUlSxVbixyqHDx/OgAED6NKlC926dWP06NHk5uZGi6z+/fvTsGFDRo0aBcCNN97In/70J1q0aMHGjRu54447WLZsGYMHDwagVq1a1KpVq9h7JCQkUK9ePVq1avVHr0+SJJUXzQ6GY26DV66AN66Hum1hv147PUwKWs6Wgl99C+Rmlq3PjRZi328u2OGx9dOSo6VX89q/fCNk45qVSU6wAJMkaW8ocTnWt29f1q5dy8iRI8nKyqJjx45Mnz49Okn/8uXLiYv7ZSj3999/z5AhQ8jKyqJGjRp07tyZmTNn0qZNm9K7CkmSVDF0HQxZn8C8R+HZ82DoW1Br36BTSWzK2xp9/DFShG2Orq/Pzd/hsempSTSt9cu3P/48EX7TmlVISbQAkyQpaKFwOBwOOkRpyMnJIS0tjezsbFJTU4OOI0mSdtfWPJh0Anw7G2q3gsFvQPKe+Xe79w/lw976PW3O38o3P5VeP88Ftmz9Zr5en8vaH/J2eGztqknRkV+RAuznxyArUzlxj38HliRJ+o2S3D/4b2pJklS2VEqCvo/Bw0fAusXw/NDIhP1xTjKu0vfOkrU88NZSvlmfy+qcHRdgNask0qxWZNRX81+VYE1rVaZacsJeSixJkkqb5ZgkSSp7qtWDMx+HCcfC0jdg1Xxo2CnoVKqAfswv5MOvN0RfV6+cUOxbIJvVrvxTAVaFtBQLMEmSKiLLMUmSVDY17Awnj4XUBhZj2mM6Na3Ov/p2iBZi1SsnBh1JkiTtZZZjkiSp7DrglKATqIKrWy2Zkw9sFHQMSZIUICfvkCRJkiRJUsyyHJMkSZIkSVLMshyTJEmSJElSzLIckyRJkiRJUsyyHJMkSZIkSVLMshyTJEmSJElSzLIckyRJkiRJUsyyHJMkSZIkSVLMshyTJEmSJElSzLIckyRJkiRJUsyyHJMkSZIkSVLMshyTJEmSJElSzLIckyRJkiRJUsyyHJMkSZIkSVLMshyTJEmSJElSzLIckyRJkiRJUsyyHJMkSZIkSVLMshyTJEmSJElSzLIckyRJkiRJUsyyHJMkSZIkSVLMshyTJEmSJElSzLIckyRJkiRJUsyyHJMkSZIkSVLMshyTJEmSJElSzLIckyRJkiRJUsyyHJMkSZIkSVLMshyTJEmSJElSzLIckyRJkiRJUsyyHJMkSZIkSVLMshyTJEmSJElSzLIckyRJkiRJUsyqFHSA0hIOhwHIyckJOIkkSSovfr5v+Pk+QmWT93mSJKmkSnKfV2HKsR9++AGAxo0bB5xEkiSVNz/88ANpaWlBx9B2eJ8nSZJ2167c54XCFeQ/lRYVFbFy5UqqVatGKBQq9fPn5OTQuHFjVqxYQWpqaqmfXzvm5x8sP/9g+fkHy88/WHv68w+Hw/zwww80aNCAuDhnmyirvM+r2Pz8g+XnHyw//2D5+QerLN3nVZiRY3FxcTRq1GiPv09qaqr/0ATIzz9Yfv7B8vMPlp9/sPbk5++IsbLP+7zY4OcfLD//YPn5B8vPP1hl4T7P/0QqSZIkSZKkmGU5JkmSJEmSpJhlObaLkpKSuO6660hKSgo6Skzy8w+Wn3+w/PyD5ecfLD9/7Q3+OQuWn3+w/PyD5ecfLD//YJWlz7/CTMgvSZIkSZIklZQjxyRJkiRJkhSzLMckSZIkSZIUsyzHJEmSJEmSFLMsxyRJkiRJkhSzLMd2wZgxY2jWrBnJycl0796d2bNnBx0pZvz3v/+ld+/eNGjQgFAoxAsvvBB0pJgxatQounbtSrVq1ahbty59+vRh8eLFQceKKQ8++CDt27cnNTWV1NRUevTowauvvhp0rJh02223EQqFuPTSS4OOEjOuv/56QqFQsWX//fcPOpYqIO/zguN9XnC8zwue93llh/d5e19ZvM+zHNuJKVOmMHz4cK677jrmzZtHhw4dyMjIYM2aNUFHiwm5ubl06NCBMWPGBB0l5rzzzjsMGzaMDz74gNdff52CggL+/Oc/k5ubG3S0mNGoUSNuu+025s6dy0cffcSRRx7JSSedxGeffRZ0tJgyZ84cHnroIdq3bx90lJjTtm1bVq1aFV3ee++9oCOpgvE+L1je5wXH+7zgeZ9XNnifF5yydp8XCofD4UATlHHdu3ena9eu3H///QAUFRXRuHFjLr74Yq655pqA08WWUCjE1KlT6dOnT9BRYtLatWupW7cu77zzDoceemjQcWJWzZo1ueOOOxg0aFDQUWLCpk2b6NSpEw888AA333wzHTt2ZPTo0UHHignXX389L7zwAvPnzw86iiow7/PKDu/zguV9Xtngfd7e5X1ecMrifZ4jx3YgPz+fuXPn0qtXr+i2uLg4evXqxaxZswJMJu192dnZQORf2tr7CgsLmTx5Mrm5ufTo0SPoODFj2LBhHH/88cX+PaC954svvqBBgwbss88+9OvXj+XLlwcdSRWI93nSL7zPC5b3ecHwPi9YZe0+r1Kg717GrVu3jsLCQtLT04ttT09PZ9GiRQGlkva+oqIiLr30Ug466CAOOOCAoOPElAULFtCjRw+2bNlC1apVmTp1Km3atAk6VkyYPHky8+bNY86cOUFHiUndu3dn0qRJtGrVilWrVnHDDTdwyCGH8Omnn1KtWrWg46kC8D5PivA+Lzje5wXH+7xglcX7PMsxSTs1bNgwPv3008CfA49FrVq1Yv78+WRnZ/Pss88yYMAA3nnnHW+c9rAVK1ZwySWX8Prrr5OcnBx0nJh07LHHRtfbt29P9+7dadq0KU8//bSPm0hSKfI+Lzje5wXD+7zglcX7PMuxHahduzbx8fGsXr262PbVq1dTr169gFJJe9dFF13ESy+9xH//+18aNWoUdJyYk5iYSIsWLQDo3Lkzc+bM4Z577uGhhx4KOFnFNnfuXNasWUOnTp2i2woLC/nvf//L/fffT15eHvHx8QEmjD3Vq1enZcuWLF26NOgoqiC8z5O8zwua93nB8D6v7CkL93nOObYDiYmJdO7cmczMzOi2oqIiMjMzfRZcFV44HOaiiy5i6tSpvPnmmzRv3jzoSCLy/0F5eXlBx6jwjjrqKBYsWMD8+fOjS5cuXejXrx/z58/3hikAmzZt4ssvv6R+/fpBR1EF4X2eYpn3eWWT93l7h/d5ZU9ZuM9z5NhODB8+nAEDBtClSxe6devG6NGjyc3NZeDAgUFHiwmbNm0q1h5//fXXzJ8/n5o1a9KkSZMAk1V8w4YN48knn+Q///kP1apVIysrC4C0tDRSUlICThcbRowYwbHHHkuTJk344YcfePLJJ3n77beZMWNG0NEqvGrVqv1u3pUqVapQq1Yt52PZS6644gp69+5N06ZNWblyJddddx3x8fGcddZZQUdTBeJ9XrC8zwuO93nB8z4vON7nBa8s3udZju1E3759Wbt2LSNHjiQrK4uOHTsyffr0303eqj3jo48+4ogjjoi+Hj58OAADBgxg0qRJAaWKDQ8++CAAhx9+eLHtEydO5Nxzz937gWLQmjVr6N+/P6tWrSItLY327dszY8YMjj766KCjSXvct99+y1lnncX69eupU6cOBx98MB988AF16tQJOpoqEO/zguV9XnC8zwue93mKZWXxPi8UDofDgb27JEmSJEmSFCDnHJMkSZIkSVLMshyTJEmSJElSzLIckyRJkiRJUsyyHJMkSZIkSVLMshyTJEmSJElSzLIckyRJkiRJUsyyHJMkSZIkSVLMshyTJEmSJElSzLIckyRJkiRJUsyyHJMkSZIkSVLMshyTJEmSJElSzLIckyRJkiRJUsz6f24mSjZB6KMgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist_['loss'],label='Train_Loss')\n",
    "plt.plot(hist_['val_loss'],label='Validation_Loss')\n",
    "plt.title('Train_Loss & Validation_Loss',fontsize=20)\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(hist_['accuracy'],label='Train_Accuracy')\n",
    "plt.plot(hist_['val_accuracy'],label='Validation_Accuracy')\n",
    "plt.title('Train_Accuracy & Validation_Accuracy',fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "882914c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8404 - loss: 0.3866\n",
      "Validation Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss, acc = model.evaluate(augmented_data_val)\n",
    "print(f\"Validation Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c57b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0.85214],\n",
       "       [     0.6616],\n",
       "       [     0.8521],\n",
       "       [    0.42987],\n",
       "       [    0.46671],\n",
       "       [     0.7271],\n",
       "       [    0.81913],\n",
       "       [    0.59527],\n",
       "       [    0.73213],\n",
       "       [    0.61607],\n",
       "       [     0.7461],\n",
       "       [    0.84783],\n",
       "       [    0.43996],\n",
       "       [    0.82863],\n",
       "       [    0.41876],\n",
       "       [    0.76553],\n",
       "       [    0.80803],\n",
       "       [    0.41343],\n",
       "       [    0.86041],\n",
       "       [    0.57861],\n",
       "       [    0.81711],\n",
       "       [    0.70732],\n",
       "       [    0.42507],\n",
       "       [    0.58564],\n",
       "       [     0.6997],\n",
       "       [    0.83232],\n",
       "       [    0.74322]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1876c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07f07d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "pred_probs = model.predict(augmented_data_val, verbose=1)\n",
    "y_pred = np.argmax(pred_probs, axis=1)\n",
    "class_labels = [\"Animal\" , \"human\"]\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# y_true = augmented_data_val.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da91565e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dsmat\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\dsmat\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\dsmat\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Animal': {'precision': 0.2222222222222222,\n",
       "  'recall': 1.0,\n",
       "  'f1-score': 0.36363636363636365,\n",
       "  'support': 30.0},\n",
       " 'human': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 105.0},\n",
       " 'accuracy': 0.2222222222222222,\n",
       " 'macro avg': {'precision': 0.1111111111111111,\n",
       "  'recall': 0.5,\n",
       "  'f1-score': 0.18181818181818182,\n",
       "  'support': 135.0},\n",
       " 'weighted avg': {'precision': 0.04938271604938271,\n",
       "  'recall': 0.2222222222222222,\n",
       "  'f1-score': 0.08080808080808081,\n",
       "  'support': 135.0}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y, y_pred, target_names=class_labels, output_dict=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
